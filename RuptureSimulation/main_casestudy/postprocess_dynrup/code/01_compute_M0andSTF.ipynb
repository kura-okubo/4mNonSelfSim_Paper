{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic rupture modeling of gouge patch: compare the M0 and STF\n",
    "\n",
    "In this notebook, we compute the seismic moment and source time function obtained from the dynamic rupture modeling.\n",
    "We dump the processed data into HDF5.\n",
    "We evaluate the source parameters by fitting the synthetic STF in the later notebooks.\n",
    "\n",
    "2024.02.22 Kurama Okubo\n",
    "\n",
    "- 2025.1.30 Clean up the notebook for the master plot.\n",
    "- 2025.2.3 Update for parameter study: upsampling the STF of dynamic rupture model to improve the time shift during the fitting.\n",
    "- 2025.2.6 Update iterate the Tw_init to avoid the jump in the fitting residual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.cm import ScalarMappable\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from scipy.signal import freqz\n",
    "from scipy import signal\n",
    "\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "\n",
    "from post_dynrup_func import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 4.75\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.75\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"xtick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 4.75\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.75\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"ytick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = False\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = \"../figure/01_M0andSTF\"\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/01_M0andSTF\"\n",
    "if not os.path.exists(datadir):\n",
    "    os.makedirs(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compute seismic moment\n",
    "\n",
    "The seismic moment is computed as follows:\n",
    "\n",
    "$$ M_0(t) = \\mu \\int_A u(\\mathbf{\\xi}, t) dA $$\n",
    "\n",
    "$$ = \\mu dA \\sum_i^{N} u_i $$\n",
    "\n",
    "where $dA$ is the area of grid in the simulation, which is uniform in the simulaiton.\n",
    "\n",
    "# 2. Compute STF\n",
    "\n",
    "The seismic moment is computed as follows:\n",
    "\n",
    "$$ \\dot{M}_0(t) = \\mu \\int_A \\dot{u}(\\mathbf{\\xi}, t) dA $$\n",
    "\n",
    "$$ = \\mu dA \\sum_i^{N} \\dot{u}_i $$\n",
    "\n",
    "where $dA$ is the area of grid in the simulation, which is uniform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 96e9\n",
    "nu = 0.246 # metagabbro\n",
    "mu = E/(2*(1+nu))\n",
    "\n",
    "a_patch = 4.0e-3\n",
    "rupturetype = \"pulse\"\n",
    "pdcscaling= 0.6 #0.475 #0.5 #0.55 # 0.65\n",
    "bgbeta= 0.35 #0.4 #0.3 #0.5\n",
    "# gammautry = 0.8\n",
    "\n",
    "nb_x_elements = 1024 #128\n",
    "nb_z_elements = 1024 #128\n",
    "\n",
    "sig_n = 6e6\n",
    "\n",
    "IfBinaryOutput = True\n",
    "\n",
    "Ifmasteroutput=True\n",
    "if Ifmasteroutput:\n",
    "    filekey = \"_master\"\n",
    "else:\n",
    "    filekey = \"\"\n",
    "    \n",
    "read_dumpedpickle = False # false if you first run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case study parameter casename\n",
    "casestr = f\"a={a_patch*1e3:.2f}_ruptype={rupturetype}_pdcscaling={pdcscaling:.3f}_sn={sig_n/1e6:.1f}MPa_hatfr=0.3_bgbeta={bgbeta:.2f}\"\n",
    "\n",
    "finame=f\"../../preprocess_modelsetup/data/gouge_dynamicrupture_modelparam_{casestr}{filekey}.csv\"\n",
    "\n",
    "# Read model parameters\n",
    "df_modelparam = pd.read_csv(finame, index_col=0)\n",
    "\n",
    "# datadir_root = \"../../../uguca/build_v42_masterfitmodel/simulations_main_casestudy\"\n",
    "\n",
    "# datadir_root = \"/Volumes/4mGouge_WorkHDD/RuptureSimulation/build_hpcv15_neweventset_dt1e-8/simulations_main_casestudy_hpc\"\n",
    "# datadir_root = \"/Volumes/4mGouge_WorkHDD/RuptureSimulation/build_hpcv52_paramstudy_v11/simulations_main_casestudy_hpc_dev\"\n",
    "datadir_root = \"/Volumes/Okuboetal2025_masterHDD/RuptureSimulation/main_casestudy/build_hpcv62_mastercase_v3/simulations_main_casestudy_hpc_master\"\n",
    "\n",
    "casestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelparam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter study\n",
    "# ifParamStudy = True # deprecated: change the file name for the parameter study\n",
    "ifSaveHDF = True # dump the data to the HDF file for the following processings.\n",
    "    \n",
    "selectids_list = [24, 50, 52, 72, 129]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select model parameter index\n",
    "# delsigma_index = {\"24\": 5,\n",
    "#                   \"50\": 5,\n",
    "#                   \"52\": 5,\n",
    "#                   \"72\": 7,\n",
    "#                   \"129\": 6,\n",
    "#                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select the model index\n",
    "# delsigma_factorstr = dict() \n",
    "# for ii, sid in enumerate(selectids_list):\n",
    "#     delsigma_factorstr[f\"{sid}\"] = delsigma_factor_range[ii][delsigma_index[f\"{sid}\"]]\n",
    "    \n",
    "# delsigma_factorstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delsigma_factorstr ={\n",
    "    \"24\":0.695,\n",
    "    \"50\":0.5,\n",
    "    \"52\":0.46,\n",
    "    \"72\":0.43,\n",
    "    \"129\":0.41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delsigma_factorstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_id = 87\n",
    "model_ids = [24, 50, 52, 72, 129]\n",
    "# model_ids = [24, 52, 129]\n",
    "# model_ids = [50, 52, 72, 129]\n",
    "# model_ids = [72, 129]\n",
    "\n",
    "data_all = dict()\n",
    "\n",
    "for model_id in model_ids:\n",
    "#model_id = model_ids[0]\n",
    "\n",
    "    df_modelparam_selected = df_modelparam[df_modelparam.index == model_id]\n",
    "\n",
    "    # if ifParamStudy:\n",
    "    simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}_{delsigma_factorstr[f'{model_id}']:.4f}\"\n",
    "    # else:\n",
    "        # simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}\"\n",
    "\n",
    "    print(f\"Process {simulation_name}\")\n",
    "    \n",
    "    df_time = pd.read_csv(os.path.join(datadir_root,simulation_name+\".time\"), header=None, sep=' ', index_col=0)\n",
    "    df_coord = pd.read_csv(os.path.join(datadir_root,simulation_name+\".coords\"), header=None, sep=' ', index_col=None)\n",
    "    NT = len(df_time)\n",
    "\n",
    "    # set coordinate\n",
    "    xcoord = df_coord.loc[:,0].values\n",
    "    zcoord = df_coord.loc[:,2].values\n",
    "\n",
    "    x_length = xcoord.max()\n",
    "    z_length = zcoord.max()\n",
    "\n",
    "    dgrid = zcoord[1]-zcoord[0]\n",
    "    dA = dgrid * dgrid\n",
    "    print(f\"Grid size: {dgrid*1e3}[mm]\") \n",
    "\n",
    "    # read displacement\n",
    "    read_parameter = \"top_disp_0\" # consider only the x direction.\n",
    "    \n",
    "    \n",
    "    if IfBinaryOutput:\n",
    "        D = np.fromfile(os.path.join(datadir_root,simulation_name+f\"-DataFiles/{read_parameter}.out\"), dtype=\"float32\")\n",
    "        df_data = pd.DataFrame(data=D.reshape((NT, -1)))\n",
    "    else:\n",
    "        df_data = pd.read_csv(os.path.join(datadir_root,simulation_name+f\"-DataFiles/{read_parameter}.out\"), header=None, sep=' ')        \n",
    "\n",
    "    # trim the domain\n",
    "    x_maxwidth=15e-3 # half width of the area to compute the moment; 15mm is large enough to encompass all the slip region\n",
    "    z_maxwidth=15e-3\n",
    "    M0_internal_inds_rec = np.where((np.abs(xcoord - dgrid/2 - x_length/2) <= x_maxwidth) & (np.abs(zcoord - dgrid/2 - z_length/2) <= z_maxwidth))\n",
    "\n",
    "    # extract within the patch    \n",
    "    rcoord = np.linalg.norm(np.vstack([xcoord - dgrid/2 - x_length/2, zcoord - dgrid/2 - z_length/2]), axis=0)\n",
    "    M0_internal_inds_patch = np.where(rcoord <= a_patch)\n",
    "    # M0_internal_inds\n",
    "\n",
    "#     h = plt.scatter(xcoord - x_length/2, zcoord - z_length/2, c=rcoord, cmap='viridis')\n",
    "#     plt.colorbar(h)\n",
    "\n",
    "    M0_rec = np.zeros(NT)\n",
    "    M0_patch = np.zeros(NT)\n",
    "\n",
    "    for i in range(NT):\n",
    "        M0_rec[i] = mu * dA * df_data.loc[i, M0_internal_inds_rec].sum()*2 # convert from top displacement to slip by multiplying 2\n",
    "        M0_patch[i] = mu * dA * df_data.loc[i, M0_internal_inds_patch].sum()*2 # convert from top displacement to slip by multiplying 2\n",
    "\n",
    "    2    # STF_patch = np.gradient(M0_patch, df_time.values.squeeze())\n",
    "\n",
    "    # Read velocity\n",
    "    read_parameter = \"top_velo_0\" # select the parameter to read\n",
    "    \n",
    "    if IfBinaryOutput:\n",
    "        D = np.fromfile(os.path.join(datadir_root,simulation_name+f\"-DataFiles/{read_parameter}.out\"), dtype=\"float32\")\n",
    "        df_data = pd.DataFrame(data=D.reshape((NT, -1)))\n",
    "    else:\n",
    "        df_data = pd.read_csv(os.path.join(datadir_root,simulation_name+f\"-DataFiles/{read_parameter}.out\"), header=None, sep=' ')\n",
    "        \n",
    "    STF_rec = np.zeros(NT)\n",
    "    STF_patch = np.zeros(NT)\n",
    "\n",
    "\n",
    "    for i in range(NT):\n",
    "        STF_rec[i] = mu * dA * df_data.loc[i, M0_internal_inds_rec].sum()*2 # convert from top half velocity to the slip velocity by multiplying 2\n",
    "        STF_patch[i] = mu * dA * df_data.loc[i, M0_internal_inds_patch].sum()*2 # convert from top half velocity to the slip velocity by multiplying 2\n",
    "\n",
    "\n",
    "    # store the data\n",
    "\n",
    "    key_t = f\"t_{simulation_name}\"\n",
    "    key_M0 = f\"M0_rec_{simulation_name}\"\n",
    "    key_STF = f\"STF_rec_{simulation_name}\"\n",
    "    key_STF_patch = f\"STF_patch_{simulation_name}\"\n",
    "\n",
    "\n",
    "    data_all[key_t] = df_time[1].values\n",
    "    data_all[key_M0] = M0_rec\n",
    "    data_all[key_STF] = STF_rec\n",
    "    data_all[key_STF_patch] = STF_patch\n",
    "          \n",
    "    print(f\"{M0_rec[-1]:.3f}J, {M0_patch[-1]:3f}J, {(M0_rec[-1] - M0_patch[-1])/M0_rec[-1]}\")\n",
    "#     # Dump data\n",
    "#     with open(datadir+f'/M0andSTF_all_{tau_r:.2f}.pickle', 'wb') as fo:\n",
    "#         pickle.dump(data_all, fo, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time step of numerical simulation\n",
    "\n",
    "dt_dynrup = (df_time.values[1]-df_time.values[0])[0]\n",
    "print(f\"result dumping rate of dynamic rupture model is {dt_dynrup*1e6:.4f} μs, {1/dt_dynrup/1e6:.2f} MHz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot time history of M0\n",
    "\n",
    "Here we plot the time history of $M_0$ to check the growth of slip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "for model_id in model_ids:\n",
    "    \n",
    "    df_modelparam_selected = df_modelparam[df_modelparam.index == model_id]\n",
    "\n",
    "    # if ifParamStudy:\n",
    "    simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}_{delsigma_factorstr[f'{model_id}']:.4f}\"\n",
    "    # else:\n",
    "        # simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}\"\n",
    "\n",
    "    key_M0 = f\"M0_rec_{simulation_name}\"\n",
    "    \n",
    "    ax.plot(df_time*1e6, data_all[key_M0], \"k-\")\n",
    "    #     ax.plot(df_time*1e6, M0_patch, \"r-\", label=\"Dynamic rupture model patch domain\")\n",
    "    # ax.plot(df_time*1e6, cosine_stf, \"gray\", ls=\"--\",  label=f\"Cosine STF: TR={TR*1e6:.1f}μs\")\n",
    "\n",
    "    ax.axhline(df_modelparam_selected.M0_mean.values[0], ls=\"--\", c=\"k\")\n",
    "\n",
    "ax.set_xlim([0, 10])\n",
    "# ax.set_ylim([-0.02, 1.1])\n",
    "\n",
    "ax.set_xlabel(\"Time [μs]\")\n",
    "\n",
    "ylabelstr = r\"$\\mathrm{{M}_0}$\"\n",
    "ax.set_ylabel(\"{} [Nm]\".format(ylabelstr))\n",
    "\n",
    "# ax.legend(loc=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figdir +f\"/M0_all_{casestr}{filekey}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# plt.close()\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot source time function\n",
    "\n",
    "We deprecated the comparison to the stacked observation of STF. We compare the modeled STF with the best-fit averaged cosine STF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load color dictionary consistent to the plot of the repeated waveforms\n",
    "repeated_sensor_lcdict = \"OL08\" # the color dict is same for all the sensor although separately saved.\n",
    "gougepatch_id = \"G3\"\n",
    "with open(f'../../../../ComputeScaling/data/01_plot_gougeevents/lc_dict_{gougepatch_id}_{repeated_sensor_lcdict}.pkl', 'rb') as fi:\n",
    "    lc_dict = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "tvec_model = df_time.values.squeeze()\n",
    "\n",
    "i = 0\n",
    "\n",
    "maxloc_center = 1.3e-6\n",
    "\n",
    "# tvec_data = np.array(fo_stack[f\"param/tvec_upsampled_trimmed\"])\n",
    "# dt_upsampled = tvec_data[1] - tvec_data[0]\n",
    "\n",
    "for model_id in model_ids:\n",
    "\n",
    "    # plot observation data and synthetic STF\n",
    "    datacase = f\"fb03-087__{model_id:04d}\"\n",
    "\n",
    "    # plot synthetic\n",
    "    df_modelparam_selected = df_modelparam[df_modelparam.index == model_id]\n",
    "    M0_mean = df_modelparam_selected[\"M0_mean\"].values[0]\n",
    "    Tw_mean = df_modelparam_selected[\"Tw_mean\"].values[0]\n",
    "       \n",
    "    # compute synthetic STF\n",
    "    tvec_syn = np.linspace(0, Tw_mean, int(Tw_mean/dt_dynrup))\n",
    "    STF_syn = stf_cosine(tvec_syn, Tw_mean, M0_mean)\n",
    "    # STF_syn = stf_kupper(tvec_syn, Tw_mean, M0_mean)\n",
    "    \n",
    "    ax.plot((tvec_syn+0)*1e6, STF_syn/1e6, ls=\":\", c=lc_dict[datacase], lw=2.0) # before alignment\n",
    "    \n",
    "    # Plot dynamic rupture model\n",
    "    df_modelparam_selected = df_modelparam[df_modelparam.index == model_id]\n",
    "    \n",
    "    # if ifParamStudy:\n",
    "    simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}_{delsigma_factorstr[f'{model_id}']:.4f}\"\n",
    "    # else:\n",
    "        # simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}\"\n",
    "\n",
    "    key_STF = f\"STF_rec_{simulation_name}\"\n",
    "    STF_rec = data_all[key_STF]\n",
    "    STF_maxarg = np.argmax(STF_rec)\n",
    "    dt_model = tvec_model[1] - tvec_model[0]\n",
    "    tshift = (tvec_model[STF_maxarg] - maxloc_center)\n",
    "    ax.plot((tvec_model - tshift)*1e6, STF_rec/1e6, \"-\", c=lc_dict[datacase], lw=2, zorder=3)\n",
    "\n",
    "    # Apply band-pass filter to mimic the observation\n",
    "    freqmin = 0.1e6\n",
    "    freqmax = 1e6\n",
    "    butterworth_order = 3\n",
    "    filtered_yshift = [0.02, 0.08, 0.12, 0.18 ,0.25]\n",
    "    b, a = signal.butter(butterworth_order, (freqmin, freqmax), 'bandpass', fs=1/dt_model, output='ba')\n",
    "    STF_rec_filtered = signal.filtfilt(b, a, STF_rec, method='gust') # using two-way filter Gustafsson’s method\n",
    "    # ax.plot((tvec_model - tshift)*1e6, STF_rec_filtered/1e6+ filtered_yshift[i], \"--\", c=lc_dict[datacase], lw=2, zorder=3)\n",
    "\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "\n",
    "ylabelstr = r\"$\\dot{M}_0(t)$\"\n",
    "ax.set_xlabel(\"Time [μs]\")\n",
    "ax.set_ylabel(\"{} [MNm/s]\".format(ylabelstr))\n",
    "\n",
    "ax.set_xlim([-2, 4.5])\n",
    "ax.set_ylim([-0.05, 1.0])\n",
    "# ax.set_ylim([-0.05, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the source parameters $M_0$ and $T_w$\n",
    "\n",
    "Here we compute the $M_0$ and $T_w$ by fitting the synthetic STF same as the main analysis of the observations. For a fair comparison, we apply the attenuation factor to mimic the path effect, then apply the low-pass filter similar with the main analysis, and deconvolve the attenuation factor with the water-level. We fit the processed STF with the synthetic cosine STF to estimate the source parameters. Note that we ignore the directivity effect, which modifies the shape of STF in the observations. See the `Others/Synthetictest_STFestimation` for the synthetic test of this process flow.\n",
    "\n",
    "> We apply the low-pass filter instead of the band-pass filter to avoid the acausal artifacts on the STF. In the main analysis, we applied the band-pass filter on the velocity waveform, and detrend using the polynomials, which mitigated the acausal bump in the STF. The purpose of the band-pass filter is to remove the low-frequency noise on the AE waveforms. Here, since the dynamic rupture model does not show the noise, we selected the low-pass filter at 1MHz same as the upper bound of main analysis to estimate the source parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"01_dynrupSTFfit_schematic.png\" alt=\"01_dynrupSTFfit_schematic.png\" style=\"width: 1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Q model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gougepatch_id = \"G3\"\n",
    "Qinv_quart = 50\n",
    "\n",
    "df_Qinv_quantile = pd.read_csv(\"../../../../Calibration/Attenuation/data/df_Qinv_quantile.csv\", index_col=0)\n",
    "df_Qinv_quantile.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the dynamic rupture STF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing parameters\n",
    "\n",
    "# upsample the data\n",
    "dt_upsampled = 1e-9 #9\n",
    "\n",
    "zerowin_pre = 10e-6\n",
    "zerowin_post = 10e-6\n",
    "vp = 6200 #[m/s]\n",
    "k_waterlevel = 0.3 # used in the observation analysis\n",
    "\n",
    "# Parameters for filtering\n",
    "# We use the same filter as the previously analyzed gouge events\n",
    "freqmin = 0.1e6 #\n",
    "freqmax = 1e6 # \n",
    "\n",
    "butterworth_order = 3\n",
    "\n",
    "\n",
    "# fitting STF parameters\n",
    "LBA_buffer_winlen = 1.5e-6 # standard value for the LBA buffer\n",
    "\n",
    "Tshift_init = 0.0\n",
    "pwin_pre = zerowin_pre\n",
    "\n",
    "bounds = [(0, 10), (0.1e-6, 10.0e-6), (-1e-6, 1e-6)]\n",
    "stf_type = \"cosine\" #\"kupper\"\n",
    "xatol = 1e-8 #2 \n",
    "fatol = 1e-8 #2\n",
    "\n",
    "residu_win = [0.5, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the source distance datasheet to compute the mean source distance of the event\n",
    "trimP_coef_columns = [\"rdist\", \"incidentangle\", \"dip\", \"azimuth\", \"k_M0uz\", \"TR\", \"beta_coef_p\"]\n",
    "df_trimP_coef = pd.DataFrame(columns=trimP_coef_columns)\n",
    "\n",
    "AEsensor_list = [\"OL23\", \"OL07\", \"OL08\", \"OL22\"] # update: we use 4 close sensors\n",
    "\n",
    "for stnm in AEsensor_list:\n",
    "    df_trimP_sensor = pd.read_csv(f\"../../../../ComputeScaling/data/02_trim_pwave/trimP_coefficients_{gougepatch_id}_{stnm}.csv\", index_col=0)\n",
    "    df_trimP_coef = pd.concat([df_trimP_coef if not df_trimP_coef.empty else None, df_trimP_sensor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for model_id in model_ids:\n",
    "# model_id = model_ids[3]\n",
    "# print(f\"prcess {model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_debug = sns.color_palette(\"colorblind\")\n",
    "lc_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynrup_sourceparam = pd.DataFrame(columns=[\"event_id\", \"M0_rec\", \"M0_bestfit\", \"Tw_bestfit\", \"Tshift_bestfit\"])\n",
    "\n",
    "for model_id in model_ids:\n",
    "# model_id = model_ids[3]\n",
    "    print(f\"prcess {model_id}\")\n",
    "    \n",
    "    #------------------------#\n",
    "    # 1. Zeropadding the STF\n",
    "    #------------------------#\n",
    "    \n",
    "    df_modelparam_selected = df_modelparam[df_modelparam.index == model_id]\n",
    "    \n",
    "    # if ifParamStudy:\n",
    "    simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}_{delsigma_factorstr[f'{model_id}']:.4f}\"\n",
    "    # else:\n",
    "        # simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}\"\n",
    "\n",
    "    # simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}\"\n",
    "    key_M0 = f\"M0_rec_{simulation_name}\"\n",
    "    M0_rec = data_all[key_M0]\n",
    "    \n",
    "    key_STF = f\"STF_rec_{simulation_name}\"\n",
    "    STF_rec = data_all[key_STF]\n",
    "    tvec_dynrup = df_time.values.squeeze()\n",
    "    dt_dynrup = tvec_model[1] - tvec_model[0]\n",
    "    # plt.plot(tvec_model*1e6, STF_rec/1e6, \"-\", c=lc_dict[datacase], lw=1, zorder=3)\n",
    "\n",
    "    # upsample the data\n",
    "    tvec_upsampled = np.arange(tvec_dynrup[0], tvec_dynrup[-1], step=dt_upsampled)\n",
    "    STF_rec_upsampled = np.interp(tvec_upsampled, tvec_dynrup, STF_rec)\n",
    "    \n",
    "    # tpre = -np.arange(dt_dynrup, zerowin_pre, step=dt_dynrup)[::-1]\n",
    "    # tpost = np.arange(tvec_dynrup[-1]+dt_dynrup, tvec_dynrup[-1]+zerowin_post, step=dt_dynrup)\n",
    "    tpre = -np.arange(dt_upsampled, zerowin_pre, step=dt_upsampled)[::-1]\n",
    "    tpost = np.arange(tvec_dynrup[-1]+dt_upsampled, tvec_dynrup[-1]+zerowin_post, step=dt_upsampled)\n",
    "    tvec_dynrup_padded = np.hstack([tpre, tvec_upsampled, tpost])\n",
    "    \n",
    "    post_add = 0\n",
    "    if np.mod(len(tvec_dynrup_padded), 2) == 1:\n",
    "        # make tvec length as even\n",
    "        tvec_dynrup_padded = np.hstack([tvec_dynrup_padded, tvec_dynrup_padded[-1]+dt_upsampled])\n",
    "        post_add = 1\n",
    "    \n",
    "    STF_rec_padded = np.hstack([np.zeros(len(tpre)), STF_rec_upsampled, np.zeros(len(tpost)+post_add)])\n",
    "    # plt.plot(tvec_dynrup_padded, STF_rec_padded)\n",
    "    \n",
    "    #------------------------#\n",
    "    # 2. Compute attenuation factor\n",
    "    #------------------------#\n",
    "    # We use the mean source distance of the four AE sensors to compute the p wave arrival time\n",
    "    sourcedist_average = df_trimP_coef.loc[f\"fb03-{expr_id:03d}__{model_id:04d}\"][\"rdist\"].mean()\n",
    "    tt_average = sourcedist_average/vp\n",
    "    print(f\"Averaged travel time: {tt_average*1e6:.2f}μs\")\n",
    "    \n",
    "    Ndata_FFT = len(tvec_dynrup_padded)\n",
    "    # NFFT = 2**(Ndata_FFT-1).bit_length()\n",
    "    NFFT = Ndata_FFT # same length of the data for the sake of simplicity\n",
    "    \n",
    "    # print(Ndata_FFT, NFFT)\n",
    "    F_freq = np.fft.rfftfreq(NFFT, d=dt_upsampled)\n",
    "    Qinv_interp = get_Qinv(F_freq, df_Qinv_quantile.freq.values*1e6, df_Qinv_quantile[f\"Qinv_{Qinv_quart}\"].values).astype(float)\n",
    "    \n",
    "    # plt.loglog(F_freq/1e6, Qinv_interp.real, \".-\")\n",
    "    # plt.xlim([0.1, 2])\n",
    "    # plt.ylim([0.002, 0.2])\n",
    "    # plt.xlabel(\"Frequency [MHz]\")\n",
    "    # plt.ylabel(\"Attenuation, $Q^{-1}$\")\n",
    "    \n",
    "    Bomega_interp = np.exp(-np.pi * F_freq * tt_average * Qinv_interp)\n",
    "    Bomega_wlv = np.maximum(np.abs(Bomega_interp), (k_waterlevel*np.abs(Bomega_interp).max()))\n",
    "    \n",
    "    # fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    # ax.loglog(F_freq/1e6, Bomega_interp)\n",
    "    # ax.loglog(F_freq/1e6, Bomega_wlv)\n",
    "    # ax.set_xlim([0.06, 2])\n",
    "    # ax.set_ylim([0.06, 1.2])\n",
    "    # ax.set_xlabel(\"Frequency [MHz]\")\n",
    "    # ax.set_ylabel(\"$B(\\omega)$\")\n",
    "    \n",
    "    #------------------------#\n",
    "    # 3. Convolve the attenuation factor to mimic the path effect\n",
    "    #------------------------#\n",
    "    # compute source spectrum\n",
    "    F_STF1 = np.fft.rfft(STF_rec_padded, n=NFFT)\n",
    "    \n",
    "    #1. convolve the attenuation factor\n",
    "    STF_Qconvolved = np.fft.irfft(F_STF1 * Bomega_interp).real\n",
    "    \n",
    "    #------------------------#\n",
    "    # 4. Apply the low-pass filter\n",
    "    #------------------------#\n",
    "    # b, a = signal.butter(butterworth_order, (freqmin, freqmax), 'bandpass', fs=(1/dt_upsampled), output='ba') # not apply band-pass to mitigate acausal signal\n",
    "    b, a = signal.butter(butterworth_order, freqmax, 'lowpass', fs=(1/dt_upsampled), output='ba') #\n",
    "    STF_Qconvolved_filtered = signal.filtfilt(b, a, STF_Qconvolved, method='gust')\n",
    "    \n",
    "    \n",
    "    #------------------------#\n",
    "    # 5. Deconvolve Bomega with water level\n",
    "    #------------------------#\n",
    "    F_STF2 = np.fft.rfft(STF_Qconvolved_filtered, n=NFFT)\n",
    "    STF_Q_deconvolved = np.fft.irfft(F_STF2/Bomega_wlv).real # divide the spectra by the attenuation factor\n",
    "    \n",
    "    #------------------------#\n",
    "    # 6. Fit the cosine STF to estimate the source parameters\n",
    "    #------------------------#\n",
    "    \n",
    "    # process flow:\n",
    "    # 1. remove offset at the LBA\n",
    "    # 2. compute half maximum pulse width to estimate Tw_init\n",
    "    # 3. search the best-fit source parameters\n",
    "      \n",
    "    # pick the LBA as it is\n",
    "    STF_grad = np.gradient(STF_Q_deconvolved)\n",
    "            \n",
    "    # https://stackoverflow.com/a/3843124\n",
    "    zero_crossings = np.where(np.diff(np.sign(STF_grad)) > 0)[0]\n",
    "    min_list = np.array(zero_crossings)\n",
    "    \n",
    "    LBA_ind = min_list[np.where(int((zerowin_pre+LBA_buffer_winlen)/dt_upsampled) - min_list > 0)[0][-1]] # search the first bump of STF;\n",
    "    LBA_amp = STF_Q_deconvolved[LBA_ind]\n",
    "    LBA_t = tvec_dynrup_padded[LBA_ind]\n",
    "    \n",
    "    # remove the offset\n",
    "    STF_Q_deconvolved_offsetremoved = STF_Q_deconvolved-LBA_amp\n",
    "    \n",
    "    # compute Tw_init as the HMPW\n",
    "    pmax = np.max(STF_Q_deconvolved_offsetremoved)\n",
    "    pmax_ind = np.argmax(STF_Q_deconvolved_offsetremoved)\n",
    "    \n",
    "    halfamp = pmax/2\n",
    "    \n",
    "    # search the half pulse width\n",
    "    halfamp_list = np.where(np.diff(np.sign(STF_Q_deconvolved_offsetremoved - halfamp)))[0]\n",
    "    \n",
    "    # for tiny events, skip if we cannot find the LHA or RHA due to low S/N\n",
    "    LHA_ind = halfamp_list[np.where(halfamp_list - pmax_ind < 0)[0][-1]]\n",
    "    RHA_ind = halfamp_list[np.where(halfamp_list - pmax_ind > 0)[0][0]] # set HMPW just below the half-maximum amplitude\n",
    "    HMPW = tvec_dynrup_padded[RHA_ind] - tvec_dynrup_padded[LHA_ind]\n",
    "    Tw_init = 2*HMPW\n",
    "    M0_init = 0.5*np.max(STF_Q_deconvolved_offsetremoved)*Tw_init\n",
    "    Tshift_init = 0.0\n",
    "\n",
    "    # NOTE: The STF of dynamic rupture is narrow. Thus, the HMPW is not enough for the T_init. \n",
    "    # To better and stably fit the cosine STF to the model, we increase the T_init.\n",
    "    # Update: to avoid the jump in the residual during the grid search caused by the dependency of the initial value,\n",
    "    # we iterate to find the global minimum in the fitting.\n",
    "    Tw_init_list = Tw_init * np.linspace(1.0, 1.1, 3)\n",
    "    res_fun_all = []\n",
    "    # Tw_init *= 1.05\n",
    "\n",
    "    for Tw_init_test in Tw_init_list:\n",
    "        x0 = [M0_init, Tw_init_test, Tshift_init]\n",
    "        # print(x0)\n",
    "        \n",
    "        # fit the synthetic STF to the dynamic rupture STF\n",
    "        res_test = minimize(compute_res, x0, args=(STF_Q_deconvolved_offsetremoved, dt_upsampled, pwin_pre, residu_win, stf_type, False), \n",
    "                       method='Nelder-Mead', bounds=bounds, options={\"return_all\": False, \"xatol\":xatol, \"fatol\":fatol, \"maxfev\":1000})\n",
    "        res_fun_all.append(res_test.fun)\n",
    "    \n",
    "    # use Tw_init with minimum residual \n",
    "    Tw_init_best = Tw_init_list[np.argmin(res_fun_all)]\n",
    "    x0 = [M0_init, Tw_init_best, Tshift_init]\n",
    "    res = minimize(compute_res, x0, args=(STF_Q_deconvolved_offsetremoved, dt_upsampled, pwin_pre, residu_win, stf_type, False), \n",
    "                method='Nelder-Mead', bounds=bounds, options={\"return_all\": False, \"xatol\":xatol, \"fatol\":fatol, \"maxfev\":1000})\n",
    "        \n",
    "    # synthesize the estimated STF\n",
    "    M0_best, Tw_best, tshift_best = res.x\n",
    "    # print(Tw_best*1e6)\n",
    "    tvec_syn = np.linspace(0, Tw_best, int(Tw_best/dt_upsampled))\n",
    "    STF_syn = stf_cosine(tvec_syn, Tw_best, M0_best)\n",
    "    \n",
    "    # Debug plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 5.2))\n",
    "    ax.plot(tvec_dynrup_padded*1e6, STF_rec_padded/1e6, label=\"original STF\", c=\"k\", zorder=2)\n",
    "    ax.plot(tvec_dynrup_padded*1e6, STF_Qconvolved/1e6, label=\"Apply B(ω)\", c=lc_debug[0])\n",
    "    ax.plot(tvec_dynrup_padded*1e6, STF_Qconvolved_filtered/1e6, label=f\"Apply lowpass \\nat {freqmax/1e6:.1f}MHz\", c=lc_debug[1])\n",
    "    ax.plot(tvec_dynrup_padded*1e6, STF_Q_deconvolved_offsetremoved/1e6, \"-\", marker=\".\", \n",
    "            label=f\"Deconv B(ω) \\nwith waterlevel at {k_waterlevel:.2f}\", c=\"crimson\")\n",
    "    # ax.xlim([-4, 6])\n",
    "    ax.plot(LBA_t*1e6, 0, \"kv\", ms=6, zorder=5)\n",
    "    ax.plot((tvec_syn+tshift_best)*1e6, STF_syn/1e6, \"--\", label=f\"best-fit {stf_type} STF\", c=\"b\")\n",
    "    # ax.plot(tvec_dynrup_padded[zero_crossings]*1e6, np.zeros(len(tvec_dynrup_padded[zero_crossings])), \"ks\", ms=4)\n",
    "    # ax.axhline(0)\n",
    "    ax.legend(loc=0)\n",
    "    \n",
    "    props = dict(boxstyle='square', facecolor='white', alpha=1.0)\n",
    "    \n",
    "    annot_txt = '\\n'.join((\n",
    "        r'event {}'.format(model_id),\n",
    "        r'$M_0$={:.2f} Nm'.format(M0_best),\n",
    "        r'$T_w$={:.2f} μs'.format(Tw_best*1e6),\n",
    "        r'source dist.={:.1f}mm'.format(sourcedist_average*1e3)))\n",
    "    \n",
    "    ax.text(0.05, 0.9, annot_txt, transform=ax.transAxes, fontsize=11,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    \n",
    "    # ax.set_xlim(np.array([tvec_dynrup_padded[0], tvec_dynrup_padded[-1]]) * 1e6)\n",
    "    ax.set_xlim([-3, 8])\n",
    "    ax.set_xlabel(\"Time [μs]\")\n",
    "    ylabelstr = r\"$\\dot{M}_0$\"\n",
    "    ax.set_ylabel(\"{} [MNm/s]\".format(ylabelstr))\n",
    "    ax.grid(True, c=np.array([230, 230, 230])/255, lw=0.25, zorder=-1, which=\"major\")\n",
    "    ax.set_axisbelow('True')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # plt.savefig(figdir + f\"/dynrupSTFfit_{gougepatch_id}_event{model_id}.png\", dpi=80)\n",
    "    plt.savefig(figdir + f\"/dynrupSTFfit_{gougepatch_id}_event{model_id}{filekey}.pdf\")\n",
    "    # \n",
    "    \n",
    "    # save the best-fit parameters\n",
    "    data = {\"event_id\":[model_id],\n",
    "            \"M0_rec\":[M0_rec[-1]],\n",
    "            \"M0_bestfit\":[M0_best],\n",
    "            \"Tw_bestfit\":[Tw_best],\n",
    "            \"Tshift_bestfit\":[tshift_best]}\n",
    "    \n",
    "    df_param = pd.DataFrame.from_dict(data)\n",
    "    df_dynrup_sourceparam = pd.concat([df_dynrup_sourceparam if not df_dynrup_sourceparam.empty else None, df_param])\n",
    "    \n",
    "    # plt.clf()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1.0, 1.1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_fun_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(res_fun_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tw_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tw_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1428.987180937763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tshift_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynrup_sourceparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the dynamic rupture source parameters to the datasheet\n",
    "df_dynrup_sourceparam.to_csv(f\"../data/dynrup_bestfit_sourceparam_{casestr}{filekey}.csv\", index=False, float_format=\"%12.8g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gougeevent = pd.read_csv(f\"../../../../GougeEventCatalog/data/gougeeventcatalog__fb03-{expr_id:03d}__{gougepatch_id}__Q{Qinv_quart}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvalidsensors_thresh = 4\n",
    "df_gougeevent_selected = df_gougeevent[df_gougeevent[\"Nvalidsensors\"] == Nvalidsensors_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_gougeevent_selected))\n",
    "df_gougeevent_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_mc = sns.color_palette(\"Set1\")\n",
    "scatter_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gougeevent_selected_modelled = df_gougeevent_selected[df_gougeevent_selected[\"event_id\"].isin(model_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute regression\n",
    "colnames = [\"Method\", \"Intercept\", \"Slope\", \"Angle(degrees)\", \"P-perm(1-tailed)\"]\n",
    "df_res = pd.read_csv(\"../../../../ComputeScaling/data/07_loglinearfit/lmodel2_out_regression.txt\", sep=' ',\n",
    "                     names=colnames, skipinitialspace=True, skiprows=1, header=None)\n",
    "df_res = df_res.set_index(\"Method\")\n",
    "fit_method=\"MA\"\n",
    "\n",
    "M0_reg = np.logspace(-3, 1, 101)\n",
    "TR_reg = (10**df_res.loc[fit_method, \"Intercept\"])*(M0_reg**df_res.loc[fit_method, \"Slope\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5.7, 6))\n",
    "\n",
    "scatter_kws0 = {\"s\": 0, \"edgecolors\": \"k\", \"zorder\": 1, \"alpha\": 0.9}\n",
    "scatter_kws1 = {\"s\": 90, \"edgecolors\": \"k\", \"zorder\": 1, \"alpha\": 0.9}\n",
    "line_kws = {\"color\": \"crimson\", \"zorder\": -3}\n",
    "\n",
    "tc = [\"\"]\n",
    "mctype = [\"o\", \"d\", \"s\", \"v\"]\n",
    "\n",
    "labelflag = 0\n",
    "\n",
    "ifPlotMain = True\n",
    "ifPlotModeled = True\n",
    "ifPlotRegression = True\n",
    "\n",
    "# Compute standard error\n",
    "standarderror_factor = np.sqrt(Nvalidsensors_thresh)\n",
    "\n",
    "mainmarkersize = 7\n",
    "\n",
    "if ifPlotMain:\n",
    "    ax.errorbar(df_gougeevent_selected[\"M0\"].values, df_gougeevent_selected[\"Tw\"].values*1e6, \n",
    "            yerr = df_gougeevent_selected[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_gougeevent_selected[\"M0_std\"]/standarderror_factor,\n",
    "            capsize=0, fmt='o', markersize=mainmarkersize, color=scatter_mc[0], lw=1, markeredgecolor = \"black\", label=\"Mean of four AE sensors\", zorder=3)\n",
    "\n",
    "if ifPlotModeled:\n",
    "    ax.errorbar(df_gougeevent_selected_modelled[\"M0\"].values, df_gougeevent_selected_modelled[\"Tw\"].values*1e6, \n",
    "        yerr = df_gougeevent_selected_modelled[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_gougeevent_selected_modelled[\"M0_std\"]/standarderror_factor,\n",
    "        capsize=0, fmt='^', markersize=mainmarkersize, color=scatter_mc[1], lw=1, markeredgecolor = \"black\", label=\"Mean of four AE sensors\", zorder=3)\n",
    "\n",
    "# plot the best-fit regression\n",
    "if ifPlotRegression:\n",
    "    ax.plot(M0_reg, TR_reg, c=scatter_mc[0], lw=1.0, zorder = 2)\n",
    "\n",
    "\n",
    "# Plot scaling of dynamic rupture model\n",
    "ax.plot(df_dynrup_sourceparam[\"M0_bestfit\"].values, df_dynrup_sourceparam[\"Tw_bestfit\"].values*1e6, \"*\", ms=12, mfc=scatter_mc[5], mec=\"k\",\n",
    "        label=\"Dynamic rupture model\", zorder=4)\n",
    "           \n",
    "        # yerr = df_gougeevent_selected[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_gougeevent_selected[\"M0_std\"]/standarderror_factor,\n",
    "        # capsize=0, fmt='o', markersize=mainmarkersize, color=scatter_mc[0], lw=1, markeredgecolor = \"black\", label=\"Mean of four AE sensors\", zorder=3)\n",
    "\n",
    "\n",
    "\n",
    "xlimit_scaling = [0.004, 3] #10] # check 1/3\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(xlimit_scaling)\n",
    "ax.set_ylim([1.5, 3.8]) #10]) # update 2025/1/23 # check 1/3\n",
    "\n",
    "# ax.set_yticks([1, 2, 3, 4])\n",
    "# ax.set_yticklabels([1, 2, 3, 4])\n",
    "ax.set_yticks([2, 3, ]) # update 2025/1/23\n",
    "ax.set_yticklabels([2, 3, ]) # update 2025/1/23\n",
    "\n",
    "ax.set_xlabel(\"$M_0$ [Nm]\")\n",
    "ax.set_ylabel(\"$T_w$ [μs]\")\n",
    "\n",
    "ax.grid(True, c=np.array([230, 230, 230])/255, lw=0.25, zorder=-1)\n",
    "ax.set_axisbelow('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(figdir+f\"/preliminary_dynrupscaling_{casestr}_{nb_x_elements}{filekey}.png\",  dpi=200)\n",
    "plt.savefig(figdir+f\"/preliminary_dynrupscaling_{casestr}_{nb_x_elements}{filekey}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump the data into HDF5\n",
    "\n",
    "We save the data on the time history of $M_0$ and STFs into the HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ifSaveHDF: # save the data only for the master case study\n",
    "    \n",
    "    fo = h5py.File(datadir+f\"/DynrupModelData_{casestr}_{nb_x_elements}{filekey}.hdf5\", 'w')\n",
    "    \n",
    "    fo.create_group(\"param\")\n",
    "    fo.create_dataset(f\"param/tvec_dynrup\", data=df_time[1].values)\n",
    "    fo[f\"param\"].attrs[\"E\"] = E\n",
    "    fo[f\"param\"].attrs[\"nu\"] = nu\n",
    "    fo[f\"param\"].attrs[\"mu\"] = mu\n",
    "    fo[f\"param\"].attrs[\"a_patch\"] = a_patch\n",
    "    fo[f\"param\"].attrs[\"rupturetype\"] = rupturetype\n",
    "    fo[f\"param\"].attrs[\"pdcscaling\"] = pdcscaling\n",
    "    fo[f\"param\"].attrs[\"bgbeta\"] = bgbeta\n",
    "    fo[f\"param\"].attrs[\"nb_x_elements\"] = nb_x_elements\n",
    "    fo[f\"param\"].attrs[\"nb_z_elements\"] = nb_z_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ifSaveHDF:\n",
    "    for model_id in model_ids:\n",
    "    \n",
    "        fo.create_group(f\"dynrup_{model_id:04d}\")\n",
    "    \n",
    "        df_modelparam_selected = df_modelparam[df_modelparam.index == model_id]\n",
    "        simulation_name = f\"fb03-{expr_id:03d}__{df_modelparam_selected.index[0]:04d}_{casestr}_{delsigma_factorstr[f'{model_id}']:.4f}\"\n",
    "        print(f\"{simulation_name}\")\n",
    "        key_t = f\"t_{simulation_name}\"\n",
    "        key_M0 = f\"M0_rec_{simulation_name}\"\n",
    "        key_STF = f\"STF_rec_{simulation_name}\"\n",
    "        key_STF_patch = f\"STF_patch_{simulation_name}\"\n",
    "    \n",
    "        fo.create_dataset(f\"dynrup_{model_id:04d}/M0_rec\", data=data_all[key_M0])\n",
    "        fo.create_dataset(f\"dynrup_{model_id:04d}/STF_rec\", data=data_all[key_STF])\n",
    "        # fo.create_dataset(f\"dynrup_{model_id:04d}/STF_patch\", data=data_all[key_STF_patch])\n",
    "    \n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
