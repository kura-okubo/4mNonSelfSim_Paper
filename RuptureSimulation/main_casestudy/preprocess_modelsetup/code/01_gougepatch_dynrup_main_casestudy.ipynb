{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dynamic rupture modeling of gouge patch: Case study\n",
    "\n",
    "In this notebook we configure the initial conditions of the dynamic rupture modeling associated with the gouge-mediated seismic event.\n",
    "\n",
    "2024.02.12 Kurama Okubo\n",
    "\n",
    "- 2024.02.19 update for linea_coulomb_friction_law\n",
    "- 2024.02.20 update for the contrast between $\\hat{\\tau}_{patch}$ and $\\hat{\\tau}_{background}$ to arrest the rupture.\n",
    "- 2024.02.21 append all the parameter in the input file\n",
    "- 2024.02.22 update for case study 1. $\\tau_r=0$, 2. $\\tau_r=0.6$MPa.\n",
    "- 2024.03.07 update for the case of patch expansion\n",
    "- 2024.03.15 update for master case study\n",
    "- 2024.03.18 update to set dynamic_excess for the case of tau_r=0.6MPa\n",
    "- 2024.03.27 update the patch margin from 0.1 mm to 0.08 mm to harmonize with the grid size of 0.04 mm.\n",
    "- 2024.05.06 update for advanced rupture model: generate the input files for smooth nucleation model and the rapid + stress free model.\n",
    "- 2024.05.15 update for the nucleation by decreasing fp. It did not work, so deprecated.\n",
    "\n",
    "updated v2: master casestudy\n",
    "- 2024.06.11 update to implement master casestudy for the rupture type (crack-like or self-healing pulse-like) and the scaling exponent of Dc.\n",
    "- 2024.09.03 update for the new set of non-self-similar events obtained by the stacking of multiple AE sensor. We also removed the dependency of the Energy budget precalculation.\n",
    "\n",
    "updated v3: master casestudy with the merged catalog\n",
    "- 2024.12.18 update for the new gouge event catalog.\n",
    "- 2025.1.23 update the model with $\\sigma_n$=6MPa.\n",
    "- 2025.1.29 update for the master casestudy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of this notebook\n",
    "\n",
    "This notebook generates the input file for the dynamic rupture simulation with uguca.\n",
    "\n",
    "The parameters to search in the case study is $a_{patch}$, rupture type, and $p$ as the trial scaling exponent of Dc.\n",
    "For the single run of this notebook produces a set of input files with different events with the predefined parameters above.\n",
    "\n",
    "To produce different cases, re-run the notebook with setting different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 4.75\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.75\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"xtick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 4.75\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.75\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"ytick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = \"../figure\"\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data\"\n",
    "if not os.path.exists(datadir):\n",
    "    os.makedirs(datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set case study variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_patch = 4.0e-3 # patch radius without margine\n",
    "rupturetype = \"pulse\" # \"crack\": without self-healing or \"pulse\": with self-healing\n",
    "p_dcscaleexp = 0.6 #0.55 #0.54 #0.56 #0.555  # #0.475 #0.55 #0.575 #0.65 #0.8 #0.65 #0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casestudy_name = f\"a={a_patch*1e3:.2f}_ruptype={rupturetype:s}_pdcscaling={p_dcscaleexp:.3f}\"\n",
    "print(casestudy_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory to derive the model parameters\n",
    "\n",
    "The key parameters are the stress drop and $Dc$, which are unknown due to the causal loop: the \"true\" stress drop and $D_c$ can be estimated from fitting the data to the dynamic rupture simulation, whereas we need first set them to run the simulation. Ideally, the iterative approch can solve this loop. However, it is way too much in our purpose as we already have apriori information on the source paramters. To solve this loop, we set the trial parameters inferred from the gouge patch size and the seismic moment. Note that we set the gouge patch size as the free parameter to answer the question if this affects the conclusions.\n",
    "\n",
    "We set the stress drop as followings:\n",
    "\n",
    "$$ \\bar{ \\Delta \\sigma } _{\\text{try}}^{(i)} = \\dfrac{7}{16} \\dfrac{M_0^{(i)}}{a^3_{\\text{patch}}}, $$\n",
    "\n",
    "where $(i)$ indicates the parameter of the $i$th event. We use $a_{\\text{patch}} = 4.0$ mm + $0.08$ mm of the patch margin for the initial condition.\n",
    "\n",
    "$$ \\bar{u}_{\\text{try}}^{(i)} = \\dfrac{M_0^{(i)}}{\\mu \\pi a^2_{\\text{patch}}} $$\n",
    "\n",
    "where $\\bar{u}_{\\text{try}}^{(i)}$ is the trial averaged slip.\n",
    "\n",
    "We set the initial shear stress as the fraction of peak friction:\n",
    "\n",
    "$$ \\tau_0 = cf_p\\sigma_n, $$\n",
    "\n",
    "where $c$ determines the coefficient of initial traction fraction. Then, we set the $f_p$ as follows:\n",
    "\n",
    "$$ \\Delta\\sigma = cf_p\\sigma_n - f_r\\sigma_n $$\n",
    "$$ f_p = \\dfrac{1}{c}\\left[ \\dfrac{s\\Delta\\sigma}{\\sigma_n} + f_r \\right] $$ \n",
    "\n",
    "Here, $\\Delta\\sigma$ is controlled with the `dynamic_excess`, $s$, as $ \\Delta\\sigma = s \\bar{ \\Delta \\sigma } _{\\text{try}}^{(i)} $ to control the amplitude of STF.\n",
    "\n",
    "To estimate the $D_c$ as follows:\n",
    "\n",
    "$$ D_{c}^{(i)} =  \\dfrac{D_c^{\\text{min}}}{\\min \\left\\{ \\bar{u}_{\\text{try}} \\right\\}^{p} } \\bar{u}_{\\text{try}}^{(i)p},$$\n",
    "\n",
    "$D_c^{\\text{min}}$ indicates the best-fit $D_c$ for the case of minimum gouge event, which we find by trial and error. $p$ is the scaling exponent with the trial slip.\n",
    "\n",
    "When the trial parameters are validated with the observations, i.e., source time functions with non-self-similarity, we can evaluate the \"true\" paramters such as $\\bar{ \\Delta \\sigma } _{\\text{true}}^{(i)}$ and $\\bar{u}_{\\text{true}}^{(i)}$ as well as the true source region $A_{\\text{true}}$.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "The way to define $D_c$ has been updated from our previous work. We used the energy budget such as Dc = (1-$\\eta_R$)$\\bar{u}$, but it has an assumption of the radiated energy inferred from the kinematic source model. As the direct observation of $E_R$ is unstable and difficult, we changed the derivation as described above. In this metric, we consider the increase in the  $\\bar{u}_{\\text{try}}^{(i)p}$ from the $D_c$ to model the minimum event, which we predefine with a emperical constant value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic constant\n",
    "E = 96e9\n",
    "rho = 2980\n",
    "nu = 0.246 # metagabbro\n",
    "mu = E/(2*(1+nu))\n",
    "\n",
    "print(f\"E, mu, rho = {E:.4g} {mu:.4g} {rho:.4g}\")\n",
    "\n",
    "R_patch = a_patch #4e-3 # gouge patch radius \n",
    "R_margin = a_patch+0.08e-3 #4.08e-3 #4.1e-3 #5e-3 # This is the outer bound of the stress margin, used for the input parameter of simulation\n",
    "# R_margin = a_patch\n",
    "\n",
    "# Set the range of average GIIC\n",
    "A_patch = np.pi * R_patch**2\n",
    "\n",
    "hat_sn_patch = 6e6 #8e6 # normal stress on gouge patch\n",
    "hat_sn_background = 2e6 # normal stress on background region\n",
    "\n",
    "hat_fr_patch = 0.3 # fixed the residual friction level as an assumption\n",
    "hat_tau_r_patch = hat_sn_patch * hat_fr_patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recompute case study parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gougepatch_id = \"G3\" # to set output filename\n",
    "denoise_method = \"detrend\"\n",
    "Qinv_quart = 50\n",
    "k_waterlevel = 0.3\n",
    "expr_id = 87\n",
    "\n",
    "foname_mean = f\"../../../../ComputeScaling/data/05_STFstats/SourceParam_meanstd_fb03-{expr_id:03d}_{gougepatch_id}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.csv\"\n",
    "df_stats = pd.read_csv(foname_mean, index_col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qinv_quart = \"50\"\n",
    "NvalidSensor = 4\n",
    "\n",
    "df_stats_selected = df_stats[(df_stats[\"Qinv_quart\"] == Qinv_quart) & (df_stats[\"Nvalidsensors\"] >= NvalidSensor)].copy()\n",
    "df_stats_selected.head()\n",
    "print(f\"Num. event = {len(df_stats_selected)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_selected[\"Tw_mean\"] * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M02Mw(M0):\n",
    "    \"\"\"\n",
    "    convert from M0 to Mw\n",
    "    \"\"\"\n",
    "    return (np.log10(M0) - 9.105) * 2.0 / 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_selected.loc[:, \"Mw_mean\"] = df_stats_selected.apply(lambda x: M02Mw(x.M0_mean), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0_stats = (df_stats_selected['M0_mean'].mean(), df_stats_selected['M0_mean'].std(), df_stats_selected['M0_mean'].min(), df_stats_selected['M0_mean'].max())\n",
    "Mw_stats = (df_stats_selected['Mw_mean'].mean(), df_stats_selected['Mw_mean'].std(), df_stats_selected['Mw_mean'].min(), df_stats_selected['Mw_mean'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"M0 stats: {0[0]:.3f} ± {0[1]:.3f} Nm with the range from {0[2]:.3f} to {0[3]:.3f} Nm.\".format(M0_stats))\n",
    "print(\"Mw stats: {0[0]:.3f} ± {0[1]:.3f} with the range from {0[2]:.3f} to {0[3]:.3f}.\".format(Mw_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe for the dynamic rupture parameters\n",
    "df_dynparam = df_stats_selected[[\"M0_mean\", \"Tw_mean\", \"Mw_mean\"]].copy()\n",
    "df_dynparam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynparam.loc[:, \"hat_sn_patch\"] = hat_sn_patch\n",
    "df_dynparam.loc[:, \"hat_sn_background\"] = hat_sn_background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. compute trial stress drop\n",
    "df_dynparam[\"delsig_withmargin_try\"] = df_dynparam.apply(lambda x: (7/16) * (x.M0_mean/R_margin**3), axis=1)\n",
    "\n",
    "#2. compute trial average slip\n",
    "df_dynparam[\"slip_try\"] = df_dynparam.apply(lambda x: x.M0_mean/(mu * np.pi * R_margin**2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dynparam.sort_values(\"Mw_mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the frictional parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  |  $\\sigma_n$  | $\\tau_0$ | $f_p$ | $f_r$ |\n",
    "| ---- | ---- | ---- | ---- | ---- | \n",
    "| nucleation zone | $\\alpha \\hat{\\sigma}_n$ | Gaussian distribution | $f_p$ | $\\hat{f}_r$ |\n",
    "| gouge patch zone | $\\hat{\\sigma}_n$ | 0.925*$\\tau_p$ | $f_p$ | $\\hat{f}_r$ |\n",
    "| stress margin | 0 | 0 | 0 | 0 |\n",
    "| background region | $\\hat{\\sigma}_n^{background}$ | $\\beta \\tau_r$ | $f_p = \\hat{f}_r$| $\\hat{f}_r$ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Master unirateral + best case\n",
    "\n",
    "R_nuc = 2.5e-3 #1.5e-3 # nucleation radius \n",
    "A_nuc = np.pi * R_nuc**2\n",
    "\n",
    "nuc_x = -(R_patch - R_nuc) #-(0.5*R_patch) # x coordinate of the center of the nucleation area\n",
    "\n",
    "# Parameter of the background zone \n",
    "print(f\"hat_fr_patch={hat_fr_patch}\")\n",
    "hat_fp_background = 0.4 #0.3 # estimated from macroscopic friction value\n",
    "hat_fr_background = 0.4 #0.3\n",
    "\n",
    "nuc_normalstress_alpha = 1.0 # amplication factor of the normal stress on the nucleation zone\n",
    "\n",
    "stressbackground_beta = 0.35 #0.3 #0.4 #0.3 # factor to define the background stress level; this decides the strength of barrier\n",
    "\n",
    "#--- set the self-healing parameter---#\n",
    "if rupturetype==\"crack\":\n",
    "    hat_ds_factor_rapidnuc_nuc = 10000 # factor of slip-strengthening distance in the nucleation zone\n",
    "    hat_ds_factor_rapidnuc_patch =  10000 # factor of slip-strengthening distance in the patch area\n",
    "    \n",
    "elif rupturetype==\"pulse\":\n",
    "    hat_ds_factor_rapidnuc_nuc = 5.5 #5.5  # factor of slip-strengthening distance in the nucleation zone\n",
    "    hat_ds_factor_rapidnuc_patch = 5.5 #5.5 # factor of slip-strengthening distance in the patch area\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"rupturetype {rupturetype} not defined.\")\n",
    "\n",
    "hat_ds_factor_rapidnuc_background = 10000 # to avoid the slip-strengthening for the background region\n",
    "\n",
    "# initialstress_fraction = 0.925 #0.9 #0.9 # initial shear stress is initialstress_fraction*sn*fp\n",
    "\n",
    "c_nucexcess = 0.02 #0.025 #0.015 # #0.05 #0.05 # the percentage of the excess of the initial shear stress tau0_{nuc}^{max} = (1+c)taup\n",
    "\n",
    "casename = casestudy_name+\"_sn={:.1f}MPa_hatfr={:.1f}_bgbeta={:.2f}\".format(hat_sn_patch/1e6, hat_fr_patch, stressbackground_beta)\n",
    "\n",
    "print(casename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set initial stress fraction on the events\n",
    "df_dynparam.loc[:, \"initialstress_fraction\"] = 0.925 #0.875 #0.925\n",
    "\n",
    "\n",
    "# change the initial stress fraction on the small events\n",
    "df_dynparam.loc[24, \"initialstress_fraction\"] = 0.98 #0.94 # large initialstress_fraction \n",
    "\n",
    "# df_dynparam.loc[\"fb03-087__0035\", \"initialstress_fraction\"] = 0.94 #0.925 #0.975\n",
    "\n",
    "\n",
    "# # We unified the initialstress_fraction with different events\n",
    "# if rupturetype==\"pulse\":\n",
    "#     df_dynparam.loc[\"fb03-087__0036\", \"initialstress_fraction\"] = 0.942 #0.945 #0.975 # large initialstress_fraction \n",
    "#     df_dynparam.loc[\"fb03-087__0035\", \"initialstress_fraction\"] = 0.94 #0.925 #0.975\n",
    "\n",
    "\n",
    "# elif rupturetype==\"crack\":\n",
    "\n",
    "#     df_dynparam.loc[\"fb03-087__0036\", \"initialstress_fraction\"] = 0.942 #0.945 #0.975 # large initialstress_fraction \n",
    "#     df_dynparam.loc[\"fb03-087__0035\", \"initialstress_fraction\"] = 0.94 #0.925 #0.975\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynparam.loc[[24, 50, 52, 72, 129], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Compute equivalent delsigma_factor\n",
    "\n",
    "We keep the $D_c^{min}$ with `initialstress_fraction` $c$  = 0.925 with `delsigma_factor` $s$ = 0.7. To keep it, we set the delsigma_factor as follows:\n",
    "\n",
    "\n",
    "$$ D_c^{min} = \\dfrac{2G_{IIC}^{min}}{\\sigma_n \\left[\\dfrac{1}{c}[\\dfrac{s\\Delta \\sigma}{\\sigma_n} + f_r] - f_r\\right]} $$\n",
    "\n",
    "$$s = \\dfrac{\\sigma_n}{\\Delta \\sigma} \\left[ c [\\dfrac{2G_{IIC}^{min}}{D_c^{min}\\sigma_n} + f_r] -f_r \\right] $$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GIICmin = 0.0064519416 # obtained with c=0.925 and s=0.7\n",
    "# Dcmin = 2.3551006e-08\n",
    "# c_min = 0.95\n",
    "\n",
    "# min_gougeid = 128 # gouge event to use as the minimum event in the set of non-self-similar events \n",
    "\n",
    "# df_dcmin = df_dynparam[df_dynparam.index == f\"fb03-087__{min_gougeid:04d}\"]\n",
    "# dcmin_slip = df_dcmin.slip_try.values[0]\n",
    "\n",
    "# delsigma_factor_min_fixed = (df_dcmin.hat_sn_patch/df_dcmin.delsig_withmargin_try) * (c_min * (2*GIICmin / (Dcmin*df_dcmin.hat_sn_patch) + hat_fr_patch) - hat_fr_patch)\n",
    "# print(f\"initalstress_fraction={c_min} corresponds to delsigma_factor = {delsigma_factor_min_fixed.values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set dynamic excess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynparam.loc[:, \"delsigma_factor\"] = 0.6 # initialize the delsigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rupturetype==\"pulse\":\n",
    "    df_dynparam.loc[24, \"delsigma_factor\"] = 0.7\n",
    "    df_dynparam.loc[50, \"delsigma_factor\"] = 0.5\n",
    "    df_dynparam.loc[52, \"delsigma_factor\"] = 0.455\n",
    "    df_dynparam.loc[72, \"delsigma_factor\"] = 0.425\n",
    "    df_dynparam.loc[129, \"delsigma_factor\"] = 0.405\n",
    "\n",
    "elif rupturetype==\"crack\":\n",
    "    df_dynparam.loc[24, \"delsigma_factor\"] = 0.7\n",
    "    df_dynparam.loc[50, \"delsigma_factor\"] = 0.5\n",
    "    df_dynparam.loc[52, \"delsigma_factor\"] = 0.455\n",
    "    df_dynparam.loc[72, \"delsigma_factor\"] = 0.425\n",
    "    df_dynparam.loc[129, \"delsigma_factor\"] = 0.405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_p$ is determined as follows:\n",
    "\n",
    "$$ f_p = \\dfrac{1}{c}\\left[ \\dfrac{s\\Delta\\sigma}{\\sigma_n} + f_r \\right] $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute fp_patch\n",
    "# df_dynparam.loc[:, \"fp_patch\"] = df_dynparam.apply(lambda x: (dynamic_excess*x.delsig_withmargin_try/hat_sn_patch) + hat_fr_patch, axis=1)\n",
    "# df_dynparam.loc[:, \"fp_patch\"] = df_dynparam.apply(lambda x: ((dynamic_excess*x.delsig_withmargin_try/hat_sn_patch) + hat_fr_patch)/initialstress_fraction, axis=1)\n",
    "# df_dynparam.loc[:, \"fp_patch\"] = df_dynparam.apply(lambda x: ((x.delsigma_factor*x.delsig_withmargin_try/hat_sn_patch) + hat_fr_patch)/initialstress_fraction, axis=1) # flexible \n",
    "df_dynparam.loc[:, \"fp_patch\"] = df_dynparam.apply(lambda x: ((x.delsigma_factor*x.delsig_withmargin_try/hat_sn_patch) + hat_fr_patch)/x.initialstress_fraction, axis=1) # variable initialstress_fraction  \n",
    "\n",
    "df_dynparam.loc[:, \"hat_fr\"] = hat_fr_patch\n",
    "df_dynparam.loc[:, \"hat_fp_background\"] = hat_fp_background\n",
    "df_dynparam.loc[:, \"hat_fr_background\"] = hat_fr_background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dynparam.plot.scatter(x=\"M0_mean\", y=\"fp_patch\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. compute dc\n",
    "\n",
    "# compute u_min and dc_min\n",
    "min_gougeid = 24 # gouge event to use as the minimum event in the set of non-self-similar events \n",
    "\n",
    "df_dcmin = df_dynparam[df_dynparam.index == min_gougeid]\n",
    "dcmin_slip = df_dcmin.slip_try.values[0]\n",
    "print(f\"min utry = {dcmin_slip*1e6:.3g} μm.\")\n",
    "# dc_min = 1e-07 # 9.42e-8 we found the best-fit minimum dc by trial and error inferred from kinematic source energy based values;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynparam[df_dynparam.index == min_gougeid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dc_min from fracture energy scaling\n",
    "# load the data\n",
    "sei_types={'Reference M0, a':'category'}\n",
    "df_seis = pd.read_csv('../../../../Others/EnergyBudget/fracture_energy/merged_data-seismology.csv',sep=';',encoding='cp1252',dtype=sei_types)\n",
    "\n",
    "df_m2014 = df_seis[df_seis[\"Reference M0, a\"] == 'McLaskey et al., 2014']\n",
    "df_s2019 = df_seis[df_seis[\"Reference M0, a\"] == 'Selvadurai, 2019']\n",
    "df_y2014 = df_seis[df_seis[\"Reference M0, a\"] == 'Yoshimitsu et al., 2014']\n",
    "df_s2003 = df_seis[df_seis[\"Reference M0, a\"] == 'Sellers et al., 2003']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update: the estimation of $G_{IIC}^{syn}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ G_{IIC}^{syn} (\\delta) = 10^{p_0 + p_1 \\log_{10}\\delta} $$\n",
    "\n",
    "We decrease the synthetic slope of $G_{IIC}$ as follows:\n",
    "$$ G_{IIC}^{syn, modified} (\\delta) = c 10^{p_0 + p_1 \\log_{10} \\delta } $$\n",
    "$$ \\log_{10} G_{IIC}^{syn, modified} (\\delta) = \\log_{10} c + p_0 + p_1 \\log_{10}\\delta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# use the references with the rock sample\n",
    "slip_all = []\n",
    "GIIC_all = []\n",
    "for i, df in enumerate([df_s2003, df_m2014, df_y2014]):\n",
    "    df = df[df[\"value (J/m^2)\"].astype(float)>0] # select positive GIIC \n",
    "    slip_all = np.append(slip_all,  df[\"value (m)\"].astype(float))\n",
    "    GIIC_all = np.append(GIIC_all,  df[\"value (J/m^2)\"].astype(float))\n",
    "\n",
    "# regression with the scaling model\n",
    "# ref: https://stackoverflow.com/a/3433503\n",
    "\n",
    "popt, pcov = curve_fit(lambda x,a,b: a+b*x ,  np.log10(slip_all),  np.log10(GIIC_all),  p0=(1, 2))\n",
    "\n",
    "# UPDATE: decrease the interseption of slope to reproduce the smallest event\n",
    "GIIC_slope_intercept_factor = 0.425 #0.6 # 0.9\n",
    "\n",
    "popt[0] += np.log10(GIIC_slope_intercept_factor)\n",
    "\n",
    "slip_syn = np.logspace(-8, -6, 11)\n",
    "\n",
    "GIIC_syn = 10**(popt[0] + popt[1]*np.log10(slip_syn))\n",
    "\n",
    "\n",
    "# define the function to estimate GIIC from scaling\n",
    "def get_GIIC(slp):\n",
    "    return 10**(popt[0] + popt[1]*np.log10(slp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dcmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_min = 2*get_GIIC(dcmin_slip) / ((df_dcmin.fp_patch-df_dcmin.hat_fr)*df_dcmin.hat_sn_patch)\n",
    "print(f\"GIIC min: {get_GIIC(dcmin_slip):12.8g}, dc min: {dc_min.values[0]:12.8g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. compute dc\n",
    "df_dynparam[\"dc_try\"] = df_dynparam.apply(lambda x: (dc_min/dcmin_slip**p_dcscaleexp) * (x.slip_try)**p_dcscaleexp, axis=1)\n",
    "df_dynparam[\"hat_ds_factor_rapidnuc_nuc\"] = hat_ds_factor_rapidnuc_nuc\n",
    "df_dynparam[\"hat_ds_factor_rapidnuc_patch\"] = hat_ds_factor_rapidnuc_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dynparam[\"dc_try\"].sort_values() * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot debug Dc distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "ax.plot(df_dynparam[\"slip_try\"]*1e6, df_dynparam[\"dc_try\"].values*1e6, \"o\", c=\"k\", alpha=0.5)\n",
    "\n",
    "# ax.text(0.02, 0.5, f\"log slope={popt[1]:.3g}\")\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Slip [μm]\")\n",
    "ax.set_ylabel(\"Dc [μm]\")\n",
    "\n",
    "# ax.set_xlim([1e-3, 1])\n",
    "# ax.set_ylim([1e-3, 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test = 2.4e-3\n",
    "a_test**3/a_patch**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot debug for the estimation of minimum Dc and GIIC\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "ax.plot(slip_all*1e6, GIIC_all, \"o\", c=\"gray\", alpha=0.5)\n",
    "ax.plot(slip_syn*1e6, GIIC_syn, \"k-\")\n",
    "\n",
    "for index, df in df_dynparam.iterrows():\n",
    "    ax.plot(df.slip_try*1e6, 0.5*df.dc_try*((df.fp_patch-df.hat_fr)*df.hat_sn_patch), \"o-\", mfc=\"blue\", mec=\"k\", ms=5)\n",
    "    \n",
    "ax.plot(dcmin_slip*1e6, 0.5*dc_min*((df_dcmin.fp_patch-df_dcmin.hat_fr)*df_dcmin.hat_sn_patch), \"*\", mfc=\"yellow\", mec=\"k\", ms=20)\n",
    "\n",
    "ax.text(0.02, 0.5, f\"log slope={popt[1]:.3g}\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Slip [μm]\")\n",
    "ax.set_ylabel(\"Fracture energy [J/m$^2$]\")\n",
    "\n",
    "ax.set_xlim([1e-3, 1])\n",
    "ax.set_ylim([1e-5, 0.5e1])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../figure/debug_minDc_fitting.png\", dpi=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commpute the other model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_GIIC(dc, fp, fr, sn):\n",
    "    return 0.5*dc*(fp-fr)*sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak and residual frictional resistance for the cohesive law\n",
    "# the friction coefficient is same between nuc and patch even for the rapid nucleation model\n",
    "df_dynparam.loc[:, \"tau_c_nuc\"] = df_dynparam.apply(lambda x: x.fp_patch*(hat_sn_patch*nuc_normalstress_alpha), axis=1) # same fp as the patch\n",
    "df_dynparam.loc[:, \"tau_r_nuc\"] = hat_fr_patch * (hat_sn_patch * nuc_normalstress_alpha) # same fr as the patch\n",
    "\n",
    "df_dynparam.loc[:, \"tau_c_patch\"] = df_dynparam.apply(lambda x: x.fp_patch*hat_sn_patch, axis=1)\n",
    "df_dynparam.loc[:, \"tau_r_patch\"] = hat_fr_patch*hat_sn_patch\n",
    "\n",
    "df_dynparam.loc[:, \"tau_c_background\"] = hat_fp_background * hat_sn_background\n",
    "df_dynparam.loc[:, \"tau_r_background\"] = hat_fr_background * hat_sn_background\n",
    "                  \n",
    "# Initial stress state\n",
    "# df_dynparam.loc[:, \"tau_0_nuc\"] = df_dynparam.apply(lambda x: x.tau_c_patch*initialstress_fraction*(1+c_nucexcess), axis=1) # we control the stress in the nucleation area by gaussian distribution with 'c_nucexcess'\n",
    "df_dynparam.loc[:, \"tau_0_nuc\"] = df_dynparam.apply(lambda x: x.tau_c_patch*x.initialstress_fraction*(1+c_nucexcess), axis=1) # \n",
    "# df_dynparam.loc[:, \"tau_0_patch\"] = df_dynparam.apply(lambda x: x.tau_c_patch*initialstress_fraction, axis=1)\n",
    "df_dynparam.loc[:, \"tau_0_patch\"] = df_dynparam.apply(lambda x: x.tau_c_patch*x.initialstress_fraction, axis=1)\n",
    "df_dynparam.loc[:, \"tau_0_background\"] = stressbackground_beta * hat_fr_background * hat_sn_background # for stress-free model, we investigate this value to arrest the rupture by the positive stress drop \n",
    "\n",
    "# Compute fracture energy\n",
    "df_dynparam.loc[:, \"GIIC_nuc\"] = df_dynparam.apply(lambda x: compute_GIIC(x.dc_try, x.fp_patch, hat_fr_patch, (hat_sn_patch*nuc_normalstress_alpha)), axis=1) # Dc is same as the value in patch \n",
    "df_dynparam.loc[:, \"GIIC_patch\"] = df_dynparam.apply(lambda x: compute_GIIC(x.dc_try, x.fp_patch, hat_fr_patch, hat_sn_patch), axis=1)\n",
    "df_dynparam.loc[:, \"GIIC_background\"] = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute critical nucleation size in nucleation area and patch region\n",
    "We compute the critical nucleation size of 3D fault with the linear slip weakening law From Galis et al. (2014) as follows:\n",
    "\n",
    "$$A_{init} = 1.75 S^{2.81} + 3.82 $$\n",
    "\n",
    "$$ A_{init} = A_i / L_{fric}^2 $$\n",
    "\n",
    "$$L_{fric} = \\mu D_c / (\\tau_s - \\tau_d) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_Sratio(taup, taur, tau0):\n",
    "    return (taup-tau0)/(tau0-taur)\n",
    "    \n",
    "def compute_Ainit(S):\n",
    "    return 1.75*(S**2.81) + 3.82\n",
    "\n",
    "def compute_Anuc(Ainit, mu, Dc, tptd):\n",
    "    return Ainit*((mu*Dc) / (tptd))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Sratio\n",
    "df_dynparam.loc[:, \"Sratio_nuc\"] = 0 # assume tau0 = taup  as it is in critical state\n",
    "df_dynparam.loc[:, \"Sratio_patch\"] = df_dynparam.apply(lambda x: compute_Sratio(x.tau_c_patch, x.tau_r_patch, x.tau_0_patch), axis=1)\n",
    "\n",
    "# compute Ainit\n",
    "df_dynparam.loc[:, \"Ainit_nuc\"] =  df_dynparam.apply(lambda x: compute_Ainit(x.Sratio_nuc), axis=1)\n",
    "df_dynparam.loc[:, \"Ainit_patch\"] = df_dynparam.apply(lambda x: compute_Ainit(x.Sratio_patch), axis=1)\n",
    "\n",
    "# compute Anuc\n",
    "df_dynparam.loc[:, \"Anuc_nuc\"] =  df_dynparam.apply(lambda x: compute_Anuc(x.Ainit_nuc, mu, x.dc_try, (x.tau_c_nuc - x.tau_r_nuc)), axis=1)\n",
    "df_dynparam.loc[:, \"Anuc_patch\"] = df_dynparam.apply(lambda x: compute_Anuc(x.Ainit_patch, mu, x.dc_try, (x.tau_c_patch - x.tau_r_patch)), axis=1)\n",
    "\n",
    "# compute rnuc\n",
    "df_dynparam.loc[:, \"rnuc_nuc\"] =  df_dynparam.apply(lambda x: np.sqrt(x.Anuc_nuc/np.pi), axis=1) * 1e3\n",
    "df_dynparam.loc[:, \"rnuc_patch\"] = df_dynparam.apply(lambda x: np.sqrt(x.Anuc_patch/np.pi), axis=1) * 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "df_dynparam.plot.scatter(x=[\"M0_mean\"], y=[\"rnuc_patch\"], ylabel=\"mm\", ax=ax, label=\"patch\")\n",
    "df_dynparam.plot.scatter(x=[\"M0_mean\"], y=[\"rnuc_nuc\"], ylabel=\"mm\", ax=ax, c=\"r\", label=\"nuc\")\n",
    "ax.axhline(R_nuc*1e3, c=\"k\", ls=\"--\")\n",
    "\n",
    "ax.set_ylim([0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsize_hpc = 0.041015625 #[mm]\n",
    "NgridperLc = df_dynparam.loc[129, \"rnuc_patch\"]/gridsize_hpc\n",
    "NgridperLc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the amplitude of $f_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dynparam_sorted = df_dynparam.sort_values(\"fp_patch\").copy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4.5))\n",
    "ax.plot(df_dynparam_sorted.M0_mean, df_dynparam_sorted.fp_patch, marker=\"o\", c=\"k\", ls=\"\", ms=9, )\n",
    "\n",
    "# locs, _ = plt.xticks()\n",
    "# xlabels_all = [int(x.split('__')[1]) for x in df_modelparam.index]\n",
    "# plt.xticks(locs, xlabels_all)\n",
    "plt.axhline(1.0, c=\"k\", ls=\"--\")\n",
    "\n",
    "M0str = r\"M$_{\\mathrm{0}}$\"\n",
    "\n",
    "ax.set_xlabel('{} [Nm]'.format(M0str))\n",
    "ax.set_ylabel(r\"Peak friction coefficient $f_p$\")\n",
    "\n",
    "ax.tick_params(axis='x', which='major', pad=5)\n",
    "\n",
    "ax.set_xlim([0, 1.4]);\n",
    "ax.set_ylim([0, 1.5]);\n",
    "\n",
    "ax.grid(True, which=\"major\", c=np.array([230, 230, 230])/255, lw=0.25, zorder=-1)\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()\n",
    "\n",
    "# plt.savefig(figdir + f\"/peakfrictioncoef_allevents_{casename}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "# ax.set_title(\"all the events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other model parameters related to the computation\n",
    "alpha_domain = 10 # 10 # computational domain size is alpha_domain times larger than radius of gauge\n",
    "nb_elements = 128 # #256 # number of grids per length; we set same for both x and z directions.\n",
    "\n",
    "# location of the center of nucleation zone\n",
    "nuc_z = 0\n",
    "\n",
    "# duration and time stepping\n",
    "duration = 8e-6 #10e-6 \n",
    "tsf = 0.3 # factor of the critical time step\n",
    "\n",
    "char_reg_time = 0.0 #regularization time of normal stress for the case of linear coulomb friction law\n",
    "\n",
    "# dumping\n",
    "dump_fields = \"cohesion_0,cohesion_1,cohesion_2,top_disp_0,top_disp_1,top_disp_2,top_velo_0,top_velo_1,top_velo_2,G_c,tau_c,tau_r,mu_s,mu_k,d_c,load_0,load_1,load_2\" # no space\n",
    "# dump_fields = \"cohesion_0,top_disp_0,top_velo_0\" # for HPC\n",
    "\n",
    "# compute the total time step\n",
    "cs = np.sqrt(mu/rho)\n",
    "dx = float(R_patch*alpha_domain/nb_elements)\n",
    "dt_cfl = tsf*dx/cs\n",
    "Ntimestep = int(duration/dt_cfl)\n",
    "print(dt_cfl, Ntimestep)\n",
    "\n",
    "# we control the output frequency by the dt_dump\n",
    "dt_dump = 2e-8 # [s] output sampling rate: dump data every dt_dump\n",
    "\n",
    "nb_dumps = int(np.ceil(Ntimestep/(dt_dump/dt_cfl)))\n",
    "nb_dumps, int(Ntimestep/nb_dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynparam[\"fp_patch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynparam.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfileoutdir = f\"../../../../../4mNonSelfSim_UGUCA/dev_simulations_main_casestudy/gouge_rupture_inputfiles_{casestudy_name}\"\n",
    "# remove the previous case study\n",
    "if os.path.exists(inputfileoutdir):\n",
    "    shutil.rmtree(inputfileoutdir)\n",
    "\n",
    "if not os.path.exists(inputfileoutdir):\n",
    "    os.makedirs(inputfileoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of parameters\n",
    "def generate_paramin_rapidnuc(df_model):\n",
    "    param_in = []\n",
    "    param_in.append(f\"# The gouge patch dynamic rupture input file generated at {datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\\n\")\n",
    "    param_in.append(\"string simulation_id = fb03-087__{:04d}_{:s}\\n\".format(df_model.name, casename))\n",
    "    \n",
    "    param_in.append(\"\\n# Computational domain size\\n\")\n",
    "    param_in.append(\"double x_length = {:12.8e}\\n\".format(R_patch*alpha_domain))\n",
    "    param_in.append(\"double z_length = {:12.8e}\\n\".format(R_patch*alpha_domain))\n",
    "    \n",
    "    param_in.append(\"int nb_x_elements = {:d}\\n\".format(nb_elements))\n",
    "    param_in.append(\"int nb_z_elements = {:d}\\n\".format(nb_elements))\n",
    "    \n",
    "    # External loading\n",
    "    param_in.append(\"\\n# External loading\\n\")\n",
    "    param_in.append(\"double sn_nuc = {:12.8e}\\n\".format(-hat_sn_patch*nuc_normalstress_alpha)) # sign convention is positive in opening\n",
    "    param_in.append(\"double sn_patch = {:12.8e}\\n\".format(-hat_sn_patch))\n",
    "    param_in.append(\"double sn_background = {:12.8e}\\n\".format(-hat_sn_background))\n",
    "    \n",
    "#     param_in.append(\"double tau_nuc = {:12.8e}\\n\".format(df_model.tau_0_nuc))\n",
    "    param_in.append(\"double tau_patch = {:12.8e}\\n\".format(df_model.tau_0_patch))\n",
    "    param_in.append(\"double tau_background = {:12.8e}\\n\".format(df_model.tau_0_background))\n",
    "    \n",
    "    param_in.append(\"\\n# Material constants\\n\")\n",
    "    param_in.append(\"double E_top = {:12.8e}\\n\".format(E))\n",
    "    param_in.append(\"double nu_top = {:12.8e}\\n\".format(nu))\n",
    "    param_in.append(\"double rho_top = {:12.8e}\\n\".format(rho))\n",
    "    \n",
    "    # Frictional parameters; uniform GIIC in the patch\n",
    "    param_in.append(\"\\n# Frictional parameters\\n\")\n",
    "    param_in.append(\"double Gc_nuc = {:12.8e}\\n\".format(df_model.GIIC_nuc))\n",
    "    param_in.append(\"double tau_c_nuc = {:12.8e}\\n\".format(df_model.tau_c_nuc))\n",
    "    param_in.append(\"double tau_r_nuc = {:12.8e}\\n\".format(df_model.tau_r_nuc))\n",
    "    \n",
    "    param_in.append(\"double Gc_patch = {:12.8e}\\n\".format(df_model.GIIC_patch))\n",
    "    param_in.append(\"double tau_c_patch = {:12.8e}\\n\".format(df_model.tau_c_patch))\n",
    "    param_in.append(\"double tau_r_patch = {:12.8e}\\n\".format(df_model.tau_r_patch))\n",
    "    \n",
    "#     param_in.append(\"double Gc_background = {:12.8e}\\n\".format(df_model.GIIC_patch)) # To avoid the zero division, we set the same GIIC as the patch; not used in the simulation with Coulomb's law\n",
    "    param_in.append(\"double tau_c_background = {:12.8e}\\n\".format(df_model.tau_c_background))\n",
    "    param_in.append(\"double tau_r_background = {:12.8e}\\n\".format(df_model.tau_r_background))\n",
    "    \n",
    "    param_in.append(\"double dc_nuc = {:12.8e}\\n\".format(df_model.dc_try)) # same as the patch\n",
    "    param_in.append(\"double ds_nuc = {:12.8e}\\n\".format(hat_ds_factor_rapidnuc_nuc * df_model.dc_try))\n",
    "#     param_in.append(\"double ds_nuc = {:12.8e}\\n\".format(hat_ds_nuc))\n",
    "    param_in.append(\"double fp_nuc = {:12.8e}\\n\".format(df_model.fp_patch)) # same as the fp patch, which is modified when using fp Gaussian nucleation\n",
    "#     param_in.append(\"double fr_nuc = {:12.8e}\\n\".format(df_model.hat_fr/nuc_normalstress_alpha)) # after the nucleation, stress drop is same level with the patch domain #(df_model.hat_fr))\n",
    "    param_in.append(\"double fr_nuc = {:12.8e}\\n\".format(df_model.hat_fr)) # set same fr as the patch\n",
    "  \n",
    "    param_in.append(\"double dc_patch = {:12.8e}\\n\".format(df_model.dc_try))\n",
    "    param_in.append(\"double ds_patch = {:12.8e}\\n\".format(hat_ds_factor_rapidnuc_patch * df_model.dc_try))\n",
    "#     param_in.append(\"double ds_patch = {:12.8e}\\n\".format(hat_ds_patch))\n",
    "    param_in.append(\"double fp_patch = {:12.8e}\\n\".format(df_model.fp_patch))\n",
    "    param_in.append(\"double fr_patch = {:12.8e}\\n\".format(df_model.hat_fr))\n",
    "    \n",
    "    param_in.append(\"double dc_background = {:12.8e}\\n\".format(df_model.dc_try)) # need to be non-zero to avoid zero devision\n",
    "    param_in.append(\"double ds_background = {:12.8e}\\n\".format(hat_ds_factor_rapidnuc_background * df_model.dc_try))\n",
    "    # param_in.append(\"double dc_background = {:12.8e}\\n\".format(100*df_model.dc_try)) # need to be non-zero to avoid zero devision\n",
    "    # param_in.append(\"double ds_background = {:12.8e}\\n\".format(100*hat_ds_factor_rapidnuc_background * df_model.dc_try))\n",
    "    param_in.append(\"double fp_background = {:12.8e}\\n\".format(df_model.hat_fp_background)) #### peak is same as redisual in background\n",
    "    param_in.append(\"double fr_background = {:12.8e}\\n\".format(df_model.hat_fr_background))\n",
    "    \n",
    "\n",
    "    # patch sizes\n",
    "    param_in.append(\"\\n# Patch sizes and locations\\n\")\n",
    "    param_in.append(\"double R_nuc = {:12.8e}\\n\".format(R_nuc)) # sign convention is positive in opening\n",
    "    param_in.append(\"double R_patch = {:12.8e}\\n\".format(R_patch))\n",
    "    param_in.append(\"double R_margin = {:12.8e}\\n\".format(R_margin))\n",
    "    \n",
    "    param_in.append(\"double nuc_x = {:12.8e}\\n\".format(nuc_x))\n",
    "    param_in.append(\"double nuc_z = {:12.8e}\\n\".format(nuc_z))\n",
    "\n",
    "    param_in.append(\"double c_nucexcess = {:12.8e}\\n\".format(c_nucexcess))\n",
    "#     param_in.append(\"double alpha_fpnuc = {:12.8e}\\n\".format(alpha_fpnuc)) \n",
    "#     param_in.append(\"double c_fpnuc = {:12.8e}\\n\".format(c_fpnuc))\n",
    "\n",
    "    # simulation parameters\n",
    "    param_in.append(\"\\n# Simulation parameters\\n\")\n",
    "    param_in.append(\"double duration = {:12.8e}\\n\".format(duration))\n",
    "    param_in.append(\"double tsf = {:12.8e}\\n\".format(tsf))\n",
    "    param_in.append(\"double char_reg_time= {:12.8e}\\n\".format(char_reg_time))\n",
    "    \n",
    "    param_in.append(\"string dump_fields = {:s}\\n\".format(dump_fields))\n",
    "    param_in.append(\"int nb_dumps = {:d}\\n\".format(nb_dumps))\n",
    "\n",
    "    return param_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select some cases for preliminary result\n",
    "selectids = [24, 50, 52, 72, 129] # New set of non-self-similar events with merged event catalog.\n",
    "# selectids = [50, 52, 72, 129] # New set of non-self-similar events with merged event catalog.\n",
    "# selectids = [24] # New set of non-self-similar events with merged event catalog.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_model in df_dynparam.iterrows():\n",
    "    if i not in selectids:\n",
    "        # print(i)\n",
    "        continue\n",
    "        \n",
    "    foname = inputfileoutdir+f\"/rupgougepatch_fb03-{expr_id:03d}__{df_model.name:04d}_{casename}.in\"\n",
    "    print(f\"output {foname}\")\n",
    "#     param_in = generate_paramin(df_model)\n",
    "#     param_in = generate_paramin_linear_coulomb_friction_law(df_model)\n",
    "    param_in = generate_paramin_rapidnuc(df_model)\n",
    "    # output file\n",
    "    with open(foname, \"w\") as fo:\n",
    "        fo.writelines(param_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the csv file\n",
    "df_dynparam.to_csv(f\"../data/gouge_dynamicrupture_modelparam_{casename}_dev.csv\", float_format=\"%12.8e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
