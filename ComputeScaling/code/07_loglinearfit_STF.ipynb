{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot scaling with the histogram of the duration\n",
    "\n",
    "Plot the stats of the moment-duration diagram with the log-linear fitting to show the non-self-similarity.\n",
    "\n",
    "2024.11.28 Kurama Okubo\n",
    "\n",
    "- 2024.11.30 update for the log linear fitting\n",
    "- 2024.12.3 update for the fitting with log linear function.\n",
    "- 2025.1.31 update plot dynamic rupture result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import obspy\n",
    "from obspy import read, Stream, Trace\n",
    "from scipy import signal, stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import FixedLocator\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mpmath as mp\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit  \n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import seaborn as sns \n",
    "from scipy.interpolate import LSQUnivariateSpline\n",
    "from scipy import integrate\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "import h5py # store the STF in hdf5\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from shapely.geometry import Point # use to find the data in the interval\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "\n",
    "from STFfit_func import *\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 4.75\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.75\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"xtick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 4.75\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.75\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"ytick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = False #True\n",
    "plt.rcParams['axes.linewidth'] = 0.75\n",
    "\n",
    "from obspy.core.utcdatetime import UTCDateTime  \n",
    "os.environ['TZ'] = 'GMT' # change time zone to avoid confusion in unix_tvec conversion\n",
    "UTCDateTime.DEFAULT_PRECISION = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/07_loglinearfit/\"\n",
    "if not os.path.exists(datadir):\n",
    "    os.makedirs(datadir)\n",
    "\n",
    "figdir = \"../figure/07_loglinearfit/\"\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the STF stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gougepatch_id = \"G3\" # to set output filename\n",
    "denoise_method = \"detrend\"\n",
    "Qinv_quart = 50\n",
    "k_waterlevel = 0.3\n",
    "\n",
    "# fo = h5py.File(f\"../data/03_computePdisp/STF_all_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.hdf5\", 'r+')\n",
    "\n",
    "expr_id = 87\n",
    "foname_all = f\"../data/05_STFstats/SourceParam_allsensors_fb03-{expr_id:03d}_{gougepatch_id}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.csv\"\n",
    "df_sourceparam = pd.read_csv(foname_all, index_col=0)\n",
    "\n",
    "foname_mean = f\"../data/05_STFstats/SourceParam_meanstd_fb03-{expr_id:03d}_{gougepatch_id}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.csv\"\n",
    "df_stats = pd.read_csv(foname_mean, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the stats rows\n",
    "Nvalidsensors_thresh = 4\n",
    "\n",
    "df_stats_case = df_stats[(df_stats[\"Qinv_quart\"] == f\"{Qinv_quart}\") & (df_stats[\"Nvalidsensors\"] >= Nvalidsensors_thresh)].copy()\n",
    "\n",
    "df_stats_case[\"Tw_microsec\"] = df_stats_case[\"Tw_mean\"]*1e6\n",
    "df_stats_case\n",
    "df_stats_case = df_stats_case.set_index(\"gougeevent_id\")\n",
    "# remove the events near the measurement limitation\n",
    "remove_eventlist = [118, 126]\n",
    "df_stats_case_droplim = df_stats_case.drop(index = remove_eventlist) # events without limit events\n",
    "df_stats_case_limevent = df_stats_case.loc[remove_eventlist, :] # removed events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case_limevent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the case without Q correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_noQcorr = df_stats[df_stats[\"Qinv_quart\"] == \"noQcorr\"].copy()\n",
    "# synchronize the events with the Q corrected case\n",
    "case_inds = [x in df_stats_case.index.values for x in df_stats_noQcorr[\"gougeevent_id\"]]\n",
    "df_stats_noQcorr = df_stats_noQcorr.loc[case_inds, :]\n",
    "df_stats_noQcorr[\"Tw_microsec\"] = df_stats_noQcorr[\"Tw_mean\"]*1e6\n",
    "assert (df_stats_noQcorr.gougeevent_id == df_stats_case.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for log-linear fitting\n",
    "\n",
    "It causes the difference with the curve fit to the linear scaled data with $y = c x^{\\alpha}$ and $\\log{y} = \\log{c} + \\alpha\\log{x}$. We selected the fitting with the latter form as follows:\n",
    "\n",
    "$$ Y = \\beta + \\alpha X, $$\n",
    "$Y = \\log{y}$, $\\beta = \\log{c}$, $X = \\log{x}$. Then, \n",
    "$$ y = c x ^ {\\alpha} $$\n",
    "\n",
    "$y = T_R$ and $x = M_0$ in our application. \n",
    "\n",
    "We estimate $\\alpha$ and $\\beta$ by the fitting.\n",
    "\n",
    "See also https://stackoverflow.com/questions/64632563/difference-between-exponential-fit-and-log-linear-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case_droplim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = np.log10(df_stats_case_droplim[\"Tw_mean\"].values)\n",
    "Y = np.log10(df_stats_case_droplim[\"Tw_microsec\"].values)\n",
    "X = np.log10(df_stats_case_droplim[\"M0_mean\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, Y, \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the data\n",
    "\n",
    "We dump the data to perform type II linear regression using `lmodel2` in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tofit = pd.DataFrame(data=[X, Y], index=[\"X\", \"Y\"]).T\n",
    "data_tofit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tofit.to_csv(datadir+f\"/logfitdata_fb03-{expr_id:03d}_{gougepatch_id}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.csv\",\n",
    "                  index=False, float_format='%12.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the R script\n",
    "\n",
    "move to `ComputeScaling/code` using `setwd()` and run `source('R07_compute_loglinfit.R')` to perform the major axis fitting. Note that SMA/RMA normalize the M0 and Tw range to be std of 1, which may be inappropriate for our use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dumped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\"Method\", \"Intercept\", \"Slope\", \"Angle(degrees)\", \"P-perm(1-tailed)\"]\n",
    "df_res = pd.read_csv(\"../data/07_loglinearfit/lmodel2_out_regression.txt\", sep=' ',\n",
    "                     names=colnames, skipinitialspace=True, skiprows=1, header=None)\n",
    "# change the column name as angle includes a white space\n",
    "\n",
    "df_conf = pd.read_csv(\"../data/07_loglinearfit/lmodel2_out_confidence.txt\", sep=' ', skipinitialspace=True)\n",
    "df_res = df_res.set_index(\"Method\")\n",
    "df_conf = df_conf.set_index(\"Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_method=\"MA\"\n",
    "fit_slope = df_res.loc[fit_method, \"Slope\"]\n",
    "fit_slope_low = df_conf.loc[fit_method, \"2.5%-Slope\"]\n",
    "fit_slope_high = df_conf.loc[fit_method, \"97.5%-Slope\"]\n",
    "fit_slope_err = (fit_slope_high - fit_slope_low)/2\n",
    "print(f\"slope with major axis regression is {fit_slope:.4f} ± {fit_slope_err:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_difference_ratio = (1-df_res.loc[\"OLS\", \"Slope\"]/df_res.loc[\"MA\", \"Slope\"])*100\n",
    "print(f\"Fitting slope difference between OLS and MA is {fit_difference_ratio:.4}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot data with log linear fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selfsim_scaling(k, beta, delsig, M0):\n",
    "    return (1/(k*beta)) * (7/(16*delsig))**(1/3) * M0**(1/3)\n",
    "\n",
    "def M02Mw(M0):\n",
    "    return (np.log10(M0) - 9.1) * 2.0 / 3.0 # synchronized with OpenSWPC : moment_magnitude ( m0 )\n",
    "\n",
    "def Mw2M0(Mw):\n",
    "    return 10**( 1.5 * Mw + 9.05) # synchronized with OpenSWPC : seismic_moment ( mw )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute regression\n",
    "M0_reg = np.logspace(-3, 1, 101)\n",
    "TR_reg = (10**df_res.loc[fit_method, \"Intercept\"])*(M0_reg**df_res.loc[fit_method, \"Slope\"])\n",
    "\n",
    "TR_reg_low = (10**df_conf.loc[fit_method, \"2.5%-Intercept\"])*(M0_reg**df_conf.loc[fit_method, \"2.5%-Slope\"])\n",
    "TR_reg_high = (10**df_conf.loc[fit_method, \"97.5%-Intercept\"])*(M0_reg**df_conf.loc[fit_method, \"97.5%-Slope\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipcolor = 2\n",
    "datacases_thresh_Nsensor = df_stats_case[\"datacase\"].values\n",
    "lc_selected = dict()\n",
    "c_norm = mpl.colors.Normalize(vmin=0, vmax=len(datacases_thresh_Nsensor)+skipcolor)\n",
    "cmap = sns.color_palette(\"tab20\", as_cmap=True) # for tab 20 not ordering to distribute the color\n",
    "for i, datacase in enumerate(datacases_thresh_Nsensor):\n",
    "    lc_selected[datacase] = cmap(c_norm(i+skipcolor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected AE sensors for patch G3\n",
    "AEsensor_list = [\"OL23\", \"OL07\", \"OL08\", \"OL22\"] # update: we use 4 close sensors \"OL24\"] \n",
    "gougeevent_id = 4\n",
    "stnm = AEsensor_list[0]\n",
    "df_sourceparam[(df_sourceparam[\"Qinv_quart\"] == f\"{Qinv_quart}\") & (df_sourceparam[\"gougeevent_id\"] ==  gougeevent_id) & (df_sourceparam[\"AEsensor\"] ==  int(stnm[2:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stats_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard error\n",
    "\n",
    "We plot the error bar with the standard error with is computed as follows:\n",
    "$$ STE = \\dfrac{\\sigma}{\\sqrt{N_{\\text{sensor}}}}, $$ \n",
    "\n",
    "Where the N sensor is thresholded as four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_inds = np.argsort(df_stats_case.M0_mean.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_mc = sns.color_palette(\"tab10\")\n",
    "scatter_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynrup_col = sns.color_palette(\"colorblind\")\n",
    "dynrup_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load color dictionary consistent to the plot of the repeated waveforms\n",
    "repeated_sensor_lcdict = \"OL08\" # the color dict is same for all the sensor although separately saved.\n",
    "gougepatch_id = \"G3\"\n",
    "with open(f'../data/01_plot_gougeevents/lc_dict_{gougepatch_id}_{repeated_sensor_lcdict}.pkl', 'rb') as fi:\n",
    "    lc_dict = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifPlotSelfSimLines = True\n",
    "vs=3600\n",
    "n_boot = 1000\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5.46, 5.8))\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(8, 7))\n",
    "\n",
    "scatter_kws0 = {\"s\": 0, \"edgecolors\": \"k\", \"zorder\": 1, \"alpha\": 0.9}\n",
    "scatter_kws1 = {\"s\": 90, \"edgecolors\": \"k\", \"zorder\": 1, \"alpha\": 0.9}\n",
    "line_kws = {\"color\": \"crimson\", \"zorder\": -3}\n",
    "\n",
    "tc = [\"\"]\n",
    "mctype = [\"o\", \"d\", \"s\", \"v\"]\n",
    "\n",
    "labelflag = 0\n",
    "\n",
    "ifPlotMain=1 #1\n",
    "ifPlotnoQcorr=0\n",
    "ifPlotAllSensors = 0\n",
    "ifPlotRegression = 1\n",
    "ifPlotDynrup = 1\n",
    "ifAnnotID = 1\n",
    "\n",
    "for k, datacase in enumerate(datacases_thresh_Nsensor[sorted_inds]):\n",
    "\n",
    "    tx = []\n",
    "    for i, stnm in enumerate(AEsensor_list):\n",
    "    # stnm = AEsensor_list[i]\n",
    "    # for datacase in datacases:\n",
    "    \n",
    "        gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "\n",
    "        df_sensor = df_sourceparam[(df_sourceparam[\"Qinv_quart\"] == f\"{Qinv_quart}\") & (df_sourceparam[\"gougeevent_id\"] ==  gougeevent_id) & (df_sourceparam[\"AEsensor\"] ==  int(stnm[2:]))]\n",
    "        M0_sensor = df_sensor[\"M0\"].values[0]\n",
    "        Tw_sensor = df_sensor[\"Tw\"].values[0]\n",
    "\n",
    "        if labelflag < 4:\n",
    "            label = f\"AS{stnm[2:]}\"\n",
    "            labelflag += 1\n",
    "        else:\n",
    "            label = \"\"\n",
    "            \n",
    "        if ifPlotAllSensors:\n",
    "            ax.plot(M0_sensor, Tw_sensor*1e6, marker=mctype[i], c=lc_selected[datacase], label=label, alpha=0.6, zorder=-5)\n",
    "\n",
    "\n",
    "# sns.regplot uses bootstrap method to obtain the confidence interval\n",
    "# sns.regplot(x=\"M0_mean\", y=\"Tw_microsec\", data=df_stats_case_droplim, ci=95, fit_reg=True, label=\"\", color=\"crimson\", n_boot=1000,\n",
    "#             scatter_kws=scatter_kws0, line_kws=line_kws, ax=ax, order=1);\n",
    "# sns.regplot(x=\"M0_mean\", y=\"Tw_microsec\", data=df_stats_case, ci=95, fit_reg=False, label=\"Mean of four AE sensors\", color=\"crimson\",\n",
    "#             scatter_kws=scatter_kws1, ax=ax, order=1);\n",
    "\n",
    "# ax.scatter(df_stats_case_droplim[\"M0_mean\"].values, df_stats_case_droplim[\"Tw_microsec\"].values, 90, marker=\"o\", ec=\"k\", color=\"crimson\", alpha=0.9,\n",
    "#            label=\"Mean of four AE sensors\", zorder=1)\n",
    "\n",
    "# ax.scatter(df_stats_case_limevent[\"M0_mean\"].values, df_stats_case_limevent[\"Tw_microsec\"].values, 90, marker=\"o\", ec=\"k\", color=\"crimson\", alpha=0.9,\n",
    "#            label=None, zorder=1)\n",
    "\n",
    "# Compute standard error\n",
    "standarderror_factor = np.sqrt(Nvalidsensors_thresh)\n",
    "\n",
    "mainmarkersize = 7\n",
    "dynrup_targets = [24, 50, 52, 72, 129]\n",
    "\n",
    "if ifPlotMain:\n",
    "    \n",
    "    df_stats_case_dynruptargets = df_stats_case[df_stats_case.index.isin(dynrup_targets)]\n",
    "    df_stats_case_others = df_stats_case[~df_stats_case.index.isin(dynrup_targets)]\n",
    "\n",
    "    if ifPlotDynrup:\n",
    "        # update: change zorder for dynamic rupture target events\n",
    "\n",
    "        hm = ax.errorbar(df_stats_case_others[\"M0_mean\"].values, df_stats_case_others[\"Tw_microsec\"].values, \n",
    "                yerr = df_stats_case_others[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_stats_case_others[\"M0_std\"]/standarderror_factor,\n",
    "                capsize=0, alpha=1.0, fmt='o', markersize=mainmarkersize, mew=0.75, color=scatter_mc[3], lw=1, markeredgecolor = \"k\", label=\"Observation after Q correction\", zorder=3)\n",
    "        \n",
    "        hm0 = ax.errorbar(df_stats_case_dynruptargets[\"M0_mean\"].values, df_stats_case_dynruptargets[\"Tw_microsec\"].values, \n",
    "                yerr = df_stats_case_dynruptargets[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_stats_case_dynruptargets[\"M0_std\"]/standarderror_factor,\n",
    "                capsize=0, alpha=1.0, fmt='o', markersize=mainmarkersize, mew=1.5, color=scatter_mc[3], lw=1, markeredgecolor = \"b\", label=None, zorder=4)\n",
    "\n",
    "    else:\n",
    "        hm = ax.errorbar(df_stats_case_others[\"M0_mean\"].values, df_stats_case_others[\"Tw_microsec\"].values, \n",
    "                yerr = df_stats_case_others[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_stats_case_others[\"M0_std\"]/standarderror_factor,\n",
    "                capsize=0, alpha=1.0, fmt='o', markersize=mainmarkersize, mew=0.75, color=scatter_mc[3], lw=1, markeredgecolor = \"k\", label=\"Observation after Q correction\", zorder=3)\n",
    "        \n",
    "        hm0 = ax.errorbar(df_stats_case_dynruptargets[\"M0_mean\"].values, df_stats_case_dynruptargets[\"Tw_microsec\"].values, \n",
    "                yerr = df_stats_case_dynruptargets[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_stats_case_dynruptargets[\"M0_std\"]/standarderror_factor,\n",
    "                capsize=0, alpha=1.0, fmt='o', markersize=mainmarkersize, mew=0.75, color=scatter_mc[3], lw=1, markeredgecolor = \"k\", label=None, zorder=4)\n",
    "\n",
    "if ifPlotnoQcorr:\n",
    "    nocorrmarkersize = 5.5\n",
    "    if ifPlotMain:\n",
    "        label_noQcorr = \"\"\n",
    "        alpha_noQcorr = 0.15 #1.0\n",
    "        mc = [0.7, 0.7, 0.7] #[0.9, 0.9, 0.9]\n",
    "        mec = \"k\" #[0.8, 0.8, 0.8]\n",
    "        \n",
    "    else:\n",
    "        # label_noQcorr = \"Mean of four AE sensors\"\n",
    "        alpha_noQcorr = 1.0\n",
    "        mc = [0.7, 0.7, 0.7] #scatter_mc[-1]\n",
    "        mec = \"black\"\n",
    "\n",
    "    label_noQcorr = \"No Q correction\"\n",
    "    ax.errorbar(df_stats_noQcorr[\"M0_mean\"].values, df_stats_noQcorr[\"Tw_microsec\"].values, \n",
    "            yerr = df_stats_noQcorr[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_stats_noQcorr[\"M0_std\"]/standarderror_factor,\n",
    "            capsize=0, fmt='D', markersize=nocorrmarkersize, color=mc, lw=1, markeredgecolor = mec, label=label_noQcorr, alpha=alpha_noQcorr, zorder=1,\n",
    "            )\n",
    "\n",
    "\n",
    "# plot the best-fit regression\n",
    "if ifPlotRegression:\n",
    "    # reglabelstr = rf\"$T_w \\propto M_0 {fit_slope:.2f}±{fit_slope_err:.2}$\"\n",
    "    reglabelstr = r\"$T_w \\propto M_0 ^{{ {{{:.2f}}} ± {{{:.2f}}} }}$\".format(fit_slope, fit_slope_err)\n",
    "    ax.plot(M0_reg, TR_reg, lw=1.0, zorder = 2, label=reglabelstr, c=\"gray\") #c=scatter_mc[3])\n",
    "# ax.plot(M0_reg, TR_reg_low, c=\"crimson\", ls=\"--\", zorder = -3)\n",
    "# ax.plot(M0_reg, TR_reg_high, c=\"crimson\", ls=\"--\", zorder = -3)\n",
    "    # ax.text(5e-3, 2.8, f\"α={fit_slope:.2f}±{fit_slope_err:.2f}\") \n",
    "\n",
    "xlimit_scaling = [0.004, 3] #10] # check 1/3\n",
    "ax.set_xscale('log') # We checked the error bar works in log scale.\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(xlimit_scaling)\n",
    "ax.set_ylim([1.5, 3.6]) #10]) # update 2025/1/23 # check 1/3\n",
    "\n",
    "\n",
    "ax.set_yticks([2, 3, ]) # update 2025/1/23\n",
    "ax.set_yticklabels([2, 3, ]) # update 2025/1/23\n",
    "\n",
    "# ax.set_yticks(np.arange(2.0, 3.5, step=0.1)) # update 2025/1/23\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"$M_0$ [Nm]\")\n",
    "ax.set_ylabel(\"$T_w$ [μs]\")\n",
    "\n",
    "ax.grid(True, c=np.array([230, 230, 230])/255, lw=0.25, zorder=-1)\n",
    "ax.set_axisbelow('True')\n",
    "# ax.legend(loc=3)\n",
    "\n",
    "# if not ifPlotAllSensors:\n",
    "#     ax.legend(loc=3)\n",
    "# else:\n",
    "#     ax.legend(loc=3, handlelength=0)\n",
    "\n",
    "\n",
    "if ifPlotSelfSimLines:\n",
    "    # M0_selfsim = np.linspace(0, 2, 101)\n",
    "    M0_selfsim = np.logspace(-3, 1.2, 101)\n",
    "    \n",
    "    delsig_list = [1e6, 5e6, 15e6] #[5e6, 10e6, 20e6]\n",
    "    # delsig_annot_x = [1.35e-2, 2.5e-2, 7.5e-2]\n",
    "    # delsig_annot_y = [1.55, 1.35, 1.25]\n",
    "    \n",
    "    # delsig_annot_x = np.array([1.12e-2, 5.7e-2, 1.7e-1]) # update 2025/1/23\n",
    "    delsig_annot_x = np.array([1.6e-2, 8.1e-2, 2.4e-1]) # update 2025/1/23\n",
    "    delsig_annot_y = [1.6, 1.6, 1.6] #[1.16, 1.16, 1.16]\n",
    "    \n",
    "    # k_rup = 0.32 # P wave for vr = 0.9cs\n",
    "    delsig_ls = [\":\", \"--\"]\n",
    "    \n",
    "    # C_k = [0.15, 0.32]\n",
    "    C_k = [0.32]\n",
    "    for k, k_rup in enumerate(C_k): # for 0.6vs and 0.9vs\n",
    "    \n",
    "        for j, delsig in enumerate(delsig_list):\n",
    "            TR_selfsim = get_selfsim_scaling(k_rup, vs, delsig, M0_selfsim)\n",
    "            ax.plot(M0_selfsim, TR_selfsim*1e6, \"k\", ls=delsig_ls[k], lw=1, zorder=-1, label=None)\n",
    "            \n",
    "            if j == 0:\n",
    "                delsigstr = r'$\\Delta \\sigma$ = {:.0f}MPa'.format(delsig/1e6)\n",
    "            else:\n",
    "                delsigstr = '{:.0f}MPa'.format(delsig/1e6)\n",
    "                \n",
    "            ax.text(delsig_annot_x[j], delsig_annot_y[j], delsigstr)\n",
    "\n",
    "# plot measurement limitation\n",
    "if ifPlotRegression:\n",
    "    Tw_limit = 2.0\n",
    "    # ax.axhline(Tw_limit, ls=\"--\", c=\"k\", lw=1.0, dashes=(4, 2.8), label=None)\n",
    "    # ax.axhline(2.5, ls=\":\", c=\"gray\", lw=1.0, dashes=(4, 2.8))\n",
    "\n",
    "\n",
    "# plot result of dynamic rupture model\n",
    "if ifPlotDynrup:\n",
    "\n",
    "    # dynamic rupture parameters\n",
    "    a_patch = 4.0e-3\n",
    "    rupturetype = \"pulse\"\n",
    "    pdcscaling = 0.6 #0.65\n",
    "    bgbeta= 0.35 #0.4\n",
    "    sig_n = 6e6\n",
    "        \n",
    "    casestr = f\"a={a_patch*1e3:.2f}_ruptype={rupturetype}_pdcscaling={pdcscaling:.3f}_sn={sig_n/1e6:.1f}MPa_hatfr=0.3_bgbeta={bgbeta:.2f}\"\n",
    "\n",
    "    # read STF best-fit associated with the dynamic rupture model\n",
    "    df_dynrup_sourceparam = pd.read_csv(f\"../../RuptureSimulation/main_casestudy/postprocess_dynrup/data/dynrup_bestfit_sourceparam_{casestr}_master.csv\", index_col=None)\n",
    "    df_dynrup_sourceparam = df_dynrup_sourceparam.set_index(\"event_id\")\n",
    "    for index, row in df_dynrup_sourceparam.iterrows():\n",
    "        if index==24:\n",
    "            label=\"Dynamic rupture model\"\n",
    "        else:\n",
    "            label=None\n",
    "            \n",
    "        hdyn = ax.plot(row[\"M0_bestfit\"], row[\"Tw_bestfit\"]*1e6,\n",
    "            \"*\", ms=12, mfc=\"gold\", mew=0.75, mec=\"k\",\n",
    "            label=label, alpha=1.0, zorder=5)\n",
    "\n",
    "    # Annotate event ID for the dynamic rupture model\n",
    "    # ifAnnotID = 1\n",
    "\n",
    "    annot_locs = [(0.55, 0.15), (0.57, 0.15), (0.58, 0.25), (0.94, -0.30), (1.2, -0.12)]\n",
    "    for jj, targetid in enumerate(dynrup_targets):\n",
    "        M0_bestfit = df_dynrup_sourceparam.loc[targetid].M0_bestfit\n",
    "        Tw_bestfit = df_dynrup_sourceparam.loc[targetid].Tw_bestfit\n",
    "        (a_xy, b_xy) = annot_locs[jj]\n",
    "        xytext = (a_xy*M0_bestfit, Tw_bestfit*1e6 + b_xy)\n",
    "            \n",
    "        ax.annotate(f'M{targetid:g}', xy=(M0_bestfit, Tw_bestfit*1e6), xytext=xytext,\n",
    "            arrowprops=dict(arrowstyle = '-', connectionstyle = 'arc3', lw=1.0), \n",
    "            horizontalalignment=\"left\", zorder=4, fontsize=10., c=\"k\")\n",
    "        \n",
    "    # Plot potential measurement limitation\n",
    "    measurement_limit_Tw = 2.0\n",
    "    ax.plot(xlimit_scaling, [measurement_limit_Tw, measurement_limit_Tw], \"--\", c=\"gray\", lw=0.75)\n",
    "\n",
    "# Annotate measurement limitation\n",
    "if ifPlotMain:\n",
    "    for kk, smallevent_id in enumerate(remove_eventlist): # two events 118 and 126\n",
    "        annot_locs = [(0.57, 0.15), (0.57, 0.16),]\n",
    "        print(smallevent_id)\n",
    "        M0_small = df_stats_case_others.loc[smallevent_id].M0_mean\n",
    "        Tw_small = df_stats_case_others.loc[smallevent_id].Tw_mean\n",
    "        (a_xy, b_xy) = annot_locs[kk]\n",
    "        xytext = (a_xy*M0_small, Tw_small*1e6 - b_xy)\n",
    "            \n",
    "        ax.annotate(f'D{smallevent_id:g}', xy=(M0_small, Tw_small*1e6), xytext=xytext,\n",
    "            arrowprops=dict(arrowstyle = '-', connectionstyle = 'arc3', lw=1.0), \n",
    "            horizontalalignment=\"left\", zorder=0, fontsize=10., c=\"k\")\n",
    "        \n",
    "       \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='upper left', frameon=False)\n",
    "# set rectangle for clarity of legend\n",
    "if ~ifPlotMain & ifPlotnoQcorr:\n",
    "    print(\"skip white rectangle.\")\n",
    "elif ifPlotnoQcorr:\n",
    "    ax.plot(0.121, 3.3, \"s\", c=\"w\", ms=12, zorder=4)\n",
    "else:\n",
    "    ax.plot(0.14, 3.44, \"s\", c=\"w\", ms=12, zorder=4)\n",
    "\n",
    "#-----------------------#\n",
    "#--- plot double axis---#\n",
    "#-----------------------#\n",
    "\n",
    "# https://pythonmatplotlibtips.blogspot.com/2018/01/add-second-x-axis-below-first-x-axis-python-matplotlib-pyplot.html\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xlabel(\"$M_w$\")\n",
    "ax2.set_xlim([M02Mw(xlimit_scaling[0]), M02Mw(xlimit_scaling[1])]) # synchronize with the first axis\n",
    "\n",
    "# major tick\n",
    "newlabel = np.array([-7.5, -7, -6.5, -6.0,])\n",
    "ax2.minorticks_on()\n",
    "ax2.set_xticks(newlabel)\n",
    "\n",
    "ax.grid(True, c=np.array([230, 230, 230])/255, lw=0.25, zorder=-1)\n",
    "ax.set_axisbelow('True')\n",
    "\n",
    "\n",
    "# Debug turning on minor ticks\n",
    "# ax.set_yticks(np.arange(1.0, 3.6, step=0.1)) # update 2025/1/23\n",
    "# ax.set_yticklabels([2, 3, ]) # update 2025/1/23\n",
    "\n",
    "\n",
    "# plt.suptitle(f'Q{Qinv_quart} water-level={k_waterlevel:.2f}', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(figdir+f\"/STF_M0TRscaling_Regplot_fb03-{expr_id:03d}_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}_selfsimlines{ifPlotSelfSimLines}_fitlog_{fit_method}_{ifPlotAllSensors}{ifPlotRegression}{ifPlotMain}{ifPlotnoQcorr}{ifPlotDynrup}{ifAnnotID}.png\", format=\"png\", dpi=200)\n",
    "plt.savefig(figdir+f\"/STF_M0TRscaling_Regplot_fb03-{expr_id:03d}_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}_selfsimlines{ifPlotSelfSimLines}_fitlog_{fit_method}_{ifPlotAllSensors}{ifPlotRegression}{ifPlotMain}{ifPlotnoQcorr}{ifPlotDynrup}{ifAnnotID}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug plot logscale spacing\n",
    "y1 = [np.log10(x) for x in np.arange(1, 4, 1)]\n",
    "y2 = [np.log10(x) for x in np.arange(1, 3, 0.1)]\n",
    "\n",
    "plt.plot(np.zeros((len(y1),1)), y1, \"s\", zorder=2)\n",
    "plt.plot(np.zeros((len(y2),1)), y2, \"o\", zorder=1)\n",
    "plt.ylim([0.25, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynrup_targets = [24, 50, 52, 72, 129]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dynrup_sourceparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_stats_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case[\"Tw_mean\"] * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case[\"M0_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standarderror_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_slope, fit_slope_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with event IDs\n",
    "ifPlotSelfSimLines = True\n",
    "vs=3600\n",
    "n_boot = 1000\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "scatter_kws0 = {\"s\": 0, \"edgecolors\": \"k\", \"zorder\": 1, \"alpha\": 0.9}\n",
    "scatter_kws1 = {\"s\": 90, \"edgecolors\": \"k\", \"zorder\": 1, \"alpha\": 0.9}\n",
    "line_kws = {\"color\": \"crimson\", \"zorder\": -3}\n",
    "\n",
    "tc = [\"\"]\n",
    "mctype = [\"o\", \"d\", \"s\", \"v\"]\n",
    "\n",
    "labelflag = 0\n",
    "\n",
    "ifPlotMain=1 #1\n",
    "ifPlotnoQcorr=0\n",
    "ifPlotAllSensors = 0\n",
    "ifPlotRegression = 0\n",
    "\n",
    "for k, datacase in enumerate(datacases_thresh_Nsensor[sorted_inds]):\n",
    "\n",
    "    tx = []\n",
    "    for i, stnm in enumerate(AEsensor_list):\n",
    "    # stnm = AEsensor_list[i]\n",
    "    # for datacase in datacases:\n",
    "    \n",
    "        gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "\n",
    "        df_sensor = df_sourceparam[(df_sourceparam[\"Qinv_quart\"] == f\"{Qinv_quart}\") & (df_sourceparam[\"gougeevent_id\"] ==  gougeevent_id) & (df_sourceparam[\"AEsensor\"] ==  int(stnm[2:]))]\n",
    "        M0_sensor = df_sensor[\"M0\"].values[0]\n",
    "        Tw_sensor = df_sensor[\"Tw\"].values[0]\n",
    "\n",
    "        if labelflag < 4:\n",
    "            label = f\"AS{stnm[2:]}\"\n",
    "            labelflag += 1\n",
    "        else:\n",
    "            label = \"\"\n",
    "            \n",
    "        if ifPlotAllSensors:\n",
    "            ax.plot(M0_sensor, Tw_sensor*1e6, marker=mctype[i], c=lc_selected[datacase], label=label, alpha=0.6, zorder=-5)\n",
    "\n",
    "\n",
    "# sns.regplot uses bootstrap method to obtain the confidence interval\n",
    "# sns.regplot(x=\"M0_mean\", y=\"Tw_microsec\", data=df_stats_case_droplim, ci=95, fit_reg=True, label=\"\", color=\"crimson\", n_boot=1000,\n",
    "#             scatter_kws=scatter_kws0, line_kws=line_kws, ax=ax, order=1);\n",
    "# sns.regplot(x=\"M0_mean\", y=\"Tw_microsec\", data=df_stats_case, ci=95, fit_reg=False, label=\"Mean of four AE sensors\", color=\"crimson\",\n",
    "#             scatter_kws=scatter_kws1, ax=ax, order=1);\n",
    "\n",
    "# ax.scatter(df_stats_case_droplim[\"M0_mean\"].values, df_stats_case_droplim[\"Tw_microsec\"].values, 90, marker=\"o\", ec=\"k\", color=\"crimson\", alpha=0.9,\n",
    "#            label=\"Mean of four AE sensors\", zorder=1)\n",
    "\n",
    "# ax.scatter(df_stats_case_limevent[\"M0_mean\"].values, df_stats_case_limevent[\"Tw_microsec\"].values, 90, marker=\"o\", ec=\"k\", color=\"crimson\", alpha=0.9,\n",
    "#            label=None, zorder=1)\n",
    "\n",
    "# Compute standard error\n",
    "standarderror_factor = np.sqrt(Nvalidsensors_thresh)\n",
    "\n",
    "if ifPlotMain:\n",
    "    # ax.errorbar(df_stats_case[\"M0_mean\"].values, df_stats_case[\"Tw_microsec\"].values, \n",
    "    #         yerr = df_stats_case[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_stats_case[\"M0_std\"]/standarderror_factor,\n",
    "    #         capsize=0, fmt='o', markersize=3, color=scatter_mc[0], markeredgecolor = \"black\", label=\"Mean of four AE sensors\", zorder=3)\n",
    "    ax.plot(df_stats_case[\"M0_mean\"].values, df_stats_case[\"Tw_microsec\"].values, 'o',\n",
    "            markersize=3, color=scatter_mc[0], markeredgecolor = \"black\", label=\"Mean of four AE sensors\", zorder=3)\n",
    "\n",
    "    # annotate text\n",
    "    id_text=[]\n",
    "    for gid, row in df_stats_case.iterrows():\n",
    "        ax.annotate(f\"{gid}\", xy=(row[\"M0_mean\"], row[\"Tw_microsec\"]), xytext=(0, 0), textcoords='offset fontsize', fontsize=10, zorder=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if ifPlotnoQcorr:\n",
    "    if ifPlotMain:\n",
    "        label_noQcorr = \"\"\n",
    "        alpha_noQcorr = 1.0\n",
    "        mc = [0.9, 0.9, 0.9]\n",
    "        mec = [0.8, 0.8, 0.8]\n",
    "        \n",
    "    else:\n",
    "        label_noQcorr = \"Mean of four AE sensors\"\n",
    "        alpha_noQcorr = 1.0\n",
    "        mc = scatter_mc[-1]\n",
    "        mec = \"black\"\n",
    "        \n",
    "    ax.errorbar(df_stats_noQcorr[\"M0_mean\"].values, df_stats_noQcorr[\"Tw_microsec\"].values, \n",
    "            yerr = df_stats_noQcorr[\"Tw_std\"].values*1e6/standarderror_factor, xerr = df_stats_noQcorr[\"M0_std\"]/standarderror_factor,\n",
    "            capsize=3, fmt='o', markersize=9.5, color=mc, markeredgecolor = mec, label=label_noQcorr, alpha=alpha_noQcorr, zorder=1)\n",
    "\n",
    "\n",
    "\n",
    "# plot the best-fit regression\n",
    "if ifPlotRegression:\n",
    "    ax.plot(M0_reg, TR_reg, c=scatter_mc[0], zorder = 2)\n",
    "\n",
    "# ax.plot(M0_reg, TR_reg_low, c=\"crimson\", ls=\"--\", zorder = -3)\n",
    "# ax.plot(M0_reg, TR_reg_high, c=\"crimson\", ls=\"--\", zorder = -3)\n",
    "\n",
    "    ax.text(5e-3, 3.2, f\"α={fit_slope:.2f}±{fit_slope_err:.2f}\") \n",
    "\n",
    "xlimit_scaling = [0.004, 3] #10]check 1/3\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlim(xlimit_scaling)\n",
    "ax.set_ylim([1.8, 3.2]) #[1, 4.0]) #10]) check 1/3\n",
    "ax.set_yticks([2, 3])\n",
    "ax.set_yticklabels([2, 3])\n",
    "# ax.set_yticks([1, 2, 3, 4])\n",
    "# ax.set_yticklabels([1, 2, 3, 4])\n",
    "\n",
    "ax.set_xlabel(\"$M_0$ [Nm]\")\n",
    "ax.set_ylabel(\"$T_w$ [μs]\")\n",
    "\n",
    "ax.grid(True, c=np.array([230, 230, 230])/255, lw=0.25, zorder=-1)\n",
    "ax.set_axisbelow('True')\n",
    "# ax.legend(loc=3)\n",
    "\n",
    "if not ifPlotAllSensors:\n",
    "    ax.legend(loc=3)\n",
    "else:\n",
    "    ax.legend(loc=3, handlelength=0)\n",
    "\n",
    "\n",
    "if ifPlotSelfSimLines:\n",
    "    # M0_selfsim = np.linspace(0, 2, 101)\n",
    "    M0_selfsim = np.logspace(-3, 1.2, 101)\n",
    "    \n",
    "    delsig_list = [1e6, 5e6, 15e6] #[5e6, 10e6, 20e6]\n",
    "    # delsig_annot_x = [1.35e-2, 2.5e-2, 7.5e-2]\n",
    "    # delsig_annot_y = [1.55, 1.35, 1.25]\n",
    "    \n",
    "    delsig_annot_x = np.array([1.6e-2, 8.1e-2, 2.4e-1]) # update 2025/1/23\n",
    "    delsig_annot_y = [1.9, 1.9, 1.9] #[1.16, 1.16, 1.16]\n",
    "    \n",
    "    # k_rup = 0.32 # P wave for vr = 0.9cs\n",
    "    delsig_ls = [\":\", \"--\"]\n",
    "    \n",
    "    # C_k = [0.15, 0.32]\n",
    "    C_k = [0.32]\n",
    "    for k, k_rup in enumerate(C_k): # for 0.6vs and 0.9vs\n",
    "    \n",
    "        for j, delsig in enumerate(delsig_list):\n",
    "            TR_selfsim = get_selfsim_scaling(k_rup, vs, delsig, M0_selfsim)\n",
    "            ax.plot(M0_selfsim, TR_selfsim*1e6, \"k\", ls=delsig_ls[k], lw=1, zorder=-1)\n",
    "            \n",
    "            if j == 0:\n",
    "                delsigstr = r'$\\Delta \\sigma$ = {:.0f}MPa'.format(delsig/1e6)\n",
    "            else:\n",
    "                delsigstr = '{:.0f}MPa'.format(delsig/1e6)\n",
    "                \n",
    "            ax.text(delsig_annot_x[j], delsig_annot_y[j], delsigstr)\n",
    "\n",
    "# plot measurement limitation\n",
    "if ifPlotRegression:\n",
    "    Tw_limit = 2.0\n",
    "    ax.axhline(Tw_limit, ls=\"--\", c=\"k\", lw=1.0, dashes=(4, 2.8))\n",
    "\n",
    "\n",
    "#-----------------------#\n",
    "#--- plot double axis---#\n",
    "#-----------------------#\n",
    "\n",
    "# https://pythonmatplotlibtips.blogspot.com/2018/01/add-second-x-axis-below-first-x-axis-python-matplotlib-pyplot.html\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xlabel(\"$M_w$\")\n",
    "ax2.set_xlim([M02Mw(xlimit_scaling[0]), M02Mw(xlimit_scaling[1])]) # synchronize with the first axis\n",
    "\n",
    "# major tick\n",
    "newlabel = np.array([-7.5, -7, -6.5, -6.0,])\n",
    "ax2.minorticks_on()\n",
    "ax2.set_xticks(newlabel)\n",
    "\n",
    "ax.grid(True, c=np.array([230, 230, 230])/255, lw=0.25, zorder=-1)\n",
    "ax.set_axisbelow('True')\n",
    "\n",
    "# plt.suptitle(f'Q{Qinv_quart} water-level={k_waterlevel:.2f}', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(figdir+f\"/debug_STF_M0TRscaling_Regplot_fb03-{expr_id:03d}_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}_selfsimlines{ifPlotSelfSimLines}_fitlog_{fit_method}_{ifPlotAllSensors}{ifPlotRegression}{ifPlotMain}{ifPlotnoQcorr}_withID.png\", format=\"png\", dpi=200)\n",
    "plt.savefig(figdir+f\"/debug_STF_M0TRscaling_Regplot_fb03-{expr_id:03d}_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}_selfsimlines{ifPlotSelfSimLines}_fitlog_{fit_method}_{ifPlotAllSensors}{ifPlotRegression}{ifPlotMain}{ifPlotnoQcorr}_withID.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
