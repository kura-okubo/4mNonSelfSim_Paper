{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the displacement pulse from the P wave velocity waveform\n",
    "\n",
    "We convert the P wave velocity pulse to the displacement pulse to evaluate the source parameters.\n",
    "\n",
    "2024.11.18 Kurama Okubo\n",
    "\n",
    "- NOTE: We originally evaluated the half-maximum-pulse-width to evaluate the source parameters. However, it was unstable when the pulse shape was perturbed, and it was difficult to make a criteria to qualify the source time function. We thus switched to use the synthetic source time function fitting\n",
    "\n",
    "- 2024.11.19 update computing LBA for the case without correction of attenuation factor to fit the STF.\n",
    "\n",
    "- 2024.11.21 update applying the low-pass filter before Q deconvolution. Update detrending; we remove the constant offset to keep the flat trace before the P arrival.\n",
    "\n",
    "- 2024.11.25 update making an option to denoise with the detrend or the high-pass two-way filter.\n",
    "\n",
    "- 2024.11.28 update detrend parameters for the low S/N events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import obspy\n",
    "from obspy import read, Stream, Trace\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import mpmath as mp\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit  \n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import seaborn as sns \n",
    "from scipy.interpolate import LSQUnivariateSpline\n",
    "from scipy import integrate\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "import h5py # store the STF in hdf5\n",
    "\n",
    "from detrend_func import *\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 4.75\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.75\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"xtick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 4.75\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.75\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"ytick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = True\n",
    "plt.rcParams['axes.linewidth'] = 0.75\n",
    "\n",
    "from obspy.core.utcdatetime import UTCDateTime  \n",
    "os.environ['TZ'] = 'GMT' # change time zone to avoid confusion in unix_tvec conversion\n",
    "UTCDateTime.DEFAULT_PRECISION = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataoutdir = \"../data/03_computePdisp\"\n",
    "if not os.path.exists(dataoutdir):\n",
    "    os.makedirs(dataoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = \"../figure/debug_03_computePdisp/\"\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "1. Far-field displacement pulse\n",
    "> Processed in `02_trim_Pwave_window.ipynb`. The data is dumped as `data/02_trim_pwave/st_repeat_Pdisp_OL08.pickle`.\n",
    "\n",
    "2. Attenuation factor model\n",
    "> Computed at `09_compute_Qinv.ipynb` using the ball-drop impact. This is used as the model of attenuation factor to correct from the observed displacement pulse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process flow\n",
    "\n",
    "1. Read velocity pulse\n",
    "2. Process the pulse to compute the displacement and the source time function\n",
    "3. Deconvolve the attenuation factor (constant Q & frequency-dependent Q)\n",
    "4. Store the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data of P wave pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read trace\n",
    "gougepatch_id = \"G3\" # to set output filename\n",
    "Qinv_quart = 50\n",
    "\n",
    "st_repeat_Pvel = read(f\"../data/02_trim_pwave/st_repeat_Pvel_{gougepatch_id}_OL*.pickle\", format=\"PICKLE\")\n",
    "st_repeat_Pdisp = read(f\"../data/02_trim_pwave/st_repeat_Pdisp_{gougepatch_id}_OL*.pickle\", format=\"PICKLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected AE sensors for patch G3\n",
    "AEsensor_list = [\"OL23\", \"OL07\", \"OL08\", \"OL22\"] # update: we use 4 close sensors \"OL24\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read attenuation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Q model\n",
    "df_Qinv_quantile = pd.read_csv(\"../../Calibration/Attenuation/data/df_Qinv_quantile.csv\", index_col=0)\n",
    "df_Qinv_quantile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best-fit source parameters\n",
    "Loading the source parameters estimated by the waveform fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the best fit source parameters\n",
    "bestfitsourceparam_finame = f\"../../SourceInvFit/data/datacsv/gridsearch_bestparam_M0andTR_fb03-087.csv\"\n",
    "\n",
    "df_bestparam = pd.read_csv(bestfitsourceparam_finame, index_col=0) # from waveform inversion\n",
    "datacases = df_bestparam.index\n",
    "df_bestparam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read radiation pattern coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimP_coef_columns = [\"rdist\", \"incidentangle\", \"dip\", \"azimuth\", \"k_M0uz\", \"TR\", \"beta_coef_p\"]\n",
    "df_trimP_coef = pd.DataFrame(columns=trimP_coef_columns)\n",
    "\n",
    "for stnm in AEsensor_list:\n",
    "    df_trimP_sensor = pd.read_csv(f\"../data/02_trim_pwave/trimP_coefficients_{gougepatch_id}_{stnm}.csv\", index_col=0)\n",
    "\n",
    "    if not df_trimP_coef.empty:\n",
    "        df_trimP_coef = pd.concat([df_trimP_coef, df_trimP_sensor])\n",
    "        \n",
    "    else:\n",
    "        df_trimP_coef = df_trimP_sensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases = np.unique(df_trimP_coef.index)\n",
    "datacases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:12.6g}'.format\n",
    "df_trimP_coef.loc[datacases[13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Channel Index\n",
    "channel_finame = '../../Others/AEchanneltable/AEsensorlocation_onFB03_table.csv'\n",
    "df_array = pd.read_csv(channel_finame)\n",
    "\n",
    "channel_loc={}\n",
    "\n",
    "for i in range(len(df_array)):\n",
    "    stnm = df_array.iloc[i].Instrument_Label\n",
    "    xtemp = df_array.iloc[i].North.astype('float')\n",
    "    ytemp = df_array.iloc[i].East.astype('float')\n",
    "    ztemp = df_array.iloc[i].Down.astype('float')\n",
    "    channel_loc[stnm] = [xtemp, ytemp, ztemp]\n",
    "    \n",
    "AEsensors = list(channel_loc.keys())\n",
    "# channel_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_trace(st, stname, datacase):\n",
    "    \"\"\"Extract the P disp trace\"\"\"\n",
    "    st_station = st.select(station=stname)\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_station].index(datacase)\n",
    "    return st_station[tr_ind].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = select_trace(st_repeat_Pdisp, \"OL08\", datacases[2])\n",
    "tr.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the displacement pulse\n",
    "\n",
    "We compute the displacement pulse with the pre-processing of the velocity waveform.\n",
    "\n",
    "The process flow is the followings:\n",
    "\n",
    "\n",
    "- correct polarity for STF to be positive\n",
    "- convert from uz to M0\n",
    "- upsample the data: upsample to 1ns sample by linear interpolation\n",
    "  \n",
    "~~- detrending the velocity waveform~~\n",
    "- denoise with the multi-window detrend or the high-pass filter\n",
    "- integrate velocity to convert to the displacement waveform\n",
    "- align the STF for removing the offset: use the ~~max location of P wave pulse~~ left bottom amplitude, which is more stable than the onset of P.\n",
    "- remove the offset just before the onset\n",
    "- trim the margin, which includes the discontinuity due to the `roll`.\n",
    "- store the data to the HDF group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uz2M0dot(uz, k):\n",
    "    # k: k_M0uz converting from displacement to M0\n",
    "    return uz * k\n",
    "    \n",
    "def M0dot2uz(M0, k):\n",
    "    return M0/k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_upsampled = 1e-9 #1e-8 # upsampling STF to improve the measurement of HMPW\n",
    "trim_margin = 1.5e-6 # needs to be same when trimming the P wave\n",
    "trim_margin_k = int(trim_margin/dt_upsampled)\n",
    "\n",
    "# datasize\n",
    "tr_tmp = select_trace(st_repeat_Pdisp, AEsensor_list[0], datacases[0])\n",
    "tvec_origin = tr_tmp.times()\n",
    "tvec_upsampled = np.arange(tvec_origin[0], tvec_origin[-1], step=dt_upsampled)\n",
    "\n",
    "tvec_upsampled_margintrimmed = tvec_upsampled[trim_margin_k:-trim_margin_k]\n",
    "\n",
    "Ndata = len(tvec_upsampled)\n",
    "Ndata_nomargin = len(tvec_upsampled_margintrimmed)\n",
    "\n",
    "Ndata, Ndata_nomargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_margin_k, len(tvec_upsampled_margintrimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = sns.color_palette(\"colorblind\", as_cmap=True)\n",
    "lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The detrend is crucial to evaluating the seimic moment. We first compute the spline interpolation for the data points without the P wave displacement pulse, and remove it from the trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise_method = \"detrend\" #\"highpass\" # method for the denoising of long-period noise on the P wave pulse\n",
    "k_waterlevel = 0.3 # #0.25 #0.15\n",
    "\n",
    "\n",
    "fo = h5py.File(dataoutdir+f\"/STF_all_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.hdf5\", 'w')\n",
    "\n",
    "# parameters used to trim the waveforms\n",
    "pwin_pre = 20e-6 #3e-6\n",
    "pwin_len = 20e-6 # 6e-6\n",
    "trim_margin = 1.5e-6\n",
    "\n",
    "#---High-pass filter paramerters---#\n",
    "freqmin = 0.1e6 # apply highpass\n",
    "butterworth_order = 3\n",
    "\n",
    "#---Detrend parameters---#\n",
    "onset = trim_margin+pwin_pre\n",
    "polyfit_winlens = [15e-6, 5e-6, 15e-6]\n",
    "polyfit_Rcontinu_buffer = 2e-6\n",
    "# polyfit_smooth_winlen = 0.1e-7 #2e-6 #2e-6\n",
    "polyfit_smooth_lowpass_freqmax = 0.5e6 # trend is low-pass filtered to remove the discontinuities at the window boundaries \n",
    "polyords = [5,2,3]\n",
    "detrend_eventdata=dict()\n",
    "detrend_eventdata[\"vp\"] = 6200\n",
    "detrend_eventdata[\"vs\"] = 3600\n",
    "#------------------------#\n",
    "\n",
    "peak_winlen = 2.5e-6 # window length to search peak P\n",
    "noise_winlen = 10e-6 #4e-6 # noise time window before the LBA\n",
    "\n",
    "\n",
    "fo.create_group(\"param\")\n",
    "fo.create_dataset(f\"param/tvec_upsampled_margintrimmed\", data=tvec_upsampled_margintrimmed-trim_margin)\n",
    "fo[f\"param\"].attrs[\"dt_upsampled\"] = dt_upsampled\n",
    "fo[f\"param\"].attrs[\"pwin_pre\"] = pwin_pre\n",
    "fo[f\"param\"].attrs[\"pwin_len\"] = pwin_len\n",
    "fo[f\"param\"].attrs[\"trim_margin\"] = trim_margin\n",
    "\n",
    "fo[f\"param\"].attrs[\"denoise_method\"] = denoise_method.lower()\n",
    "\n",
    "if denoise_method.lower()==\"highpass\":\n",
    "    fo[f\"param\"].attrs[\"freqmin\"] = freqmin\n",
    "    fo[f\"param\"].attrs[\"butterworth_order\"] = butterworth_order\n",
    "\n",
    "elif denoise_method.lower()==\"detrend\":\n",
    "    fo[f\"param\"].attrs[\"polyfit_winlens\"] = polyfit_winlens\n",
    "    fo[f\"param\"].attrs[\"polyfit_Rcontinu_buffer\"] = polyfit_Rcontinu_buffer\n",
    "    fo[f\"param\"].attrs[\"polyfit_smooth_lowpass_freqmax\"] = polyfit_smooth_lowpass_freqmax\n",
    "    fo[f\"param\"].attrs[\"polyords\"] = polyords\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"denoise_method '{denoise_method}' not found.\")\n",
    "\n",
    "LBA_thresh_zerocross_ampfactor = 1.0 # 0.5\n",
    "LBA_slope_subtract_const = -3e10 # additional slope to find LBA\n",
    "\n",
    "for k, datacase in enumerate(tqdm(datacases)):\n",
    "\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "\n",
    "    fo.create_group(datacase)\n",
    "    fo[f\"{datacase}\"].attrs[\"gougeevent_id\"] = gougeevent_id\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "    ax2=ax.twinx()\n",
    "\n",
    "    STF_all = np.zeros((len(AEsensor_list), Ndata_nomargin))\n",
    "\n",
    "    df_trimP_coef_event = df_trimP_coef.loc[datacase] # coefficients on the event\n",
    "\n",
    "    # M0_noQcorr = fo[f\"{datacase}/tmp_noQcorr\"].attrs[\"M0_fromintegral\"]\n",
    "    M0_bestfit = df_bestparam.loc[datacase, :].M0_best\n",
    "\n",
    "    LBA_slope_subtract = copy.deepcopy(LBA_slope_subtract_const)\n",
    "    if np.isnan(M0_bestfit) | (M0_bestfit<0.03):#0.03):\n",
    "        LBA_slope_subtract *= 0.1 # decrease the additional negative slope to detect LBA\n",
    "        \n",
    "    for i, stnm in enumerate(AEsensor_list):\n",
    "    # stnm = AEsensor_list[0]\n",
    "\n",
    "        # create group\n",
    "        fo[datacase].create_group(stnm)\n",
    "\n",
    "#         tr_Pdisp = select_trace(st_repeat_Pdisp, stnm, datacase)\n",
    "        tr_Pvel = select_trace(st_repeat_Pvel, stnm, datacase)\n",
    "        caseindex = f\"{stnm}__{datacase}\"\n",
    "        assert tr_Pvel.stats.dataindex==caseindex\n",
    "\n",
    "        # correct polarity for STF to be positive\n",
    "        polarity = -1 * np.sign(tr_Pvel.stats.xi1) * np.sign(channel_loc[stnm][1])\n",
    "        tr_Pvel.data *= polarity\n",
    "\n",
    "        # convert from uz to M0\n",
    "        # tr_Pvel.data *= df_k_M0uz.loc[stnm].values[0]\n",
    "        # update: load from the dataframe\n",
    "        k_M0uz_event = df_trimP_coef_event[df_trimP_coef_event[\"OL\"]==stnm][\"k_M0uz\"].values[0]\n",
    "        # print(k_M0uz_event)\n",
    "        tr_Pvel.data *= k_M0uz_event\n",
    "        \n",
    "        # upsample the data\n",
    "        tvec_origin = tr_Pvel.times()\n",
    "\n",
    "        tr_Pvel_upsampled_data = np.interp(tvec_upsampled, tvec_origin, tr_Pvel.data)\n",
    "\n",
    "        \n",
    "        #-------------------------------------------#\n",
    "        # Denoise the long-period noise\n",
    "        #-------------------------------------------#\n",
    "        dev_tr_Pvel_upsampled_data_beforedenoise = copy.deepcopy(tr_Pvel_upsampled_data)\n",
    "\n",
    "        if denoise_method.lower()==\"highpass\":\n",
    "            b, a = signal.butter(butterworth_order, freqmin, 'highpass', fs=(1/dt_upsampled), output='ba')\n",
    "            # apply tapering\n",
    "            win = signal.windows.tukey(len(tr_Pvel_upsampled_data), 0.05)\n",
    "            tr_Pvel_upsampled_data *= win\n",
    "            tr_Pvel_upsampled_data= signal.filtfilt(b, a, tr_Pvel_upsampled_data, method='gust') # using Gustafsson’s method\n",
    "\n",
    "        \n",
    "        elif denoise_method.lower()==\"detrend\":\n",
    "            # store for detrending\n",
    "            detrend_eventdata[\"k_M0uz_event\"] = k_M0uz_event\n",
    "            detrend_eventdata[\"source_dist\"] = df_trimP_coef_event[df_trimP_coef_event[\"OL\"]==stnm][\"rdist\"].values[0] # [m]\n",
    "            detrend_eventdata[\"datacase\"] = datacase\n",
    "            detrend_eventdata[\"stnm\"] = stnm\n",
    "            detrend_eventdata[\"P_onset\"] = onset\n",
    "\n",
    "            figdir_debug = f\"../figure/03_computePdisp/Denoise_noQcorr/{denoise_method.lower()}/{stnm}/\"\n",
    "            if not os.path.exists(figdir_debug):\n",
    "                os.makedirs(figdir_debug)\n",
    "            detrend_eventdata[\"figname\"] = figdir_debug+f\"debug_{datacase}_{stnm}_detrend.png\"\n",
    "\n",
    "\n",
    "            # b_debug, a_debug = signal.butter(3, 1e6, 'lowpass', fs=(1/dt_upsampled), output='ba')\n",
    "            # # UPDATE: two-way filtering to better retrieve the STF\n",
    "            # # tr_Pvel_upsampled_data_raw_lowpass = signal.sosfiltfilt(sos_beforedecon, tr_Pvel_upsampled_data_raw)\n",
    "            # tr_Pvel_upsampled_data = signal.filtfilt(b_debug, a_debug, tr_Pvel_upsampled_data, method='gust')\n",
    "            # if (gougeevent_id, stnm) in [(126, \"OL22\"),]:\n",
    "            #     # the onset needs to be shifted \n",
    "            #     onset_shifted = onset-1e-6\n",
    "            # else:\n",
    "            #     onset_shifted = onset\n",
    "\n",
    "            # tr_Pvel_upsampled_data = tr_Pvel_upsampled_data - tr_Pvel_upsampled_data[int(onset/dt_upsampled)]\n",
    "            debug_tr_Pvel_upsampled_data = copy.deepcopy(tr_Pvel_upsampled_data)\n",
    "            tr_Pvel_upsampled_data = STF_multiwindow_detrend(tvec_upsampled, tr_Pvel_upsampled_data, onset, polyfit_winlens, \n",
    "                            polyfit_Rcontinu_buffer, polyfit_smooth_lowpass_freqmax, polyords=polyords, debugplot=True, eventdata=detrend_eventdata)\n",
    "\n",
    "            \n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "        #------------------------#\n",
    "        #---integrate velocity to convert from the velocity to the displacement---#\n",
    "        #------------------------#\n",
    "        tr_Pdisp_upsampled_data = integrate.cumulative_trapezoid(tr_Pvel_upsampled_data, dx=dt_upsampled, initial=0)\n",
    "\n",
    "        #------------------------#\n",
    "        #---Search left bottom amplitude (LBA)---#\n",
    "        #------------------------#\n",
    "        # 1. compute the slope before the pick\n",
    "        slope_st = int((pwin_pre+trim_margin-2e-6)/dt_upsampled)\n",
    "        slope_et = int((pwin_pre+trim_margin)/dt_upsampled)\n",
    "        LBA_slope_k_poly = np.polynomial.polynomial.polyfit(tvec_upsampled[slope_st:slope_et], tr_Pdisp_upsampled_data[slope_st:slope_et], 1)\n",
    "        # print(LBA_slope_k_poly)\n",
    "\n",
    "        tr_Pdisp_updampled_data_forLBApick = copy.deepcopy(tr_Pdisp_upsampled_data) # this is used to pick the LBA\n",
    "\n",
    "        # Adjust the slope to find LBA\n",
    "        if LBA_slope_k_poly[1]>=0: # for new poly API, the slope is the poly[1]\n",
    "            # print(f\"{datacase} slope positive\", stnm, LBA_slope_k_poly[1])\n",
    "            LBA_newslope = LBA_slope_k_poly[1] + LBA_slope_subtract # added extra slope to make STF_slope negative after subtraction\n",
    "            tr_Pdisp_updampled_data_forLBApick += np.polynomial.polynomial.polyval(tvec_upsampled, [LBA_slope_k_poly[0], LBA_newslope]) # subtract slope to detect LBA\n",
    "\n",
    "        # Adjust by sensors\n",
    "        if (gougeevent_id, stnm) in [(43, \"OL08\"),]:\n",
    "            # slope is too small; add the slope\n",
    "            # print(stnm, LBA_slope_k_poly[1])\n",
    "            LBA_newslope = LBA_slope_k_poly[1] + 1.0*LBA_slope_subtract # added extra slope to make STF_slope negative after subtraction\n",
    "            tr_Pdisp_updampled_data_forLBApick += np.polynomial.polynomial.polyval(tvec_upsampled, [LBA_slope_k_poly[0], LBA_newslope]) # subtract slope to detect LBA\n",
    "        \n",
    "        # if (gougeevent_id, stnm) in [(30, \"OL08\")]:\n",
    "        #     # slope is too steep; put back\n",
    "        #     # print(stnm, LBA_slope_k_poly[1])\n",
    "        #     LBA_newslope = LBA_slope_k_poly[1] + 0.5*LBA_slope_subtract # added extra slope to make STF_slope negative after subtraction\n",
    "        #     tr_Pdisp_updampled_data_forLBApick -= np.polynomial.polynomial.polyval(tvec_upsampled, [LBA_slope_k_poly[0], LBA_newslope]) # subtract slope to detect LBA\n",
    "        \n",
    "        # if (gougeevent_id, stnm) in [(19, \"OL08\")]:\n",
    "        #     # slope is too steep; put back\n",
    "        #     # print(stnm, LBA_slope_k_poly[1])\n",
    "        #     LBA_newslope = LBA_slope_k_poly[1] +0.7*LBA_slope_subtract # added extra slope to make STF_slope negative after subtraction\n",
    "        #     tr_Pdisp_updampled_data_forLBApick -= np.polynomial.polynomial.polyval(tvec_upsampled, [LBA_slope_k_poly[0], LBA_newslope]) # subtract slope to detect LBA\n",
    "  \n",
    "        \n",
    "        # pick the LBA as it is\n",
    "        STF_grad = np.gradient(tr_Pdisp_updampled_data_forLBApick)\n",
    "\n",
    "        # https://stackoverflow.com/a/3843124\n",
    "        zero_crossings = np.where(np.diff(np.sign(STF_grad)) > 0)[0]\n",
    "\n",
    "        #         min_list = zero_crossings\n",
    "        min_list = []\n",
    "\n",
    "        # remove if the amplitude of peak is greater than the threshold\n",
    "        for zeroid in zero_crossings:\n",
    "            # print(tr_Pdisp_updampled_data_forLBApick[zeroid] , LBA_thresh_zerocross_ampfactor * np.max(tr_Pdisp_updampled_data_forLBApick))\n",
    "            if tr_Pdisp_updampled_data_forLBApick[zeroid] < LBA_thresh_zerocross_ampfactor * np.max(tr_Pdisp_updampled_data_forLBApick):\n",
    "                min_list.append(zeroid)\n",
    "\n",
    "        min_list = np.array(min_list)\n",
    "\n",
    "        # update: except buffer the ID50 OL 08\n",
    "        # if (gougeevent_id == 50) & (stnm==\"OL08\"):\n",
    "            # LBA_buffer_winlen = 1.2e-6 # Use longer buffer on the event\n",
    "        # else:\n",
    "            # LBA_buffer_winlen = 1.0e-6 # standard value for the LBA buffer\n",
    "        LBA_buffer_winlen = 1.0e-6 # standard value for the LBA buffer\n",
    "        \n",
    "        try:\n",
    "            LBA_ind = min_list[np.where(int((pwin_pre+trim_margin+LBA_buffer_winlen)/dt_upsampled) - min_list > 0)[0][-1]] # search the first bump of STF; 1.2us as buffer of search window\n",
    "        except:\n",
    "            print(f\"{datacase} {stnm} no LBA found\")\n",
    "            LBA_ind = int(np.round((pwin_pre+trim_margin)/dt_upsampled)) #use original tpick #0\n",
    "            \n",
    "        LBA_amp = tr_Pdisp_upsampled_data[LBA_ind]\n",
    "        LBA_t = tvec_upsampled[LBA_ind]\n",
    "\n",
    "        #------------------------#\n",
    "        #---Time shift STF---#\n",
    "        #------------------------#       \n",
    "\n",
    "\n",
    "        STF_tshift_k = int(((pwin_pre+trim_margin)-LBA_t)/dt_upsampled) # time shift with LBA location\n",
    "        # print(STF_tshift_k)\n",
    "        valid_flag_timeshift = 1\n",
    "        if np.abs(STF_tshift_k)>int(trim_margin/dt_upsampled):\n",
    "            # print(f\"{datacase} {stnm} time shift too large.\")\n",
    "            # time shift is too large; set time shift as the original tpick\n",
    "            LBA_ind = int(np.round((pwin_pre+trim_margin)/dt_upsampled)) #use original tpick #0\n",
    "            LBA_amp = tr_Pdisp_upsampled_data[LBA_ind]\n",
    "            LBA_t = tvec_upsampled[LBA_ind]\n",
    "            STF_tshift_k = int(((pwin_pre+trim_margin)-LBA_t)/dt_upsampled) # time shift with LBA location\n",
    "            valid_flag_timeshift = 0\n",
    "           \n",
    "\n",
    "        tr_Pvel_upsampled_data = np.roll(tr_Pvel_upsampled_data, STF_tshift_k)\n",
    "        tr_Pdisp_upsampled_data = np.roll(tr_Pdisp_upsampled_data, STF_tshift_k)\n",
    "        \n",
    "        # tr_vel_poly = np.roll(tr_vel_poly, STF_tshift_k)\n",
    "        dev_tr_Pvel_upsampled_data_beforedenoise = np.roll(dev_tr_Pvel_upsampled_data_beforedenoise, STF_tshift_k)\n",
    "        # tr_detrend_merged_smoothed = np.roll(tr_detrend_merged_smoothed, STF_tshift_k)\n",
    "        \n",
    "        #------------------------#\n",
    "        #---Remove the offset---#\n",
    "        #------------------------#\n",
    "        tr_Pdisp_upsampled_data -= LBA_amp # offset removed with the LBA\n",
    "\n",
    "        \n",
    "        # trim the margin to remove the effect of the roll\n",
    "        tr_Pvel_upsampled_data_margintrimmed = tr_Pvel_upsampled_data[trim_margin_k:-trim_margin_k]\n",
    "        tr_Pdisp_upsampled_data_margintrimmed = tr_Pdisp_upsampled_data[trim_margin_k:-trim_margin_k]\n",
    "\n",
    "        dev_tr_Pvel_upsampled_data_beforedenoise_margintrimmed = dev_tr_Pvel_upsampled_data_beforedenoise[trim_margin_k:-trim_margin_k]\n",
    "        # tr_detrend_merged_smoothed_margintrimmed = tr_detrend_merged_smoothed[trim_margin_k:-trim_margin_k]\n",
    "\n",
    "      \n",
    "        # store to HDF5\n",
    "        fo.create_dataset(f\"{datacase}/{stnm}/noQcorr/M0dot\", data=tr_Pdisp_upsampled_data_margintrimmed)\n",
    "        fo[f\"{datacase}/{stnm}\"].attrs[\"k_M0uz\"] = k_M0uz_event #df_k_M0uz\n",
    "        fo[f\"{datacase}/{stnm}\"].attrs[\"polarity\"] = polarity\n",
    "\n",
    "        # store LBA\n",
    "        LBA_ind_shifted = LBA_ind + STF_tshift_k - int(trim_margin_k)\n",
    "        LBA_amp_shifted = tr_Pdisp_upsampled_data_margintrimmed[LBA_ind_shifted]\n",
    "        LBA_t_shifted = pwin_pre\n",
    "        # print(LBA_ind_shifted, LBA_amp_shifted, LBA_t_shifted)\n",
    "        \n",
    "        fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"LBA_ind\"] = LBA_ind_shifted # one gridpoint varies due to the rounding of time shift\n",
    "        fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"LBA_amp\"] = LBA_amp_shifted\n",
    "        fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"LBA_t\"] = LBA_t_shifted\n",
    "\n",
    "        #------------------------#\n",
    "        #---Compute noise level---#\n",
    "        #------------------------#\n",
    "        # compute RMSE of noise\n",
    "        st_noise = np.max([0, LBA_ind_shifted-int(noise_winlen/dt_upsampled)])\n",
    "        et_noise = LBA_ind_shifted\n",
    "        noise_rmse = np.sqrt(np.mean((tr_Pdisp_upsampled_data_margintrimmed[st_noise:et_noise]**2))) # evaluate noise RMSE\n",
    "        noise_std = np.std(tr_Pdisp_upsampled_data_margintrimmed[st_noise:et_noise]) # evaluate noise STD\n",
    "        noise_peak = np.max(np.abs(tr_Pdisp_upsampled_data_margintrimmed[st_noise:et_noise])) \n",
    "\n",
    "        # compute peak P amp\n",
    "        st_pmax = LBA_ind_shifted\n",
    "        et_pmax = LBA_ind_shifted + int(peak_winlen/dt_upsampled)\n",
    "        pmax = np.max(tr_Pdisp_upsampled_data_margintrimmed[st_pmax:et_pmax])\n",
    "        \n",
    "        # SNR_sensor = pmax/noise_rmse\n",
    "        SNR_sensor = pmax/noise_std\n",
    "        # SNR_sensor = pmax/noise_peak\n",
    "\n",
    "        # print(noise_rmse, pmax, SNR_sensor)\n",
    "        fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"noise_rmse\"] = noise_rmse\n",
    "        fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"noise_peak\"] = noise_peak\n",
    "        fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"pmax\"] = pmax\n",
    "        fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"SNR_sensor\"] = SNR_sensor\n",
    "\n",
    "        STF_all[i, :] = tr_Pdisp_upsampled_data_margintrimmed\n",
    "        \n",
    "        # ax.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, tr_Pdisp_upsampled_data_margintrimmed/1e6, \"-\", c=lc[i], label=f\"{stnm}\", lw=2)\n",
    "        ax.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, tr_Pdisp_upsampled_data_margintrimmed/1e6/M0_bestfit, \"-\", c=lc[i], label=f\"{stnm}\", lw=2)\n",
    "\n",
    "        \n",
    "        # plot velocity waveform as twin axis\n",
    "        if i==0:\n",
    "            vellabel=\"velocity w. detrend\"\n",
    "            vellabel2=\"velocity no detrend\"\n",
    "            vellabel3=\"trend merged\"\n",
    "        else:\n",
    "            vellabel=None\n",
    "            vellabel2=None\n",
    "            vellabel3=None\n",
    "            \n",
    "        ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, tr_Pvel_upsampled_data_margintrimmed/k_M0uz_event*1e3, \":\", c=lc[i], label=vellabel, lw=2)\n",
    "        ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, dev_tr_Pvel_upsampled_data_beforedenoise_margintrimmed/k_M0uz_event*1e3, \"--\", c=lc[i], label=vellabel2, lw=1)\n",
    "\n",
    "        ax2.set_ylabel('Velocity [mm/s]')\n",
    "\n",
    "\n",
    "    ax.axvspan(0, pwin_pre*1e6, facecolor='gray', alpha=0.1)\n",
    "    ax.axvspan((pwin_pre+polyfit_winlens[1])*1e6, (pwin_pre+pwin_len)*1e6, facecolor='gray', alpha=0.1)\n",
    "    \n",
    "    h1, l1 = ax.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(h1+h2, l1+l2, loc=1, bbox_to_anchor=(1.7, 1.05))\n",
    "\n",
    "    ax.set_xlabel(\"Time [μs]\")\n",
    "    ylabelstr = r\"$\\dot{M}_0(t)$\"\n",
    "    # ax.set_ylabel(r\"{} [MNm/s]\".format(ylabelstr)) # The unit is in MNm/s\n",
    "    ax.set_ylabel(r\"Normalized {}\".format(ylabelstr)) # The unit is in MNm/s\n",
    "\n",
    "\n",
    "    # ax.set_xlim([0, 24])\n",
    "    ax.set_ylim([-1.2, 1.2])\n",
    "    # ax.set_ylim([-0.4, 0.4])\n",
    "\n",
    "    ax2.set_ylim([-0.6, 0.6])\n",
    "    \n",
    "    ax.set_title(f\"{gougepatch_id} {datacase} {M0_bestfit:.2f}Nm\")\n",
    "\n",
    "    figdir_noQcorr = f\"../figure/03_computePdisp/STF_noQcorr/{denoise_method}\"\n",
    "    if not os.path.exists(figdir_noQcorr):\n",
    "        os.makedirs(figdir_noQcorr)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figdir_noQcorr+f\"/STF_{gougepatch_id}_{datacase}_denoisemethod_{denoise_method}.png\", format=\"png\", dpi=80, bbox_inches='tight')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(debug_tr_Pvel_upsampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_Pdisp_updampled_data_forLBApick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBA_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STF_tshift_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(((pwin_pre+trim_margin)-LBA_t)/dt_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pwin_pre+trim_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBA_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot after time shifted: the gap is caused due to the roll, which will be trimmed by the margin\n",
    "plt.plot(tvec_upsampled, tr_Pdisp_upsampled_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_Pdisp_upsampled_data[int((trim_margin+pwin_pre)/dt_upsampled):int((trim_margin+pwin_pre+peak_winlen)/dt_upsampled)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(tr_Pdisp_upsampled_data[int((trim_margin+pwin_pre)/dt_upsampled):int((trim_margin+pwin_pre+peak_winlen)/dt_upsampled)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Here we skipped the process of evaluating HMPW. We will evaluate the quality of the STF when fitting the STF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolve the attenuation factor $Q^{-1}$\n",
    "\n",
    "$$y(\\omega) = s(\\omega)G(\\omega; \\mathbf{x})  B(\\omega), $$\n",
    "where\n",
    "\n",
    "$$ B(\\omega) =\\exp{\\left( - \\dfrac{\\omega t}{2 Q(\\omega)} \\right) } .$$\n",
    "\n",
    "For the far-field P wave pulse is written as\n",
    "\n",
    "$$ u^{FP}(t) = \\dfrac{1}{4 \\pi \\rho \\alpha^3} \\dfrac{1}{R} A^{FP} \\dot{M}_0 (t) $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$ y^{FP}(\\omega) = C \\dot{M}_0 (\\omega) B(\\omega), $$\n",
    "\n",
    "where $C$ is a constant including radiation pattern, source distance, density and wave speed.\n",
    "\n",
    "For the case without attenuation, the source time function can be estimated as \n",
    "\n",
    "$$ \\dot{M}_0 (\\omega) = y^{FP}(\\omega)/C. $$\n",
    "\n",
    "However, when considering the attenuation factor, we need to deconvolve it as follows:\n",
    "\n",
    "$$ \\dot{M}_0 (\\omega) = y^{FP}(\\omega)/\\{CB(\\omega)\\}. $$\n",
    "\n",
    "\n",
    "We next deconvolve the attenuation factor from the STF and repeat the analysis of source parameters.\n",
    "\n",
    "The coefficient $C$ is already computed in the processing above. From this section, we compute the deconvolution with the waterlevel  \n",
    "\n",
    "$$ \\dot{M}_0 (t) = \\mathcal{F}^{-1} \\dfrac{y(\\omega)/C}{\\max \\{|B(\\omega)|, k|B(\\omega)| \\}}, $$ \n",
    "\n",
    "to estimate the \"true\" source time function and its source parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Qinv(freq, fq, Qinv):\n",
    "    # interpolate the Q from the Qinv data\n",
    "    cs = CubicSpline(fq, Qinv)\n",
    "    \n",
    "    Qinv_interp = np.zeros(len(freq))\n",
    "    for i, ff in enumerate(freq):\n",
    "        if ff<fq[0]:\n",
    "            Qinv_interp[i] = Qinv[0] # extrapolate the minimum frequency Qinv\n",
    "        elif ff>fq[-1]:\n",
    "            Qinv_interp[i] = Qinv[-1] # extrapolate the maximum frequency Qinv\n",
    "        else:\n",
    "            Qinv_interp[i] = cs(ff)  \n",
    "                \n",
    "    return Qinv_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of deconvolution\n",
    "Ndata_FFT = len(tvec_upsampled)\n",
    "# NFFT = 2**(Ndata-1).bit_length()\n",
    "NFFT = Ndata_FFT # same length of the data for the sake of simplicity\n",
    "print(Ndata_FFT, NFFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Qinv_quantile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reading the Qinv\n",
    "F_freq = np.fft.rfftfreq(NFFT, d=dt_upsampled)\n",
    "\n",
    "for iq in [25, 50, 75]:\n",
    "    Qinv = get_Qinv(F_freq, df_Qinv_quantile.freq.values*1e6, df_Qinv_quantile[f\"Qinv_{iq}\"].values).astype(complex)\n",
    "    plt.loglog(F_freq/1e6, Qinv.real, \".-\")\n",
    "    \n",
    "plt.xlim([0.1, 2])\n",
    "plt.ylim([0.002, 0.2])\n",
    "plt.xlabel(\"Frequency [MHz]\")\n",
    "plt.ylabel(\"Attenuation, $Q^{-1}$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reading the Qinv\n",
    "F_freq = np.fft.rfftfreq(NFFT, d=dt_upsampled)\n",
    "\n",
    "for iq in [25, 50, 75]:\n",
    "    Qinv = get_Qinv(F_freq, df_Qinv_quantile.freq.values*1e6, df_Qinv_quantile[f\"Qinv_{iq}\"].values).astype(complex)\n",
    "    plt.semilogx(F_freq/1e6, 1/Qinv.real, \".-\")\n",
    "    \n",
    "plt.xlim([0.1, 2])\n",
    "# plt.ylim([0.002, 0.2])\n",
    "plt.xlabel(\"Frequency [MHz]\")\n",
    "plt.ylabel(\"Attenuation, $Q^{-1}$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute attenuation factor and deconvolve it from STF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = h5py.File(dataoutdir+f\"/STF_all_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.hdf5\", 'r+')\n",
    "\n",
    "F_freq = np.fft.rfftfreq(NFFT, d=dt_upsampled)\n",
    "vp = 6200 #[m/s]\n",
    "\n",
    "k_waterlevel_debugplot = k_waterlevel # 0.3 #0.15  #0.3 # We searched the best value by trial and error.\n",
    "\n",
    "# for Qinv_quart in [25, 50, 75]:\n",
    "for Qinv_quart in [25, 50]:\n",
    "#     Qinv_quart = 50\n",
    "       \n",
    "    # get interpolated Q^{-1}\n",
    "    Qinv_interp = get_Qinv(F_freq, df_Qinv_quantile.freq.values*1e6, df_Qinv_quantile[f\"Qinv_{Qinv_quart}\"].values).astype(float)\n",
    "    if f\"Qinv_{Qinv_quart}\" in fo[f\"{datacase}\"].keys():\n",
    "        del fo[f\"{datacase}/Qinv_{Qinv_quart}\"]\n",
    "        \n",
    "    fo.create_dataset(f\"{datacase}/Qinv_{Qinv_quart}\", data=Qinv_interp.real)\n",
    "\n",
    "    for k, datacase in enumerate(tqdm(datacases)):\n",
    "    #     print(datacase)\n",
    "#         fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "    \n",
    "        df_trimP_coef_event = df_trimP_coef.loc[datacase] # coefficients on the event\n",
    "\n",
    "        for i, stnm in enumerate(AEsensor_list):\n",
    "\n",
    "        # Compute attenuation factor\n",
    "            \n",
    "            # debug_source_dist = df_AEevents_isocoord.loc[f\"{stnm}__{datacase}\", \"rlen_sourcedist\"] # [m]\n",
    "            # Update: use the source distance for each event\n",
    "            source_dist = df_trimP_coef_event[df_trimP_coef_event[\"OL\"]==stnm][\"rdist\"].values[0] # [m]\n",
    "            # print(source_dist)\n",
    "            tt = source_dist/vp\n",
    "            # print(f\"{stnm} {source_dist}m,  {tt*1e6:.2f}μs\")\n",
    "\n",
    "            Bomega_interp = np.exp(-np.pi * F_freq * tt * Qinv_interp)\n",
    "\n",
    "            # store to the hdf5\n",
    "            if f\"Bomega_{Qinv_quart}\" in fo[f\"{datacase}/{stnm}\"].keys():\n",
    "                del fo[f\"{datacase}/{stnm}/Bomega_{Qinv_quart}\"]\n",
    "            fo.create_dataset(f\"{datacase}/{stnm}/Bomega_{Qinv_quart}\", data=Bomega_interp)\n",
    "            \n",
    "            # debug plot Bomega with waterlevel\n",
    "            Bomega_wlv = np.maximum(np.abs(Bomega_interp), (k_waterlevel_debugplot*np.abs(Bomega_interp).max()))\n",
    "            ax.plot(F_freq/1e6, Bomega_interp, \":\", c=lc[i], label=\"\")\n",
    "            ax.plot(F_freq/1e6, Bomega_wlv, \".-\", c=lc[i], label=stnm)\n",
    "            \n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.legend(loc=1)\n",
    "        ax.set_xlim([0.06, 2])\n",
    "        ax.set_ylim([0.06, 1.2])\n",
    "        ax.set_xlabel(\"Frequency [MHz]\")\n",
    "        ax.set_ylabel(r\"$B(\\omega)$\")\n",
    "        \n",
    "        figdir_Bomega = \"../figure/03_computePdisp/Bomega_debug\"\n",
    "        if not os.path.exists(figdir_Bomega):\n",
    "            os.makedirs(figdir_Bomega)\n",
    "    \n",
    "\n",
    "        ax.set_title(f\"{gougepatch_id} {datacase} Q{Qinv_quart}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figdir_Bomega+f\"/Bomega_{gougepatch_id}_{datacase}_Q{Qinv_quart}.png\", format=\"png\", dpi=80)\n",
    "\n",
    "        plt.close()\n",
    "        plt.clf()\n",
    "        \n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-analyze the source time function with the deconvolution\n",
    "\n",
    "We repeat the processes as the `noQcorr` with the deconvolution of attenuation factor. We deconvolve it from the velocity waveform with the margin so that we can detrend  the effect of deconvolution as well as trim the edge effect of the deconvolution.\n",
    "\n",
    "### process flow\n",
    "\n",
    "1. load velocity pulse with trim margin\n",
    "2. correct the polarity\n",
    "3. scale from uz to M0\n",
    "4. upsampling\n",
    "5. deconvolve attenuation factor and **apply tapering before detrend to remove edge effect**\n",
    "6. integrate to convert from velocity to displacement\n",
    "7. search left bottom amplitude **updated process**\n",
    "> The threshold is that the LBA is selected from the first zero-crossing with the LBA_buffer.\n",
    "> To improve the detection of LBA, the slope before the pulse arrival is evaluated as negative.\n",
    "8. Shift the time at the LBA align to the pre_winlen\n",
    "9. remove the offset by the value of LBA\n",
    "10. trim the margin\n",
    "11. store to the HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to search the LBA\n",
    "\n",
    "To make the searching algorithm robust, we first compute the slope of the window before the arrival of pulse. If the slope is positive, i.e., no bump at the LBA, we subtract the slope to pick the LBA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwin_pre, trim_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndata_FFT, Ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the displacement pulse with the deconvolution of attenuation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_waterlevel = 0.3 #0.3 #0.25 #0.15\n",
    "\n",
    "# LBA_buffer_winlen = 1.0e-6 # define in the loop #1e-6 # search LBA from prewin + trimmargin + LBA_buffer_winlen with the closest LBA\n",
    "LBA_thresh_zerocross_ampfactor = 0.5\n",
    "LBA_slope_subtract_const = -3e10\n",
    "\n",
    "fo = h5py.File(dataoutdir+f\"/STF_all_{gougepatch_id}_Q{Qinv_quart}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.hdf5\", 'r+')\n",
    "\n",
    "fo[f\"param\"].attrs[\"NFFT\"] = NFFT\n",
    "fo[f\"param\"].attrs[\"k_waterlevel\"] = k_waterlevel\n",
    "\n",
    "\n",
    "# low-pass filter\n",
    "decon_freqmax = 1e6\n",
    "butterworth_order = 3 #5 : order does not affect the result\n",
    "\n",
    "# assign with respect to the events\n",
    "# polyfit_onset_shift_Qdeconv = 1.5e-6 # shift the onset due to the acausal Q deconvolution\n",
    "# polyfit_winlens_Qdeconv = copy.deepcopy(polyfit_winlens)\n",
    "# polyfit_winlens_Qdeconv[1] += polyfit_onset_shift_Qdeconv\n",
    "\n",
    "for k, datacase in enumerate(tqdm(datacases)):\n",
    "\n",
    "#     datacase = datacases_selected[9]\n",
    "\n",
    "    figdir_Qcorr = f\"../figure/03_computePdisp/STF_Q{Qinv_quart}\"\n",
    "    if not os.path.exists(figdir_Qcorr):\n",
    "        os.makedirs(figdir_Qcorr)\n",
    "\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 9))\n",
    "    ax2=ax.twinx()\n",
    "\n",
    "    STF_decon_all = np.zeros((len(AEsensor_list), Ndata))\n",
    "    STF_all = np.zeros((len(AEsensor_list), Ndata_nomargin))\n",
    "\n",
    "    yshift = 0\n",
    "    yshift2 = 0\n",
    "\n",
    "    # debug plot for detrending\n",
    "    figdir_detrend = f\"../figure/03_computePdisp/debug_detrend_Q{Qinv_quart}\"\n",
    "    if not os.path.exists(figdir_detrend):\n",
    "        os.makedirs(figdir_detrend)\n",
    "    fig_det, ax_det = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    df_trimP_coef_event = df_trimP_coef.loc[datacase] # coefficients on the event\n",
    "\n",
    "    LBA_slope_subtract = copy.deepcopy(LBA_slope_subtract_const)\n",
    "    # M0_noQcorr = fo[f\"{datacase}/tmp_noQcorr\"].attrs[\"M0_fromintegral\"]\n",
    "    M0_bestfit = df_bestparam.loc[datacase, :].M0_best\n",
    "    # if np.isnan(M0_noQcorr) | (M0_noQcorr<0.02):\n",
    "    if np.isnan(M0_bestfit) | (M0_bestfit<0.03):\n",
    "        # debug_plot_scalefactor = 8\n",
    "        LBA_slope_subtract *= 0.1 # decrease the additional negative slope to detect LBA\n",
    "    # else:\n",
    "    #     debug_plot_scalefactor = 1\n",
    "    \n",
    "    for i, stnm in enumerate(AEsensor_list):\n",
    "\n",
    "        tr_Pvel = select_trace(st_repeat_Pvel, stnm, datacase) # re-read P velocity waveform\n",
    "        caseindex = f\"{stnm}__{datacase}\"\n",
    "        assert tr_Pvel.stats.dataindex==caseindex\n",
    "\n",
    "        # correct polarity to be positive\n",
    "        polarity = -1 * np.sign(tr_Pvel.stats.xi1) * np.sign(channel_loc[stnm][1])\n",
    "        tr_Pvel.data *= polarity\n",
    "\n",
    "        # convert from uz to M0\n",
    "        # tr_Pvel.data *= df_k_M0uz.loc[stnm].values[0]\n",
    "        # update: load from the dataframe\n",
    "        k_M0uz_event = df_trimP_coef_event[df_trimP_coef_event[\"OL\"]==stnm][\"k_M0uz\"].values[0]\n",
    "        tr_Pvel.data *= k_M0uz_event\n",
    "        \n",
    "        # upsample the data\n",
    "        tvec_origin = tr_Pvel.times()\n",
    "\n",
    "        tr_Pvel_upsampled_data_raw = np.interp(tvec_upsampled, tvec_origin, tr_Pvel.data)\n",
    "\n",
    "        # variable for debug plots\n",
    "        dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ = copy.deepcopy(tr_Pvel_upsampled_data_raw) # copy the original velocity waveform\n",
    "        dev_tr_Pdisp_upsampled_data_nodetrend_nodeconvQ = integrate.cumulative_trapezoid(tr_Pvel_upsampled_data_raw, dx=dt_upsampled, initial=0)\n",
    "\n",
    "        #-----------------------------------#\n",
    "        #---Deconvolve attenuation factor---#\n",
    "        #-----------------------------------#\n",
    "        ## Update: Apply low-pass before the deconvolution\n",
    "        # sos_beforedecon = signal.butter(butterworth_order, decon_freqmax, 'lowpass', fs=(1/dt_upsampled), output='sos')\n",
    "        b_beforedecon, a_beforedecon = signal.butter(butterworth_order, decon_freqmax, 'lowpass', fs=(1/dt_upsampled), output='ba')\n",
    "\n",
    "        # UPDATE: two-way filtering to better retrieve the STF\n",
    "        # tr_Pvel_upsampled_data_raw_lowpass = signal.sosfiltfilt(sos_beforedecon, tr_Pvel_upsampled_data_raw)\n",
    "        tr_Pvel_upsampled_data_raw_lowpass = signal.filtfilt(b_beforedecon, a_beforedecon, tr_Pvel_upsampled_data_raw, method='gust')\n",
    "\n",
    "        Bomega_interp = fo[f\"{datacase}/{stnm}/Bomega_{Qinv_quart}\"]\n",
    "        # F_obs = np.fft.rfft(tr_Pvel_upsampled_data_raw, n=NFFT)\n",
    "        F_obs = np.fft.rfft(tr_Pvel_upsampled_data_raw_lowpass, n=NFFT)\n",
    "        Bomega_wlv = np.maximum(np.abs(Bomega_interp), (k_waterlevel*np.abs(Bomega_interp).max()))\n",
    "        y_obs_Qremoved = np.fft.irfft(F_obs/Bomega_wlv).real # divide the spectra by the attenuation factor\n",
    "        tr_Pvel_upsampled_data = y_obs_Qremoved # velocity waveform after deconvolution of attenuation\n",
    "        \n",
    "        # Apply tukey taper with 10% of edge, which will be trimmed as margin, but it is required to detrend the waveform\n",
    "        tukeywin = signal.windows.tukey(len(tr_Pvel_upsampled_data), alpha=0.1, sym=True)\n",
    "        tr_Pvel_upsampled_data *= tukeywin\n",
    "        #-----------------------------------#\n",
    "        dev_tr_Pvel_upsampled_data_nodetrend_withdeconvQ = copy.deepcopy(tr_Pvel_upsampled_data)\n",
    "       \n",
    "        # if stnm==\"OL08\":\n",
    "            # tr_debug = copy.deepcopy(tr_Pvel_upsampled_data)\n",
    "\n",
    "         #-------------------------------------------#\n",
    "        # Denoise the long-period noise\n",
    "        #-------------------------------------------#\n",
    "        dev_tr_Pvel_upsampled_data_beforedenoise = copy.deepcopy(tr_Pvel_upsampled_data)\n",
    "\n",
    "        if denoise_method.lower()==\"highpass\":\n",
    "            b, a = signal.butter(butterworth_order, freqmin, 'highpass', fs=(1/dt_upsampled), output='ba')\n",
    "            # apply tapering\n",
    "            win = signal.windows.tukey(len(tr_Pvel_upsampled_data), 0.05)\n",
    "            tr_Pvel_upsampled_data *= win\n",
    "            tr_Pvel_upsampled_data= signal.filtfilt(b, a, tr_Pvel_upsampled_data, method='gust') # using Gustafsson’s method\n",
    "\n",
    "        \n",
    "        elif denoise_method.lower()==\"detrend\":\n",
    "            # print(datacase, stnm)\n",
    "            # store for detrending\n",
    "            detrend_eventdata[\"k_M0uz_event\"] = k_M0uz_event\n",
    "            detrend_eventdata[\"source_dist\"] = df_trimP_coef_event[df_trimP_coef_event[\"OL\"]==stnm][\"rdist\"].values[0] # [m]\n",
    "            detrend_eventdata[\"datacase\"] = datacase\n",
    "            detrend_eventdata[\"stnm\"] = stnm\n",
    "            detrend_eventdata[\"P_onset\"] = onset\n",
    "            \n",
    "            figdir_debug = f\"../figure/03_computePdisp/Denoise_Q{Qinv_quart}/{denoise_method.lower()}/{stnm}/\"\n",
    "            if not os.path.exists(figdir_debug):\n",
    "                os.makedirs(figdir_debug)\n",
    "            detrend_eventdata[\"figname\"] = figdir_debug+f\"debug_{datacase}_{stnm}_Q{Qinv_quart}_detrend.png\"\n",
    "\n",
    "            # set the onset time shift\n",
    "            if (gougeevent_id, stnm) in [(30, \"OL22\"),  (44, \"OL22\"), (50, \"OL22\"), (110, \"OL22\")]:\n",
    "                # correct the onset shift\n",
    "                polyfit_onset_shift_Qdeconv = 0.5e-6\n",
    "\n",
    "            elif (gougeevent_id, stnm) in [(88, \"OL22\")]:\n",
    "                polyfit_onset_shift_Qdeconv = 0.25e-6\n",
    "                \n",
    "            else:\n",
    "                polyfit_onset_shift_Qdeconv = 1.5e-6\n",
    "\n",
    "            polyfit_winlens_Qdeconv = copy.deepcopy(polyfit_winlens)\n",
    "            polyfit_winlens_Qdeconv[1] += polyfit_onset_shift_Qdeconv\n",
    "   \n",
    "            tr_Pvel_upsampled_data = STF_multiwindow_detrend(tvec_upsampled, tr_Pvel_upsampled_data, onset-polyfit_onset_shift_Qdeconv, polyfit_winlens_Qdeconv, \n",
    "                            polyfit_Rcontinu_buffer, polyfit_smooth_lowpass_freqmax, polyords=polyords, debugplot=True, eventdata=detrend_eventdata)\n",
    "\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "        #------------------------#\n",
    "        #---Detrending the velocity waveform---#\n",
    "        #------------------------#\n",
    "\n",
    "        # # detrend the velocity waveform\n",
    "        # # if (gougeevent_id==49) & (stnm==\"OL08\"):\n",
    "        # #     # the S/N is low so that consider the trim margin for detrending\n",
    "        # #     detrend_stind = 0 # UPDATE 2024.11.5: include the margin for the detrend window \n",
    "        # #     detrend_etind = len(tr_Pvel_upsampled_data)\n",
    "        # # else:\n",
    "        # # UPDATE: remove constant offset\n",
    "        # detrend_stind = int((trim_margin+pwin_pre-detrend_pwin_pre)/dt_upsampled)\n",
    "        # # detrend_etind = int((trim_margin+pwin_pre+detrend_pwin_len)/dt_upsampled)\n",
    "        # detrend_etind = int((trim_margin+pwin_pre-detrend_pwin_len)/dt_upsampled)\n",
    "        \n",
    "        # k_poly = np.polynomial.polynomial.polyfit(tvec_upsampled[detrend_stind:detrend_etind], tr_Pvel_upsampled_data[detrend_stind:detrend_etind], 0) #2\n",
    "        # tr_vel_poly = np.polynomial.polynomial.polyval(tvec_upsampled, k_poly)\n",
    "        # tr_Pvel_upsampled_data -= tr_vel_poly        \n",
    "\n",
    "        # # detrend the no deconv Q with the same trend for the sake of simplicity\n",
    "        # dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ -= tr_vel_poly  \n",
    "\n",
    "        # # if stnm==\"OL08\":\n",
    "        # #     tr_debug2 = copy.deepcopy(tr_Pvel_upsampled_data)\n",
    "        # #     tr_debugp = copy.deepcopy(tr_vel_poly)\n",
    "            \n",
    "        #--- debug plot---#\n",
    "        ax_det.plot(tvec_upsampled*1e6, dev_tr_Pvel_upsampled_data_nodetrend_withdeconvQ/k_M0uz_event*1e3, \"--\", c=lc[i], label=\"\")\n",
    "        ax_det.plot(tvec_upsampled*1e6, tr_Pvel_upsampled_data/k_M0uz_event*1e3, \"-\", c=lc[i], label=f\"{stnm}\")\n",
    "        # ax_det.plot(tvec_upsampled*1e6, tr_vel_poly/k_M0uz_event*1e3, \":\", c=lc[i], label=\"\", lw=1)\n",
    "        ax_det.plot(tvec_upsampled*1e6, tukeywin*M0_bestfit, \"-\", lw=0.75, c=\"gray\") # scale with M0 for the visuallization\n",
    "        #------------------------#\n",
    "        #---Integrate velocity to convert from the velocity to the displacement---#\n",
    "        #------------------------#\n",
    "        tr_Pdisp_upsampled_data = integrate.cumulative_trapezoid(tr_Pvel_upsampled_data, dx=dt_upsampled, initial=0)\n",
    "\n",
    "        #------------------------#\n",
    "        #---Search left bottom amplitude (LBA)---#\n",
    "        #------------------------#\n",
    "        # 1. compute the slope before the pick\n",
    "        slope_st = int((pwin_pre+trim_margin-2e-6)/dt_upsampled)\n",
    "        slope_et = int((pwin_pre+trim_margin)/dt_upsampled)\n",
    "        LBA_slope_k_poly = np.polynomial.polynomial.polyfit(tvec_upsampled[slope_st:slope_et], tr_Pdisp_upsampled_data[slope_st:slope_et], 1)\n",
    "#         print(LBA_slope_k_poly)\n",
    "\n",
    "        tr_Pdisp_updampled_data_forLBApick = copy.deepcopy(tr_Pdisp_upsampled_data) # this is used to pick the LBA\n",
    "\n",
    "        if LBA_slope_k_poly[1]>=0:\n",
    "#             print(LBA_slope_k_poly[1])\n",
    "            LBA_slope_k_poly[1] -= LBA_slope_subtract # added extra slope to make STF_slope negative after subtraction\n",
    "            tr_Pdisp_updampled_data_forLBApick -= np.polynomial.polynomial.polyval(tvec_upsampled, LBA_slope_k_poly) # subtract slope to detect LBA\n",
    "\n",
    "        # pick the LBA as it is\n",
    "        STF_grad = np.gradient(tr_Pdisp_updampled_data_forLBApick)\n",
    "\n",
    "        # https://stackoverflow.com/a/3843124\n",
    "        zero_crossings = np.where(np.diff(np.sign(STF_grad)) > 0)[0]\n",
    "\n",
    "        #         min_list = zero_crossings\n",
    "        min_list = []\n",
    "\n",
    "        # remove if the amplitude of peak is greater than the threshold\n",
    "        for zeroid in zero_crossings:\n",
    "            # print(tr_Pdisp_updampled_data_forLBApick[zeroid] , LBA_thresh_zerocross_ampfactor * np.max(tr_Pdisp_updampled_data_forLBApick))\n",
    "            # if tr_Pdisp_updampled_data_forLBApick[zeroid] < LBA_thresh_zerocross_ampfactor * np.max(tr_Pdisp_updampled_data_forLBApick):\n",
    "            min_list.append(zeroid)\n",
    "\n",
    "        min_list = np.array(min_list)\n",
    "\n",
    "        # update: except buffer the ID50 OL 08: This is needed\n",
    "        if (gougeevent_id == 50) & (stnm==\"OL08\"):\n",
    "            LBA_buffer_winlen = 1.2e-6 # Use longer buffer on the event\n",
    "        else:\n",
    "            LBA_buffer_winlen = 1.0e-6 # standard value for the LBA buffer\n",
    "            \n",
    "        try:\n",
    "            LBA_ind = min_list[np.where(int((pwin_pre+trim_margin+LBA_buffer_winlen)/dt_upsampled) - min_list > 0)[0][-1]] # search the first bump of STF; 1.2us as buffer of search window\n",
    "        except:\n",
    "            LBA_ind = int(np.round((pwin_pre+trim_margin)/dt_upsampled)) #use original tpick #0\n",
    "            \n",
    "        LBA_amp = tr_Pdisp_upsampled_data[LBA_ind]\n",
    "        LBA_t = tvec_upsampled[LBA_ind]\n",
    "        \n",
    "        # print(min_list, LBA_t)\n",
    "\n",
    "        #------------------------#\n",
    "        #---Time shift STF---#\n",
    "        #------------------------#\n",
    "        STF_tshift_k = int(((pwin_pre+trim_margin)-LBA_t)/dt_upsampled) # time shift with LBA location\n",
    "        # print(STF_tshift_k)\n",
    "        valid_flag_timeshift = 1\n",
    "        # if np.abs(STF_tshift_k)>int(detrend_pwin_pre/dt_upsampled):\n",
    "        if np.abs(STF_tshift_k)>int(trim_margin/dt_upsampled):\n",
    "            print(f\"{datacase} {stnm} time shift too large.\")\n",
    "            # time shift is too large; set time shift as the original tpick\n",
    "            LBA_ind = int(np.round((pwin_pre+trim_margin)/dt_upsampled)) #use original tpick #0\n",
    "            LBA_amp = tr_Pdisp_upsampled_data[LBA_ind]\n",
    "            LBA_t = tvec_upsampled[LBA_ind]\n",
    "            STF_tshift_k = int(((pwin_pre+trim_margin)-LBA_t)/dt_upsampled) # time shift with LBA location\n",
    "            valid_flag_timeshift = 0\n",
    "\n",
    "        \n",
    "        tr_Pvel_upsampled_data= np.roll(tr_Pvel_upsampled_data, STF_tshift_k)\n",
    "        dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ = np.roll(dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ, STF_tshift_k)\n",
    "        tr_Pdisp_upsampled_data = np.roll(tr_Pdisp_upsampled_data, STF_tshift_k)\n",
    "        dev_tr_Pdisp_upsampled_data_nodetrend_nodeconvQ = np.roll(dev_tr_Pdisp_upsampled_data_nodetrend_nodeconvQ, STF_tshift_k)\n",
    "        tr_Pdisp_updampled_data_forLBApick = np.roll(tr_Pdisp_updampled_data_forLBApick, STF_tshift_k)\n",
    "        # tr_vel_poly = np.roll(tr_vel_poly, STF_tshift_k)\n",
    "        \n",
    "        #------------------------#\n",
    "        #---Remove the offset---#\n",
    "        #------------------------#\n",
    "        # offset_ind = np.where((STF_center-STF_offset_init_t-STF_offset_winlen < tvec_upsampled) & (tvec_upsampled < STF_center-STF_offset_init_t))[0]\n",
    "        # we use the amplitude of LBA as the offset for the simplicity\n",
    "        tr_Pdisp_upsampled_data -= LBA_amp\n",
    "\n",
    "        # trim the margin to remove the effect of the roll\n",
    "        # The edge effect due to the deconvolution can be mitigated by trimming of the margins\n",
    "        tr_Pvel_upsampled_data_margintrimmed = tr_Pvel_upsampled_data[trim_margin_k:-trim_margin_k]\n",
    "        dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ_margintrimmed = dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ[trim_margin_k:-trim_margin_k]\n",
    "        tr_Pdisp_upsampled_data_margintrimmed = tr_Pdisp_upsampled_data[trim_margin_k:-trim_margin_k]\n",
    "        dev_tr_Pdisp_upsampled_data_nodetrend_nodeconvQ_margintrimmed = dev_tr_Pdisp_upsampled_data_nodetrend_nodeconvQ[trim_margin_k:-trim_margin_k]\n",
    "        tr_Pdisp_updampled_data_forLBApick_margintrimmed = tr_Pdisp_updampled_data_forLBApick[trim_margin_k:-trim_margin_k]\n",
    "        # tr_vel_poly_margintrimmed = tr_vel_poly[trim_margin_k:-trim_margin_k]\n",
    "\n",
    "        # store to HDF5\n",
    "        if f\"Q{Qinv_quart}\" in fo[f\"{datacase}/{stnm}/\"].keys():\n",
    "            del fo[f\"{datacase}/{stnm}/Q{Qinv_quart}/M0dot\"]\n",
    "            del fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"]\n",
    "\n",
    "        fo.create_dataset(f\"{datacase}/{stnm}/Q{Qinv_quart}/M0dot\", data=tr_Pdisp_upsampled_data_margintrimmed)\n",
    "        LBA_ind_shifted = LBA_ind + STF_tshift_k - int(trim_margin_k)\n",
    "        LBA_amp_shifted = tr_Pdisp_upsampled_data_margintrimmed[LBA_ind_shifted]\n",
    "        LBA_t_shifted = pwin_pre\n",
    "#         print(LBA_ind_shifted, LBA_amp_shifted, LBA_t_shifted)\n",
    "        \n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"LBA_ind\"] = LBA_ind_shifted # one gridpoint varies due to the rounding of time shift\n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"LBA_amp\"] = LBA_amp_shifted\n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"LBA_t\"] = LBA_t_shifted\n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"valid_flag_timeshift\"] = valid_flag_timeshift # store the time shift valid flag\n",
    "\n",
    "        #------------------------#\n",
    "        #---Compute noise level---#\n",
    "        #------------------------#\n",
    "        # compute RMSE of noise\n",
    "        st_noise = np.max([0, LBA_ind_shifted-int(noise_winlen/dt_upsampled)])\n",
    "        et_noise = LBA_ind_shifted\n",
    "        noise_rmse = np.sqrt(np.mean((tr_Pdisp_upsampled_data_margintrimmed[st_noise:et_noise]**2))) # evaluate noise RMSE\n",
    "        noise_std = np.std(tr_Pdisp_upsampled_data_margintrimmed[st_noise:et_noise]) # evaluate noise STD\n",
    "        noise_peak = np.max(np.abs(tr_Pdisp_upsampled_data_margintrimmed[st_noise:et_noise])) \n",
    "        \n",
    "        # compute peak P amp\n",
    "        st_pmax = LBA_ind_shifted\n",
    "        et_pmax = LBA_ind_shifted + int(peak_winlen/dt_upsampled)\n",
    "        pmax = np.max(tr_Pdisp_upsampled_data_margintrimmed[st_pmax:et_pmax])\n",
    "        \n",
    "        # SNR_sensor = pmax/noise_rmse\n",
    "        SNR_sensor = pmax/noise_std\n",
    "        # SNR_sensor = pmax/noise_peak\n",
    "        \n",
    "        # print(noise_rmse, pmax, SNR_sensor)\n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"noise_rmse\"] = noise_rmse\n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"noise_peak\"] = noise_peak\n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"pmax\"] = pmax\n",
    "        fo[f\"{datacase}/{stnm}/Q{Qinv_quart}\"].attrs[\"SNR_sensor\"] = SNR_sensor\n",
    "        \n",
    "        STF_all[i, :] = tr_Pdisp_upsampled_data_margintrimmed\n",
    "\n",
    "        # valid_flag_noiselevel = fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"valid_flag_noiselevel\"]\n",
    "        # valid_flag_Rzerocross = fo[f\"{datacase}/{stnm}/noQcorr\"].attrs[\"valid_flag_Rzerocross\"]\n",
    "\n",
    "        # if not valid_flag_timeshift: # check if the LBA is not found\n",
    "            # plotls = \"--\"\n",
    "        # elif valid_flag_noiselevel: # we allow for the threshold of valid_flag_Rzerocross in this plot\n",
    "            # plotls = \"-\"\n",
    "        # else:\n",
    "            # plotls = \"--\"\n",
    "\n",
    "        plotls = \"-\"\n",
    "\n",
    "        if i==0:\n",
    "            displabel1=\"disp no deconvQ no detrend\"\n",
    "        else:\n",
    "            displabel1=None\n",
    "\n",
    "        plotampnorm1 = np.max(tr_Pdisp_upsampled_data_margintrimmed)\n",
    "        # ax.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift + tr_Pdisp_upsampled_data_margintrimmed/1e6, ls=plotls, c=lc[i], label=f\"{stnm}\", lw=2)\n",
    "        ax.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift + tr_Pdisp_upsampled_data_margintrimmed/plotampnorm1, ls=plotls, c=lc[i], label=f\"{stnm}\", lw=2)\n",
    "        # ax.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift + tr_Pdisp_updampled_data_forLBApick_margintrimmed/1e6, ls=\":\", c=\"gray\", label=\"\", lw=1) # debug for detrend of slope\n",
    "        ax.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift + tr_Pdisp_updampled_data_forLBApick_margintrimmed/plotampnorm1, ls=\":\", c=\"gray\", label=\"\", lw=1) # debug for detrend of slope\n",
    "\n",
    "        # plot the displacement waveform without deconvQ and detrend below.\n",
    "        ax.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift + dev_tr_Pdisp_upsampled_data_nodetrend_nodeconvQ_margintrimmed/plotampnorm1, ls=\":\", c=\"b\", label=displabel1, lw=1) # debug for detrend of slope\n",
    "        \n",
    "        ax.plot((pwin_pre)*1e6, yshift + 0/1e6, marker=\"v\", c=\"k\", label=f\"\") # time shifted with LBA\n",
    "        # ax.plot((LBA_t-trim_margin)*1e6, yshift + 0/1e6, marker=\"v\", c=\"k\", label=f\"\")\n",
    "\n",
    "        ax.text(0, yshift+0.1, f\"{noise_rmse:.1g}, SNR={SNR_sensor:.2f}\")\n",
    "        \n",
    "        yshift -= 1 #0.8/debug_plot_scalefactor #0.1 #0.8\n",
    "\n",
    "        # if i==len(AEsensor_list)-1:\n",
    "        #     st_offset = tvec_upsampled[offset_ind[0]]\n",
    "        #     et_offset = tvec_upsampled[offset_ind[-1]]\n",
    "        #     ax.plot((np.array([st_offset, et_offset])-trim_margin)*1e6, -0.1*np.ones(2), \"-\", marker=\"\", c=\"k\", label=None, lw=0.75)\n",
    "\n",
    "        # plot velocity waveform as twin axis\n",
    "        if i==0:\n",
    "            vellabel1=\"vel. before Qcorr\"\n",
    "            vellabel2=\"vel. after Qcorr\"\n",
    "        else:\n",
    "            vellabel1=None\n",
    "            vellabel2=None\n",
    "\n",
    "        # plot velocity before and after the deconvolution\n",
    "        plotampnorm2 = np.max(dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ_margintrimmed)\n",
    "        plotampnorm2_factor = 4\n",
    "        # ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift2 + dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ_margintrimmed/k_M0uz_event*1e3, \"-\", c=lc[i], label=vellabel1, lw=1)\n",
    "        ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift2 + dev_tr_Pvel_upsampled_data_withdetrend_nodeconvQ_margintrimmed/plotampnorm2/plotampnorm2_factor, \"-\", c=lc[i], label=vellabel1, lw=1)\n",
    "        # ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift2 + tr_Pvel_upsampled_data_margintrimmed/k_M0uz_event*1e3, \"-.\", c=lc[i], label=vellabel2, lw=1)\n",
    "        ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift2 + tr_Pvel_upsampled_data_margintrimmed/plotampnorm2/plotampnorm2_factor, \"-.\", c=lc[i], label=vellabel2, lw=1)\n",
    "        # ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift2 + tr_vel_poly_margintrimmed/k_M0uz_event*1e3, \"-\", c=lc[i], label=None, lw=0.75)        \n",
    "        # ax2.plot((tvec_upsampled_margintrimmed-trim_margin)*1e6, yshift2 + tr_vel_poly_margintrimmed/plotampnorm2/plotampnorm2_factor, \"-\", c=lc[i], label=None, lw=0.75)        \n",
    "        ax2.set_ylabel('Velocity [mm/s]')\n",
    "        yshift2 -= 1 #2/debug_plot_scalefactor #0.25 #2 \n",
    "\n",
    "\n",
    "    \n",
    "    # ax.axvspan(0, STF_removal_tp*1e6, facecolor='gray', alpha=0.1)\n",
    "    # ax.axvspan((STF_removal_tp+STF_removal_winlen)*1e6, (pwin_pre+pwin_len)*1e6, facecolor='gray', alpha=0.1)\n",
    "\n",
    "    ax.axvspan(0, pwin_pre*1e6, facecolor='gray', alpha=0.1)\n",
    "    ax.axvspan((pwin_pre+polyfit_winlens[1])*1e6, (pwin_pre+pwin_len)*1e6, facecolor='gray', alpha=0.1)\n",
    "\n",
    "\n",
    "    h1, l1 = ax.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(h1+h2, l1+l2, bbox_to_anchor=(1.05, 1.0))\n",
    "\n",
    "    ax.set_xlabel(\"Time [μs]\")\n",
    "    ylabelstr = r\"$\\dot{M}_0(t)$\"\n",
    "    ax.set_ylabel(r\"{} [MNm/s]\".format(ylabelstr)) # The unit is in MNm/s\n",
    "\n",
    "    #     ax.set_xlim([0, 9])\n",
    "    ax.set_ylim([-6, 2])\n",
    "    ax2.set_ylim([-6, 2])\n",
    "\n",
    "    fig_det # debug velocity plot for detrend\n",
    "    ax_det.set_xlabel(\"Time [μs]\")\n",
    "    ax_det.set_ylabel(r\"Velocity [mm/s]\")\n",
    "    ax_det.set_title(f\"{gougepatch_id} {datacase} Q{Qinv_quart} M0prelim={M0_bestfit:.2g} Nm\")\n",
    "    ax_det.legend(loc=1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figdir_detrend+f\"/debug_detrend_{gougepatch_id}_{datacase}_Q{Qinv_quart}.png\", format=\"png\", dpi=80)\n",
    "    plt.clf()\n",
    "    plt.close()   \n",
    "    \n",
    "    fig\n",
    "    ax.set_title(f\"{gougepatch_id} {datacase} Q{Qinv_quart} M0prelim={M0_bestfit:.2g} Nm\")\n",
    "    ax.set_title(f\"{gougepatch_id} {datacase} Q{Qinv_quart} M0prelim={M0_bestfit:.2g} Nm\")\n",
    "    ax.legend(loc=1)\n",
    "    plt.savefig(figdir_Qcorr+f\"/STF_{gougepatch_id}_{datacase}_Q{Qinv_quart}.png\", format=\"png\", dpi=80)\n",
    "   \n",
    "    plt.clf()\n",
    "    plt.close()   \n",
    "\n",
    "\n",
    "\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_upsampled[zero_crossings]*1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_Pdisp_updampled_data_forLBApick[zeroid] < LBA_thresh_zerocross_ampfactor * np.max(tr_Pdisp_updampled_data_forLBApick)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBA_thresh_zerocross_ampfactor * np.max(tr_Pdisp_updampled_data_forLBApick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_Pdisp_updampled_data_forLBApick[zeroid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_Pdisp_updampled_data_forLBApick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwin_pre+pwin_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trimP_coef_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0_bestfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tan(np.deg2rad(0.02)) * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We computed the P wave displacement pulse from the velocity wave form after pre-processing.\n",
    "We fit the synthetic STF to evaluate the moment-duration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
