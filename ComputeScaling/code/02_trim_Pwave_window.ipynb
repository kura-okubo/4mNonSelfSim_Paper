{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim the P wave window\n",
    "\n",
    "Trim the P wave window to evaluate the half maximum pulse width.\n",
    "This notebook is updated from `01_Introduction_plot_gougerepeatingevents_v2.ipynb` for the section of the trimming.\n",
    "\n",
    "2024.11.3 Kurama Okubo\n",
    "\n",
    "- 2024.11.20 update high-pass filter two-way `sosfiltfilt`at 0.06->0.1MHz\n",
    "- 2024.11.25 Skipped the high-pass filter to make an option of either the detrend or the filtering in the following notebooks. Extended the trimming window length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import obspy\n",
    "from obspy import read, Stream, Trace\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import pickle \n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import mpmath as mp\n",
    "\n",
    "from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "\n",
    "from obspy.core.utcdatetime import UTCDateTime    \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 4.75\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.75\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"xtick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 4.75\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.75\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"ytick.minor.visible\"] = True\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.75\n",
    "os.environ['TZ'] = 'GMT' # change time zone to avoid confusion in unix_tvec conversion\n",
    "UTCDateTime.DEFAULT_PRECISION = 8 # increase the time precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel table\n",
    "channel_finame = '../../Others/AEchanneltable/AEsensorlocation_onFB03_table.csv'\n",
    "\n",
    "# input datadir\n",
    "data_inputdir = \"../../SourceInvFit/data/07_DATA_MTinversion\" # for the tiny events \n",
    "\n",
    "# select balldrop calibration model\n",
    "balldrop_model=4 # 2 for the model only with SiTj, 4 for the SiTjbeta\n",
    "\n",
    "if balldrop_model==4:\n",
    "    aperturecorrection=True\n",
    "elif balldrop_model==2:\n",
    "    aperturecorrection=False\n",
    "else:\n",
    "    aperturecorrection=False\n",
    "    \n",
    "# Path for event data\n",
    "datadir = f\"../../SourceInvFit/data/06_assemble_gf_model{balldrop_model}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataoutdir = \"../data/02_trim_Pwave\"\n",
    "if not os.path.exists(dataoutdir):\n",
    "    os.makedirs(dataoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = \"../figure/debug_02_trim_Pwave\"\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Channel Index\n",
    "df_array = pd.read_csv(channel_finame)\n",
    "\n",
    "channel_loc={}\n",
    "\n",
    "for i in range(len(df_array)):\n",
    "    stnm = df_array.iloc[i].Instrument_Label\n",
    "    xtemp = df_array.iloc[i].North.astype('float')\n",
    "    ytemp = df_array.iloc[i].East.astype('float')\n",
    "    ztemp = df_array.iloc[i].Down.astype('float')\n",
    "    channel_loc[stnm] = [xtemp, ytemp, ztemp]\n",
    "    \n",
    "AEsensors = list(channel_loc.keys())\n",
    "# channel_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the onset time of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gougepatch_id = \"G3\" # to set output filename\n",
    "\n",
    "sensor_id = 7 # 7,8,22,23 loop with the sensors\n",
    "repeated_sensor = f\"OL{sensor_id:02d}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onset = pd.read_csv(f\"../data/01_plot_gougeevents/P_repicked_onset_time_G3_{repeated_sensor}.csv\", index_col=0)\n",
    "datacases = list(df_onset.index)\n",
    "df_onset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load best-fit source parameters\n",
    "Loading the source parameters estimated by the waveform fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the best fit source parameters\n",
    "bestfitsourceparam_finame = f\"../../SourceInvFit/data/datacsv/gridsearch_bestparam_M0andTR_fb03-087.csv\"\n",
    "\n",
    "df_bestparam = pd.read_csv(bestfitsourceparam_finame, index_col=0) # from waveform inversion\n",
    "datacases = df_bestparam.index\n",
    "df_bestparam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_repeat_raw = Stream()\n",
    "st_repeat = Stream()\n",
    "\n",
    "for datacase in datacases:\n",
    "# datacase = datacases[4] # We repeated running the notebook with selecting the datacase to complete the grid search for all the events.\n",
    "    # print(f\"start processing {repeated_sensor} event {datacase}.\")\n",
    "\n",
    "    # load event trace\n",
    "    st_event = read(datadir + \"/{}_AEwaveform.pickle\".format(datacase)) # this contains observation and green's function within a thresholded distance\n",
    "    tr_obs_raw = st_event.select(station=repeated_sensor, location=\"raw\")[0]\n",
    "    tr_obs_afterremovalresp = st_event.select(station=repeated_sensor, location=\"stage1\")[0] # after the correction of gain\n",
    "    st_repeat_raw.append(tr_obs_raw)\n",
    "    st_repeat.append(tr_obs_afterremovalresp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute source distance\n",
    "dist_all = []\n",
    "for tr in st_repeat:\n",
    "    dist_all.append(tr.stats.dist)\n",
    "\n",
    "dist = np.mean(dist_all)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_inputdir+\"/GridSearch_param_{}_balldropmodel{}.pickle\".format(datacases[0], balldrop_model),\"rb\") as fo:\n",
    "    param = pickle.load(fo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "\n",
    "selected_sensor = st_repeat[0].stats.station\n",
    "tvec = st_repeat[0].times()*1e3\n",
    "\n",
    "\n",
    "# compute P and S arrival\n",
    "tp = dist/param['cp']\n",
    "ts = dist/param['cs']\n",
    "\n",
    "yshift = 0\n",
    "del_yshift = 7e-3 #4e-3\n",
    "ampnorm = 0.05 # for tiny events #0.1 #12\n",
    "yspan = 0# 1.2e-3\n",
    "expr_id = datacases[0].split('__')[0]\n",
    "\n",
    "pretrigger = st_repeat[0].stats.pretrigger # [ms]\n",
    "ytickloc = []\n",
    "yticklabel = []\n",
    "\n",
    "# Plot repeated events\n",
    "raw_ampnorm = 5e2\n",
    "\n",
    "for i, datacase in enumerate(datacases):\n",
    "    # i = 4\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs = st_repeat[tr_ind]\n",
    "    tr_obs_raw = st_repeat_raw[tr_ind]\n",
    "    assert(tr_obs.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "    assert(tr_obs_raw.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "    ytickloc.append(-yshift)\n",
    "    yticklabel.append(f\"{gougeevent_id:g}\")\n",
    "    h1 = ax.plot(tvec-pretrigger, (tr_obs.data/ampnorm) - yshift, \"k-\", label=\"instrumental resp. corrected\")\n",
    "    h2 = ax.plot(tvec-pretrigger, (tr_obs_raw.data/raw_ampnorm) - yshift, \"g-\", label=\"Raw\")\n",
    "    # ax.plot(tvec-pretrigger+dt_shift_p, (tr_syn.data/ampnorm) - yshift - yspan, \"r-\", lw=1)\n",
    "    yshift = yshift + del_yshift\n",
    "\n",
    "# Annotate estimated source parameters\n",
    "annot_x = 0.0027\n",
    "annot_x_text = 0.002\n",
    "annot_y = -0.0019\n",
    "\n",
    "# for i, datacase in enumerate(datacases):\n",
    "#     # print(datacase)\n",
    "#     M0_best = df_bestparam.loc[datacase][\"M0_best\"]\n",
    "#     TR_best = df_bestparam.loc[datacase][\"TR_best\"]\n",
    "#     ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f},  {:.1f}\".format(M0_best, TR_best), ha=\"left\")\n",
    "    \n",
    "annot_txt = [r\"M$_{\\mathrm{0}}$\", r\"T$_{\\mathrm{R}}$\"]\n",
    "annot_txt_unit = [\"[Nm]\", r\"[$\\mathrm{\\mu}$s]\"]\n",
    "ax.text(annot_x, ytickloc[0]+0.02, \"{}    {}\".format(*annot_txt), ha=\"left\")\n",
    "ax.text(annot_x-0.0008, ytickloc[0]+0.01, \"{}  {}\".format(*annot_txt_unit), ha=\"left\")\n",
    "\n",
    "# annotate the scale of velocity\n",
    "scale_x = 0.005\n",
    "scale_y = -(ytickloc[-1]-0.01)\n",
    "scale_amplitude = 0.2e-3 #[mm/s]\n",
    "ax.plot([scale_x, scale_x], np.array([-scale_amplitude/2, +scale_amplitude/2])/ampnorm-scale_y, \"k-\");\n",
    "ax.text(scale_x+0.001, -(scale_amplitude/2/ampnorm)-scale_y, f\"{scale_amplitude*1e3:.1f} mm/s\" )\n",
    "\n",
    "# annotate the scale of voltage\n",
    "scale_x2 = 0.02\n",
    "scale_y2 = -(ytickloc[-1]-0.01)\n",
    "scale_amplitude2 = 2.0 #[V]\n",
    "ax.plot([scale_x2, scale_x2], np.array([-scale_amplitude2/2, +scale_amplitude2/2])/raw_ampnorm-scale_y2, \"g-\");\n",
    "ax.text(scale_x2+0.001, -(scale_amplitude2/2/raw_ampnorm)-scale_y2, f\"{scale_amplitude2:.0f} V\" )\n",
    "\n",
    "# annotate p and s arrival\n",
    "arrow_y = 0.02\n",
    "ax.arrow(tp, arrow_y, 0, -8e-3, width=1e-4, length_includes_head=True, head_length=2e-3,head_width=1e-3, color='k')\n",
    "ax.arrow(ts, arrow_y, 0, -8e-3, width=1e-4, length_includes_head=True, head_length=2e-3,head_width=1e-3, color='k')\n",
    "ax.text(tp, arrow_y-0.6e-3, \" P\", ha=\"left\")\n",
    "ax.text(ts, arrow_y-0.6e-3, \" S\", ha=\"left\")\n",
    "\n",
    "# # plot stacked trace\n",
    "# yshift = yshift + 0.5*del_yshift\n",
    "# ax.plot(tvec-pretrigger, (tr_stack.data/ampnorm) - yshift, \"k-\", lw=2)\n",
    "# ytickloc.append(-yshift)\n",
    "# yticklabel.append(\"Stacked\")\n",
    "\n",
    "# decoration of figure\n",
    "ax.set_xlim([0.0, 0.12])\n",
    "ax.set_ylim([ytickloc[-1]-0.03, ytickloc[0]+0.03])\n",
    "\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "\n",
    "ax.set_yticks(np.round(ytickloc, 3))\n",
    "ax.set_yticklabels(yticklabel)\n",
    "\n",
    "title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Raw data\"\n",
    "\n",
    "ax.legend([\"instrumental resp. corrected\", \"raw\"], loc=4)\n",
    "ax.set_title(title_str)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# plt.savefig(figdir + \"/waveform_repeated_event_{}_{}_raw_afterinstrumentalcorrection_all.png\".format(gougepatch_id, repeated_sensor), dpi=300)\n",
    "# plt.savefig(figdir + \"/waveform_repeated_event_{}_{}_raw_afterinstrumentalcorrection_all.eps\".format(gougepatch_id, repeated_sensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of events: {len(datacases)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacase = datacases[9]\n",
    "gougeevent_id = 43\n",
    "tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "tr_obs = st_repeat[tr_ind]\n",
    "tr_obs_raw = st_repeat_raw[tr_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tr_obs.times()*1e6, tr_obs.data*5e3, \"k\", label=\"inst. corr.\")\n",
    "plt.plot(tr_obs.times()*1e6, tr_obs_raw.data, \"b\", label=\"raw\")\n",
    "# plt.xlim([13, 120])\n",
    "plt.xlim([40, 60])\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim the P wave window\n",
    "\n",
    "We trim the P wave window using the repicked P onset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute displacement pulse\n",
    "To evaluate the moment rate function (far-field displacement pulse) to confirm the non-self-similarity, we compute the displacement pulse.\n",
    "\n",
    "The far-field moment rate function can be writen as follows:\n",
    "\n",
    "$$ \\dot{M_0}\\left(t - \\dfrac{r}{\\alpha}\\right)  = 4 \\pi r \\rho \\alpha^3 \\dfrac{u_{in}^P(\\mathbf{x}, t)}{ {A}_{in}^{FP} },  $$\n",
    "where $u_{in}^P(\\mathbf{x}, t)$ is the radial component of the incident P wave and $ {A}_{in}^{FP} $ is the radial component of the radiation pattern such as\n",
    "\n",
    "$$ {A}_{in}^{FP} = \\sin 2\\theta \\cos \\phi, $$\n",
    "\n",
    "where $\\theta$ and $\\phi$ are the dip and azimuth from source to receiver, respectively.\n",
    "\n",
    "\n",
    "\n",
    "The amplitude of $\\mathbf{u}^P(\\mathbf{x}, t)$ is obtained by the reflection coefficient (see Aki and Richards Q5.6) such as\n",
    "\n",
    "$$  u_{in}^P(\\mathbf{x}, t) = \\dfrac{\\left( \\frac{1}{\\beta^2}-2p^2 \\right)^2 + 4 p^2 \\frac{\\cos i}{\\alpha} \\frac{\\cos j}{\\beta}}{\\frac{-2\\alpha}{\\beta^2} \\frac{\\cos i}{\\alpha} \\left( \\frac{1}{\\beta^2}-2p^2 \\right) } u_z(\\mathbf{x}, t)$$ \n",
    "\n",
    "The incident angle $i$ meets the ray parameter\n",
    "\n",
    "$$ p = \\dfrac{\\sin i}{\\alpha} = \\dfrac{\\sin j}{\\beta}. $$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$ \\cos i = \\sqrt{1-(p\\alpha)^2} $$\n",
    "$$ \\cos j = \\sqrt{1-(p\\beta)^2} $$\n",
    "\n",
    "\n",
    "Hence, the coefficient to convert from displacement to moment rate function is:\n",
    "\n",
    "$$\\dfrac{\\dot{M_0}\\left(t - \\dfrac{r}{\\alpha}\\right)}{u_z(\\mathbf{x}, t)} = 4 \\pi r \\rho \\alpha^3 \\dfrac{1}{| {A}_{in}^{FP} |} \\dfrac{\\left( \\frac{1}{\\beta^2}-2p^2 \\right)^2 + 4 p^2 \\frac{\\cos i}{\\alpha} \\frac{\\cos j}{\\beta}}{\\frac{-2\\alpha}{\\beta^2} \\frac{\\cos i}{\\alpha} \\left( \\frac{1}{\\beta^2}-2p^2 \\right) } $$\n",
    "\n",
    "We take the absolute value of the coefficient as it is negative, showing the negative direction outward of the free surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_uz2Mdot_coef(alpha, beta, r_dist, inc_P, rho, dip, azimuth):\n",
    "    \"\"\"\n",
    "    Compute the coefficient to convert the z displacement to moment rate function\n",
    "    \"\"\"\n",
    "    # Radiation pattern\n",
    "    p_slowness = np.sin(np.deg2rad(inc_P))/alpha\n",
    "    cos_i = np.cos(np.deg2rad(inc_P))\n",
    "    cos_j = np.sqrt(1-(p_slowness*beta)**2)\n",
    "    AFP = compute_AFP(dip, azimuth)\n",
    "    # print(cos_i, cos_j, AFP)\n",
    "    \n",
    "    C1 = 4 * np.pi * r_dist * rho * alpha**3 \n",
    "    CA = (1/beta**2) - 2*p_slowness**2\n",
    "    C2 = CA**2 + 4*p_slowness**2 * (cos_i/alpha) * (cos_j/beta)\n",
    "    C3 = (-2*alpha/(beta**2)) * (cos_i/alpha) * CA\n",
    "    \n",
    "    # print( (-2*alpha/(beta**2)), CA, (cos_i/alpha))\n",
    "    \n",
    "    return (C1 * C2) / (AFP * C3)\n",
    "    \n",
    "def compute_AFP(dip, azimuth):\n",
    "    # dip is from the vertical direction and azimuth is from the shear direction\n",
    "    return np.abs(np.sin(2*np.deg2rad(dip)) * np.cos(np.deg2rad(azimuth)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = param['cp'] # [m/s]\n",
    "beta = param['cs'] # [m/s]\n",
    "rho = 2980 # [kg/m^3]\n",
    "\n",
    "r_dist = dist * 1e-3 #[mm] -> [m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute orientations\n",
    "The orientations were computed in `SourceInvFit/code/04_AE_convert_to_isoparametric_coordinate.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iso_all = pd.read_csv(\"../../SourceInvFit/data/datacsv/AEevents_isocoord.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iso_all_station = df_iso_all[df_iso_all[\"OL\"]==repeated_sensor].copy()\n",
    "df_iso_all_station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidentangle_mean = df_iso_all_station[\"incidentangle\"].mean()\n",
    "\n",
    "# update 2024.08.23\n",
    "# the azimuth in the datasheet is computed as `np.rad2deg(np.arctan2(xi1, np.abs(eta1)))` in 04_AE_convert_to_isoparametric_coordinate.ipynb\n",
    "# Therefore, this is backazimuth from the sensor to source. \n",
    "# Here we convert the azimuth from source to sensor\n",
    "\n",
    "\n",
    "if  df_iso_all[df_iso_all[\"OL\"]==f\"{repeated_sensor}\"][\"ys\"].values[0] > 0:\n",
    "    # south side sensors from 1 to 16\n",
    "    azimuth_mean = 90 + df_iso_all_station[\"azimuth\"].mean() # convert clockwise from shear direction (Aki & Richards, Fig. 4.4)\n",
    "    \n",
    "else:\n",
    "    # north side sensors from 17 to 32\n",
    "    azimuth_mean = - (90 - df_iso_all_station[\"azimuth\"].mean()) # the north and south are flipped the coordinates\n",
    "    \n",
    "## DEBUG for azimuth correction to optimize the amplitude estimation\n",
    "## We confirmed the azimuth works \n",
    "### debug_azimuth_correction = +30.0 # \n",
    "### azimuth -= debug_azimuth_correction\n",
    "\n",
    "# compute dip\n",
    "df_iso_all_station.loc[:, \"dip\"] =  df_iso_all_station.apply(lambda x: np.rad2deg(np.arccos(x.zs/x.rlen_sourcedist)), axis=1)\n",
    "dip_mean=df_iso_all_station[\"dip\"].mean()\n",
    "print(f\"sensor {repeated_sensor}: {incidentangle_mean:.2f}, {azimuth_mean:.2f}, {dip_mean:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick double check of orientations\n",
    "inc_tmp = np.rad2deg(np.arccos(0.05/r_dist))\n",
    "axi_tmp = 90-np.rad2deg(np.arccos(0.05/0.17))\n",
    "\n",
    "print(f\"inc_tmp {inc_tmp:.2f} azi_tmp {axi_tmp:.2f}\") # the sign of azimuch does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check radiation pattern\n",
    "dip_vec = np.linspace(0, 360, 201)\n",
    "azi_vec = [0, azimuth_mean, 85]\n",
    "Nazi = len(azi_vec)\n",
    "\n",
    "AFP_tmp = np.zeros((len(dip_vec), Nazi))\n",
    "for i, dd in enumerate(dip_vec):\n",
    "    for j, aa in enumerate(azi_vec):\n",
    "        AFP_tmp[i, j] = compute_AFP(dd, aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, Nazi, figsize = (10, 7), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.plot(np.deg2rad(dip_vec), AFP_tmp[:, i], \"k-\")\n",
    "    if i == 1:\n",
    "        # plot sensor location\n",
    "        dip_sensorind = np.where(dip_vec>dip_mean)[0][0]\n",
    "        ax.plot(np.deg2rad(dip_mean), AFP_tmp[dip_sensorind, i], \"ro\")\n",
    "                         \n",
    "    ax.set_theta_zero_location(\"S\")\n",
    "    ax.set_rlim(0, 1)\n",
    "    ax.set_title(f\"Azimuth={azi_vec[i]:.1f}°\")\n",
    "\n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + f\"/check_radiationpattern_{gougepatch_id}_{repeated_sensor}.png\", dpi=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The radiation patterns above show the vertical cross section at given aziumth on the simulated fault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute coefficient\n",
    "print(\"alpha {:.1f}m/s, beta {:.1f}m/s,  r_dist {:.4f}m, incident angle {:.2f}°,  density {:.1f}kg/m3,  dip {:.1f}°,  azimuth {:.1f}°\".format(alpha, beta, r_dist, incidentangle_mean, rho, dip_mean, azimuth_mean))\n",
    "k_M0uz_mean = np.abs(compute_uz2Mdot_coef(alpha, beta, r_dist, incidentangle_mean, rho, dip_mean, azimuth_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_M0uz_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(dataoutdir+f\"/k_M0uz_{gougepatch_id}_{repeated_sensor}.txt\", \"w\") as fo:\n",
    "#     fo.write(f\"{k_M0uz:12.8e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.8e-10 * k_M0uz_mean # disp to M0 example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute individual incident angle and radiation pattern coefficient from `uz` to `M0`\n",
    "\n",
    "We compute the coefficient for each gouge event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incidentangle_scalingfactor_analytic(v, theta, TR, R):\n",
    "    if theta==0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        va = v/np.sin(theta)\n",
    "        J1 = mp.besselj(1, (2*np.pi*R)/(va*TR))\n",
    "        return  ((va * TR)/(np.pi*R)) * J1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iso_row = df_iso_all_station[(df_iso_all_station[\"OL\"]==repeated_sensor) & (df_iso_all_station[\"datacase\"]==datacase)]\n",
    "df_iso_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dist, df_iso_row[\"rlen_sourcedist\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimP_coef_columns = [\"datacase\", \"rdist\", \"incidentangle\", \"dip\", \"azimuth\", \"k_M0uz\", \"TR\", \"beta_coef_p\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trimP_coef = pd.DataFrame(columns=trimP_coef_columns)\n",
    "\n",
    "for i, datacase in enumerate(datacases):\n",
    "    # Radiation pattern coefficient\n",
    "    df_iso_row = df_iso_all_station[(df_iso_all_station[\"OL\"]==repeated_sensor) & (df_iso_all_station[\"datacase\"]==datacase)]\n",
    "    rdist_try = df_iso_row[\"rlen_sourcedist\"].values[0] # [m] source distance\n",
    "    incidentangle_try = df_iso_row[\"incidentangle\"].values[0] # [deg] incident ngle\n",
    "    dip_try = df_iso_row[\"dip\"].values[0] # [deg] dip\n",
    "    \n",
    "    if  df_iso_row[\"ys\"].values[0] > 0:\n",
    "        # south side sensors from 1 to 16\n",
    "        azimuth_try = 90 + df_iso_row[\"azimuth\"].values[0] # convert clockwise from shear direction (Aki & Richards, Fig. 4.4)\n",
    "    else:\n",
    "        # north side sensors from 17 to 32\n",
    "        azimuth_try = - (90 - df_iso_row[\"azimuth\"].values[0]) # the north and south are flipped the coordinates\n",
    "\n",
    "\n",
    "    k_M0uz_try = np.abs(compute_uz2Mdot_coef(alpha, beta, rdist_try, incidentangle_try, rho, dip_try, azimuth_try))\n",
    "    \n",
    "    # apature correction coefficient \n",
    "    TR_try = df_bestparam.loc[f\"{datacase}\", \"TR_best\"] * 1e-6 # [us] -> [s]\n",
    "    \n",
    "    beta_coef_p_try = float(incidentangle_scalingfactor_analytic(alpha, np.deg2rad(incidentangle_try), TR_try, param[\"R_sensor\"]))\n",
    "\n",
    "    # print(datacase, rdist_try, incidentangle_try, dip_try, azimuth_try, k_M0uz_try, TR_try, beta_coef_p_try)\n",
    "    coef_data = {\"datacase\":[datacase],\n",
    "                 \"rdist\" : [rdist_try],\n",
    "                 \"incidentangle\" : [incidentangle_try],\n",
    "                 \"dip\" : [dip_try],\n",
    "                 \"azimuth\" : [azimuth_try],\n",
    "                 \"k_M0uz\" : [k_M0uz_try],\n",
    "                 \"TR\" : [TR_try],\n",
    "                 \"beta_coef_p\" : [beta_coef_p_try]\n",
    "                }\n",
    "    \n",
    "    df_sensor_coef = pd.DataFrame.from_dict(coef_data)\n",
    "\n",
    "    if not df_trimP_coef.empty:\n",
    "        df_trimP_coef = pd.concat([df_trimP_coef, df_sensor_coef])\n",
    "    else:\n",
    "        df_trimP_coef = df_sensor_coef\n",
    "\n",
    "df_trimP_coef = df_trimP_coef.set_index([\"datacase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the coefficient\n",
    "df_trimP_coef.loc[:, \"OL\"] = repeated_sensor\n",
    "df_trimP_coef.to_csv(dataoutdir+f\"/trimP_coefficients_{gougepatch_id}_{repeated_sensor}.csv\", float_format=\"%12.8g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the far-field displacement pulse\n",
    "\n",
    "Process flow:\n",
    "1. Apply apeture effect collection\n",
    "2. Apply high-pass filter to the response-corrected velocity waveform.\n",
    "3. Trim the P wave window. **Updata:** use the recomputed tpick on P wave\n",
    "4. Integral to obtain displacement\n",
    "5. store the data to the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for filtering\n",
    "# We use the same filter as the previously analyzed gouge events\n",
    "freqmin = 0.1e6 #0.06e6 # apply highpass\n",
    "# freqmax = 1e6 # prefilter is applied when removing the instrumental response. pre_filt = (1e4, 2e4, 1e6, 2e6).\n",
    "\n",
    "butterworth_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update: using the best-fit TR for the beta coefficient of apature effect\n",
    "df_trimP_coef_event = df_trimP_coef.loc[datacases[10]]\n",
    "df_trimP_coef_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trimP_coef_event[\"beta_coef_p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datacases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onset.loc[datacase][\"onset_npt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_repeat_Pvel = Stream()\n",
    "st_repeat_Pdisp = Stream()\n",
    "\n",
    "fs = st_repeat[0].stats.sampling_rate\n",
    "pwin_pre = 20e-6 #4e-6 #10e-6 #3e-6\n",
    "pwin_len = 20e-6 #10e-6 #6e-6\n",
    "trim_margin = 1.5e-6\n",
    "\n",
    "# update: we use the datapoints instead of trim function\n",
    "pwin_pre_k = int(pwin_pre*fs)\n",
    "pwin_len_k = int(pwin_len*fs)\n",
    "trim_margin_k = int(trim_margin*fs)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "# freqmin = 0.1e6\n",
    "\n",
    "for i, datacase in enumerate(datacases):\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs = st_repeat[tr_ind].copy()\n",
    "    \n",
    "    # 1.correct aperture effect\n",
    "    tr_obs.data /= df_trimP_coef_event[\"beta_coef_p\"]\n",
    "    \n",
    "    # 2.apply highpass filter     \n",
    "    # NOT using sos to minimize the numerical error of filter\n",
    "    # sos = signal.butter(butterworth_order, freqmin, 'highpass', fs=tr_obs.stats.sampling_rate, output='sos')\n",
    "    # We use b and a with the Gustafsson method\n",
    "    b, a = signal.butter(butterworth_order, freqmin, 'highpass', fs=tr_obs.stats.sampling_rate, output='ba')\n",
    "\n",
    "    # Cheby2 was similar performance with the butter\n",
    "    # b, a = signal.cheby2(6, 40, freqmin, btype='high', fs=tr_obs.stats.sampling_rate, output='ba')\n",
    "\n",
    "    # UPDATE: not applying the filter in this notebook. \n",
    "    #We will make an option to apply either the detrend or the high-pass filter.\n",
    "    tr_obs_filtered = tr_obs.copy()\n",
    "\n",
    "    \n",
    "    # tr_obs_filtered = tr_obs.copy().taper(0.05)\n",
    "    # tr_obs_filtered.data = signal.sosfilt(sos, tr_obs_filtered.data)\n",
    "    # UPDATE: two-way filtering to better retrieve the STF\n",
    "    # # SKIP; apply high-pass filter to remove low-frequency components, which does not affect the source characteristics\n",
    "    # tr_obs_filtered.data = signal.sosfiltfilt(sos, tr_obs_filtered.data)\n",
    "    # tr_obs_filtered.data = signal.filtfilt(b, a, tr_obs_filtered.data, method='gust')\n",
    "    \n",
    "    # 3.trim the p wave window\n",
    "    # we use the datapoints instead of trim function\n",
    "    onset_k = df_onset.loc[datacase][\"onset_npt\"]\n",
    "    tr_obs_retrimmed_p = tr_obs_filtered.copy()\n",
    "    tr_obs_retrimmed_p.data = tr_obs_filtered.copy().data[onset_k-pwin_pre_k-trim_margin_k:onset_k+pwin_len_k+trim_margin_k+1]\n",
    "\n",
    "  \n",
    "    # # # remove offset by first 1us \n",
    "    # offset_inds = range(int(1e-6 * tr_obs_retrimmed_p.stats.sampling_rate))\n",
    "    # tr_obs_retrimmed_p.data -= np.mean(tr_obs_retrimmed_p.data[offset_inds])\n",
    "    \n",
    "    st_repeat_Pvel.append(tr_obs_retrimmed_p)\n",
    "\n",
    "    # 4.Integrate\n",
    "    tr_obs_retrimmed_p_disp = tr_obs_retrimmed_p.copy().integrate(method='cumtrapz')\n",
    "    \n",
    "    # Detrend the linear term\n",
    "#     tr_obs_retrimmed_p_disp.detrend(type='linear') # skip at this stage. Revisit when computing STF\n",
    "\n",
    "    # 5.Append to stream\n",
    "    st_repeat_Pdisp.append(tr_obs_retrimmed_p_disp)\n",
    "\n",
    "    # axs[0].plot(tr_obs_retrimmed_p.times()*1e6, tr_obs_retrimmed_p.copy().detrend().data*1e3, \"-\")\n",
    "    # axs[1].plot(tr_obs_retrimmed_p_disp.times()*1e6, tr_obs_retrimmed_p_disp.copy().detrend().data*1e9, \"-\")\n",
    "    axs[0].plot(tr_obs_retrimmed_p.times()*1e6, tr_obs_retrimmed_p.data*1e3, \"-\")\n",
    "    axs[1].plot(tr_obs_retrimmed_p_disp.times()*1e6, tr_obs_retrimmed_p_disp.data*1e9, \"-\")\n",
    "\n",
    "\n",
    "axs[0].set_xlabel(\"Time [μs]\")\n",
    "axs[0].set_ylabel(\"Velocity [mm/s]\")\n",
    "axs[1].set_xlabel(\"Time [μs]\")\n",
    "axs[1].set_ylabel(\"Displacement [nm]\")\n",
    "\n",
    "axs[1].set_ylim([-1, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "ax.plot(tr_obs.times()*1e6, tr_obs.data, \"k-\")\n",
    "ax.plot(tr_obs_filtered.times()*1e6, tr_obs_filtered.data, \"b-\")\n",
    "# ax.set_xlim([0, 20])\n",
    "ax.set_ylim([-.5e-3, .5e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "ax.plot(tr_obs_retrimmed_p.times()*1e6, tr_obs_retrimmed_p.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
    "ax.plot(tr_obs_retrimmed_p.times()*1e6, tr_obs_retrimmed_p_disp.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump the P wave velocity and displacement pulses\n",
    "\n",
    "These pulses are used to evaluate the half-maximum amplitude width as a metric of source duration with and without Q correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_repeat_Pvel.write(dataoutdir+f\"/st_repeat_Pvel_{gougepatch_id}_{repeated_sensor}.pickle\", format=\"PICKLE\") \n",
    "st_repeat_Pdisp.write(dataoutdir+f\"/st_repeat_Pdisp_{gougepatch_id}_{repeated_sensor}.pickle\", format=\"PICKLE\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot displacement waveform\n",
    "datacase_1 = 'fb03-087__0062'\n",
    "tr_ind = [x.stats.dataindex[6:] for x in st_repeat_Pdisp].index(datacase_1)\n",
    "tr_obs = st_repeat[tr_ind].copy()\n",
    "\n",
    "sos = signal.butter(butterworth_order, freqmin, 'highpass', fs=tr_obs.stats.sampling_rate, output='sos')\n",
    "tr_obs_raw_disp = tr_obs.copy().integrate(method='cumtrapz').copy()\n",
    "tr_obs_filtered = tr_obs.copy().taper(0.05).copy()\n",
    "# tr_obs_filtered.data = signal.sosfilt(sos, tr_obs_filtered.data).copy()\n",
    "tr_obs_filtered.data = signal.sosfiltfilt(sos, tr_obs_filtered.data).copy()\n",
    "tr_obs_filtered_disp = tr_obs_filtered.copy().integrate(method='cumtrapz').copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax, ax2]= plt.subplots(2, 1, figsize=(7, 6))\n",
    "\n",
    "ax.plot(tr_obs_raw_disp.times()*1e3, tr_obs_raw_disp.data*1e9, \"k-\", label=\"After instrumental removal\")\n",
    "ax.set_title(tr_obs_filtered_disp.stats.dataindex)\n",
    "ax.set_xlabel(\"Time [ms]\")  \n",
    "ax.set_ylabel(\"Displacement [nm]\")  \n",
    "ax.set_xlim([0, 0.3])\n",
    "# ax.set_ylim([-2.2, 2.2])\n",
    "ax.legend(loc=1)\n",
    "\n",
    "ax2.plot(tr_obs_filtered_disp.times()*1e3, tr_obs_filtered_disp.data*1e9, \"k-\", label=f\"{freqmin/1e6:g} MHz resp removal + highpass\")\n",
    "# ax2.set_title(tr_obs_filtered_disp.stats.dataindex)\n",
    "ax2.set_xlabel(\"Time [ms]\")  \n",
    "ax2.set_ylabel(\"Displacement [nm]\")\n",
    "ax2.set_xlim([0, 0.3])\n",
    "# ax2.set_ylim([-2.2, 2.2])\n",
    "ax2.legend(loc=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + \"/debug_displacementpulse_demo_{}_{}.png\".format(gougepatch_id, repeated_sensor), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook performed the trimming of P wave pulse and convert it from velocity to displacement. We also computed the radiation pattern coefficient to convert from displacement to $M_0$, which is evaluated for each gouge event. We use these displacement pulses to estimate the HMPW and the moment-duration scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
