{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot repeating events\n",
    "\n",
    "Plot the repeating gouge events generated by the gouge patch.\n",
    "\n",
    "2024.06.05 Kurama Okubo\n",
    "\n",
    "- 2024.11.1 update for the merged catalog. We modified the threshold criteria so that we do not use the maximum value of the correlation coefficient to the stacked waveform. We threshold out the HMPW with the predefined criteria. On the other hand, we use the max cc to plot the Figure 1 repeating events for the sake of visuallization.\n",
    "\n",
    "- 2024.12.6 update the plotting magnitude estimated from fitting the STF.\n",
    "- 2024.12.8 update plot the events where four sensors are fitted for the master plot.\n",
    "- 2024.12.19 update apply one-way band-pass filter between 0.1-1Hz instead of high-pass filter. Re-adjusted the onset picks. It used to be low-passed with the prefilter of instrumental response removal.\n",
    "- 2024.1.22 update `P_win_ind` to align the P wave window\n",
    "- 2025.2.7 update to plot P and S arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import obspy\n",
    "from obspy import read, Stream, Trace\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import glob\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import pickle \n",
    "import seaborn as sns\n",
    "import copy\n",
    "from scipy.optimize import minimize\n",
    "from scipy import integrate \n",
    "\n",
    "from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "\n",
    "from obspy.core.utcdatetime import UTCDateTime    \n",
    "\n",
    "from compute_reflections import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['lines.linewidth'] = 1.0\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "# plt.rcParams[\"font.sans-serif\"] = \"DejaVu Sans, Arial, Helvetica, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.direction\"] = \"in\"\n",
    "plt.rcParams[\"xtick.major.size\"] = 4.75\n",
    "plt.rcParams[\"xtick.major.width\"] = 0.75\n",
    "plt.rcParams[\"xtick.minor.size\"] = 3\n",
    "plt.rcParams[\"xtick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"xtick.minor.visible\"] = False\n",
    "\n",
    "plt.rcParams[\"ytick.direction\"] = \"in\"\n",
    "plt.rcParams[\"ytick.major.size\"] = 4.75\n",
    "plt.rcParams[\"ytick.major.width\"] = 0.75\n",
    "plt.rcParams[\"ytick.minor.size\"] = 3\n",
    "plt.rcParams[\"ytick.minor.width\"] = 0.4\n",
    "plt.rcParams[\"ytick.minor.visible\"] = False\n",
    "\n",
    "plt.rcParams[\"savefig.transparent\"] = False #True\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 0.75\n",
    "os.environ['TZ'] = 'GMT' # change time zone to avoid confusion in unix_tvec conversion\n",
    "UTCDateTime.DEFAULT_PRECISION = 8 # increase the time precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel table\n",
    "channel_finame = '../../Others/AEchanneltable/AEsensorlocation_onFB03_table.csv'\n",
    "\n",
    "# input datadir\n",
    "# data_inputdir = \"../../SourceInversion/data/07_DATA_MTinversion\"\n",
    "data_inputdir = \"../../SourceInvFit/data/07_DATA_MTinversion\" # for the tiny events \n",
    "\n",
    "# select balldrop calibration model\n",
    "balldrop_model=4 # 2 for the model only with SiTj, 4 for the SiTjbeta\n",
    "\n",
    "if balldrop_model==4:\n",
    "    aperturecorrection=True\n",
    "elif balldrop_model==2:\n",
    "    aperturecorrection=False\n",
    "else:\n",
    "    aperturecorrection=False\n",
    "    \n",
    "# Path for event data\n",
    "datadir = f\"../../SourceInvFit/data/06_assemble_gf_model{balldrop_model}\"\n",
    "\n",
    "dataoutdir = \"../data/01_plot_gougeevents\"\n",
    "if not os.path.exists(dataoutdir):\n",
    "    os.makedirs(dataoutdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = \"../figure/01_plot_gougeevents\"\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Channel Index\n",
    "df_array = pd.read_csv(channel_finame)\n",
    "\n",
    "channel_loc={}\n",
    "\n",
    "for i in range(len(df_array)):\n",
    "    stnm = df_array.iloc[i].Instrument_Label\n",
    "    xtemp = df_array.iloc[i].North.astype('float')\n",
    "    ytemp = df_array.iloc[i].East.astype('float')\n",
    "    ztemp = df_array.iloc[i].Down.astype('float')\n",
    "    channel_loc[stnm] = [xtemp, ytemp, ztemp]\n",
    "    \n",
    "AEsensors = list(channel_loc.keys())\n",
    "# channel_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the waveforms\n",
    "We read the waveforms compiled in `06_assemble_greensfunction_MTinv_removeresp`.\n",
    "We use the `stage 1`, where the instrumental response and gain correction by the ball drop were applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_sensor = \"OL23\" # 07, 08, 22, 23, ### we remove 24 due to low S/N \n",
    "gougepatch_id = \"G3\" # to set output filename\n",
    "\n",
    "# load best parameters\n",
    "# Path to the best fit source parameters\n",
    "bestfitsourceparam_finame = f\"../../SourceInvFit/data/datacsv/gridsearch_bestparam_M0andTR_fb03-087.csv\"\n",
    "\n",
    "df_bestparam = pd.read_csv(bestfitsourceparam_finame, index_col=0) # from waveform inversion\n",
    "datacases = df_bestparam.index\n",
    "df_bestparam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update source parameters with the STF fitting\n",
    "If we find the datasheet of source parameters obtained by the STF fitting, we use the updated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: bestfit M0 should be updated after the evaluation of fitting STF.\n",
    "# Update: read the stats obtained by the STF fitting\n",
    "expr_id = 87\n",
    "gougepatch_id = \"G3\" # to set output filename\n",
    "denoise_method = \"detrend\"\n",
    "Qinv_quart = 50\n",
    "k_waterlevel = 0.3\n",
    "\n",
    "# IfSTFstatsExist = os.path.exists(f\"../../HalfMaximumPulseWidth/data/df_STF_stats_stacked_all__{gougepatch_id}.csv\")\n",
    "foname_mean = f\"../data/05_STFstats/SourceParam_meanstd_fb03-{expr_id:03d}_{gougepatch_id}_wlv_{k_waterlevel:.2f}_denoisemethod_{denoise_method.lower()}.csv\"\n",
    "\n",
    "IfSTFstatsExist = os.path.exists(foname_mean)\n",
    "if IfSTFstatsExist:\n",
    "    print(f\"Datasheet {os.path.basename(foname_mean)} found.\")\n",
    "\n",
    "expr_id = 87\n",
    "\n",
    "if IfSTFstatsExist:\n",
    "    df_stats = pd.read_csv(foname_mean, index_col=0)\n",
    "    df_stats_case = df_stats[df_stats[\"Qinv_quart\"] == f\"{Qinv_quart}\"]\n",
    "    df_stats_case_sorted = df_stats_case.sort_values(by=\"M0_mean\", ascending=False)\n",
    "\n",
    "else:\n",
    "    df_stats_case_sorted = pd.DataFrame(columns = [\"datacase\", \"gougeevent_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_case_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the source parameter table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sourceparam = pd.DataFrame(columns = [\"datacase\", \"gougeevent_id\", \"Nvalidsensors\", \"M0\", \"Tw\", \"M0_fromwavfit\", \"Tw_fromwavfit\" ])\n",
    "\n",
    "for datacase in datacases:\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    df_event_fromSTFfit = df_stats_case_sorted[df_stats_case_sorted[\"datacase\"]==datacase]\n",
    "    if len(df_event_fromSTFfit)<1:\n",
    "        # No STF fit avalilable.\n",
    "        data = {\"datacase\": [datacase], \"gougeevent_id\": gougeevent_id, \"Nvalidsensors\": 0,\n",
    "               \"M0\": df_bestparam.loc[datacase, \"M0_best\"], \"Tw\": df_bestparam.loc[datacase, \"TR_best\"],\n",
    "               \"M0_fromwavfit\": df_bestparam.loc[datacase, \"M0_best\"], \"Tw_fromwavfit\": df_bestparam.loc[datacase, \"TR_best\"],}\n",
    "\n",
    "    else:\n",
    "        # use the STF fit\n",
    "        data = {\"datacase\": [datacase], \"gougeevent_id\": gougeevent_id, \"Nvalidsensors\": df_event_fromSTFfit[\"Nvalidsensors\"].values[0],\n",
    "               \"M0\": df_event_fromSTFfit[\"M0_mean\"].values[0], \"Tw\": df_event_fromSTFfit[\"Tw_mean\"].values[0]*1e6,\n",
    "                \"M0_fromwavfit\": df_bestparam.loc[datacase, \"M0_best\"], \"Tw_fromwavfit\": df_bestparam.loc[datacase, \"TR_best\"],}      \n",
    "    \n",
    "    if not df_sourceparam.empty:\n",
    "        df_sourceparam = pd.concat([df_sourceparam, pd.DataFrame.from_dict(data)])\n",
    "    else:\n",
    "        df_sourceparam = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df_sourceparam = df_sourceparam.set_index(\"datacase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Tw_fromwavfit is without the Q deconv, and the detrend algorithm is different from STF fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sourceparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "df_sourceparam.plot.scatter(x=\"M0\", y=\"M0_fromwavfit\", ax=ax)\n",
    "df_sourceparam[df_sourceparam[\"Nvalidsensors\"] >= 4].plot.scatter(x=\"M0\", y=\"M0_fromwavfit\", c=\"r\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sourceparam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sourceparam\n",
    "df_sourceparam_sorted = df_sourceparam.sort_values(by=\"M0\", ascending=False)\n",
    "# df_sourceparam_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases_sorted = df_sourceparam_sorted.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append the column of event timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aftershock_ids = [3,4,7,15,16,17,32,33,43,46,51,52,56,57,62,63,67,68,69,76,77,80,87,89,\n",
    "                  90,92,93,100,102,103,104,105,106,107,108,109,111,114,116,118,120,123,124,128,132]; # we visually categorized the aftershocks.\n",
    "\n",
    "df_sourceparam_sorted[\"eventtiming\"] = 0 # foreshock\n",
    "\n",
    "for index, row in df_sourceparam_sorted.iterrows():\n",
    "    gougeevent_id = int(index.split(\"__\")[-1])\n",
    "    if gougeevent_id in aftershock_ids:\n",
    "        df_sourceparam_sorted.loc[index, \"eventtiming\"] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_repeat_raw = Stream()\n",
    "st_repeat = Stream()\n",
    "\n",
    "for datacase in datacases_sorted:\n",
    "# datacase = datacases[4] # We repeated running the notebook with selecting the datacase to complete the grid search for all the events.\n",
    "    # print(f\"start processing {repeated_sensor} event {datacase}.\")\n",
    "\n",
    "    # load event trace\n",
    "    st_event = read(datadir + \"/{}_AEwaveform.pickle\".format(datacase)) # this contains observation and green's function within a thresholded distance\n",
    "    tr_obs_raw = st_event.select(station=repeated_sensor, location=\"raw\")[0]\n",
    "    tr_obs_afterremovalresp = st_event.select(station=repeated_sensor, location=\"stage1\")[0]\n",
    "    st_repeat_raw.append(tr_obs_raw)\n",
    "    st_repeat.append(tr_obs_afterremovalresp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_repeat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute source distance\n",
    "dist_all = []\n",
    "for tr in st_repeat:\n",
    "    dist_all.append(tr.stats.dist)\n",
    "\n",
    "dist = np.mean(dist_all)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_inputdir+\"/GridSearch_param_{}_balldropmodel{}.pickle\".format(datacases[0], balldrop_model),\"rb\") as fo:\n",
    "    param = pickle.load(fo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot raw waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "\n",
    "selected_sensor = st_repeat[0].stats.station\n",
    "tvec = st_repeat[0].times()*1e3\n",
    "\n",
    "\n",
    "# compute P and S arrival\n",
    "tp = dist/param['cp']\n",
    "ts = dist/param['cs']\n",
    "\n",
    "yshift = 0\n",
    "del_yshift = 7e-3 #4e-3\n",
    "ampnorm = 0.05 # for tiny events #0.1 #12\n",
    "yspan = 0# 1.2e-3\n",
    "expr_id = datacases[0].split('__')[0]\n",
    "\n",
    "pretrigger = st_repeat[0].stats.pretrigger # [ms]\n",
    "ytickloc = []\n",
    "yticklabel = []\n",
    "\n",
    "# Plot repeated events\n",
    "raw_ampnorm = 5e2\n",
    "\n",
    "for i, datacase in enumerate(datacases_sorted):\n",
    "    # i = 4\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs = st_repeat[tr_ind]\n",
    "    tr_obs_raw = st_repeat_raw[tr_ind]\n",
    "    assert(tr_obs.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "    assert(tr_obs_raw.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "    ytickloc.append(-yshift)\n",
    "    yticklabel.append(f\"{gougeevent_id:g}\")\n",
    "    h1 = ax.plot(tvec-pretrigger, (tr_obs.data/ampnorm) - yshift, \"k-\", label=\"instrumental resp. corrected\")\n",
    "    h2 = ax.plot(tvec-pretrigger, (tr_obs_raw.data/raw_ampnorm) - yshift, \"g-\", label=\"Raw\")\n",
    "    # ax.plot(tvec-pretrigger+dt_shift_p, (tr_syn.data/ampnorm) - yshift - yspan, \"r-\", lw=1)\n",
    "    yshift = yshift + del_yshift\n",
    "\n",
    "# Annotate estimated source parameters\n",
    "annot_x = 0.0027\n",
    "annot_x_text = 0.002\n",
    "annot_y = -0.0019\n",
    "\n",
    "for i, datacase in enumerate(datacases_sorted):\n",
    "    # print(datacase)\n",
    "    # for the raw plot, use wavfit\n",
    "    M0_best = df_sourceparam_sorted.loc[datacase, \"M0_fromwavfit\"]\n",
    "    TR_best = df_sourceparam_sorted.loc[datacase, \"Tw_fromwavfit\"]\n",
    "\n",
    "    ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f},  {:.1f}\".format(M0_best, TR_best), ha=\"left\")\n",
    "    \n",
    "annot_txt = [r\"M$_{\\mathrm{0}}$\", r\"T$_{\\mathrm{R}}$\"]\n",
    "annot_txt_unit = [\"[Nm]\", r\"[$\\mathrm{\\mu}$s]\"]\n",
    "ax.text(annot_x, ytickloc[0]+0.02, \"{}    {}\".format(*annot_txt), ha=\"left\")\n",
    "ax.text(annot_x-0.0008, ytickloc[0]+0.01, \"{}  {}\".format(*annot_txt_unit), ha=\"left\")\n",
    "\n",
    "# annotate the scale of velocity\n",
    "scale_x = 0.005\n",
    "scale_y = -(ytickloc[-1]-0.01)\n",
    "scale_amplitude = 0.2e-3 #[mm/s]\n",
    "ax.plot([scale_x, scale_x], np.array([-scale_amplitude/2, +scale_amplitude/2])/ampnorm-scale_y, \"k-\");\n",
    "ax.text(scale_x+0.001, -(scale_amplitude/2/ampnorm)-scale_y, f\"{scale_amplitude*1e3:.1f} mm/s\" )\n",
    "\n",
    "# annotate the scale of voltage\n",
    "scale_x2 = 0.02\n",
    "scale_y2 = -(ytickloc[-1]-0.01)\n",
    "scale_amplitude2 = 2.0 #[V]\n",
    "ax.plot([scale_x2, scale_x2], np.array([-scale_amplitude2/2, +scale_amplitude2/2])/raw_ampnorm-scale_y2, \"g-\");\n",
    "ax.text(scale_x2+0.001, -(scale_amplitude2/2/raw_ampnorm)-scale_y2, f\"{scale_amplitude2:.0f} V\" )\n",
    "\n",
    "# annotate p and s arrival\n",
    "arrow_y = 0.02\n",
    "ax.arrow(tp, arrow_y, 0, -8e-3, width=1e-4, length_includes_head=True, head_length=2e-3,head_width=1e-3, color='k')\n",
    "ax.arrow(ts, arrow_y, 0, -8e-3, width=1e-4, length_includes_head=True, head_length=2e-3,head_width=1e-3, color='k')\n",
    "ax.text(tp, arrow_y-0.6e-3, \" P\", ha=\"left\")\n",
    "ax.text(ts, arrow_y-0.6e-3, \" S\", ha=\"left\")\n",
    "\n",
    "# # plot stacked trace\n",
    "# yshift = yshift + 0.5*del_yshift\n",
    "# ax.plot(tvec-pretrigger, (tr_stack.data/ampnorm) - yshift, \"k-\", lw=2)\n",
    "# ytickloc.append(-yshift)\n",
    "# yticklabel.append(\"Stacked\")\n",
    "\n",
    "# decoration of figure\n",
    "ax.set_xlim([0.0, 0.12])\n",
    "ax.set_ylim([ytickloc[-1]-0.03, ytickloc[0]+0.03])\n",
    "\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "\n",
    "ax.set_yticks(np.round(ytickloc, 3))\n",
    "ax.set_yticklabels(yticklabel)\n",
    "\n",
    "title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Raw data\"\n",
    "\n",
    "ax.legend([\"instrumental resp. corrected\", \"raw\"], loc=4)\n",
    "ax.set_title(title_str)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + \"/waveform_repeated_event_{}_{}_raw_afterinstrumentalcorrection_all.png\".format(gougepatch_id, repeated_sensor), dpi=300)\n",
    "plt.savefig(figdir + \"/waveform_repeated_event_{}_{}_raw_afterinstrumentalcorrection_all.eps\".format(gougepatch_id, repeated_sensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repick the onset of P wave pulse\n",
    "\n",
    "To improve the pick time of the P wave pulse for triming the P wave window, we repick the onset of P wave arrival. \n",
    "We use the waveforms after the removal of instrumental response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply band-pass filter\n",
    "To remove the low-frequency noise and stabilize the picking, we first apply the band-pass filter. We apply `freqmin = 100 kHz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for filtering\n",
    "# We use the same filter as the previously analyzed gouge events\n",
    "freqmin = 0.1e6 #0.06e6 # apply highpass\n",
    "freqmax = 1e6 # prefilter is applied when removing the instrumental response. pre_filt = (1e4, 2e4, 1e6, 2e6).\n",
    "\n",
    "butterworth_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqmin = 60e3 # high-pass 60kHz\n",
    "# butterworth_order = 3\n",
    "\n",
    "# sos = signal.butter(butterworth_order, freqmin, 'highpass', fs=st_repeat[0].stats.sampling_rate, output='sos')\n",
    "# b, a = signal.butter(butterworth_order, freqmin, 'highpass', fs=st_repeat[0].stats.sampling_rate, output='ba')\n",
    "b, a = signal.butter(butterworth_order, (freqmin, freqmax), 'bandpass', fs=st_repeat[0].stats.sampling_rate, output='ba')\n",
    "\n",
    "st_filt_repick = Stream()\n",
    "\n",
    "for i, datacase in enumerate(datacases_sorted):\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs = st_repeat[tr_ind]\n",
    "    assert(tr_obs.stats.dataindex[6:]==datacase)\n",
    "\n",
    "    # using sos to minimize the numerical error of filter\n",
    "    tr_obs_filtered = tr_obs.copy().taper(0.05)\n",
    "\n",
    "    # Here we use the one-way filter as it is better to pick the onset of P as well as avoiding the acausal trend\n",
    "    # tr_obs_filtered.data = signal.sosfilt(sos, tr_obs_filtered.data)\n",
    "    tr_obs_filtered.data = signal.filtfilt(b, a, tr_obs_filtered.data, method='gust') # using two-way filter Gustafssonâ€™s method\n",
    "\n",
    "    # tr_obs_filtered.data = signal.sosfiltfilt(sos, tr_obs_filtered.data)\n",
    "    st_filt_repick.append(tr_obs_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the onset of P wave pulse\n",
    "\n",
    "We developed the robust process flow to accurately pick the onset of P wave pulse as follows:\n",
    "\n",
    "1. Trim the P wave window\n",
    "2. Detrend the p wave window using the polynomial fitting. We select the order depending on the noise level. The long-period noise is removed by the detrend.\n",
    "3. Find the peak location of P wave pulse using `signal.find_peaks()`.\n",
    "4. To pick the onset of the wide range of the P wave pulse, we use the inflection of the pulse. Compute the second derivative of the waveform.\n",
    "5. Find the maximum point of the second derivative of the waveform from the peak of P.\n",
    "\n",
    "Note:The station far from the source sometimes shows low S/N for the P wave pulse, and finding the onset of P is difficult. In that case, we use the original tpick, which is at least consistent with the theoretical arrival of P wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Development: plot detailed picking algorithm\n",
    "\n",
    "# for tr in st_filt_repick[36:37]: #[18:19]:\n",
    "# # tr = st_filt_repick[7] # 16 # 19\n",
    "    \n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "    \n",
    "#     tvec = tr.times()*1e3\n",
    "#     gougeevent_id = int(tr.stats.dataindex.split(\"__\")[-1])\n",
    "#     fs = st_filt_repick[0].stats.sampling_rate\n",
    "#     pwin_pre = 4e-6#3e-6\n",
    "#     pwin_len = 4e-6\n",
    "#     tpick_diff_thresh = 20 #15 # if the newly picked P onset is N points different from the original, use the original tpick.\n",
    "#     pwin_init_noise_thresh = 1e-6\n",
    "#     # mininflection_Nthresh = 5 # find max inflection larger than this points from peak\n",
    "#     # maxinflection_Nthresh = 15 # find max inflection within this points from peak\n",
    "    \n",
    "#     # onset_amp_thresh = 0.1 # threshold fraction to find the onset\n",
    "    \n",
    "#     pp = tr.stats.pretrigger\n",
    "#     pt = tr.stats.tpick\n",
    "    \n",
    "#     st_ind = np.where(tvec>(pp+pt-pwin_pre*1e3))[0][0]\n",
    "#     et_ind = np.where(tvec>(pp+pt+pwin_len*1e3))[0][0]\n",
    "#     pt_ind = np.where(tvec>(pp+pt))[0][0]\n",
    "#     onset_p_origin = (pt_ind - st_ind) # relative location of the original tpick time\n",
    "\n",
    "#     polarity = -1 * np.sign(tr.stats.xi1) * np.sign(channel_loc[repeated_sensor][1])\n",
    "    \n",
    "#     pwin_data = polarity*tr.data[st_ind:et_ind]\n",
    "#     pwin_data_origin = copy.deepcopy(pwin_data) # copy the P win waveform to evaluate the peak value\n",
    "#     Npwin_data = len(pwin_data)\n",
    "    \n",
    "#     # find the location of the peak in P \n",
    "#     # We detrend by polynomial fitting\n",
    "#     # switch the order by the level of noise\n",
    "#     pwin_init_noiselevel = np.std(pwin_data[:10])\n",
    "#     # print(pwin_init_noiselevel)\n",
    "#     if pwin_init_noiselevel>pwin_init_noise_thresh:\n",
    "#         poly_order = 3\n",
    "#     else:\n",
    "#         poly_order = 1\n",
    "        \n",
    "#     tvec_data = np.array(range(Npwin_data)) * (1/fs)\n",
    "#     k_poly = np.polynomial.polynomial.polyfit(tvec_data, pwin_data, poly_order)\n",
    "#     tr_poly = np.polynomial.polynomial.polyval(tvec_data, k_poly)\n",
    "#     pwin_data_detrended = pwin_data-tr_poly\n",
    "\n",
    "#     # apply tapering\n",
    "#     pwin_data_detrended *= signal.windows.hann(Npwin_data)\n",
    "    \n",
    "#     # pwin_data_detrended = signal.detrend(pwin_data)\n",
    "#     peaks, _ = signal.find_peaks(pwin_data_detrended, prominence=1e-6) #threshold=5e-7 ) # prominence in [m/s]\n",
    "\n",
    "#     # AS22 37 decrease the prominence\n",
    "#     if (repeated_sensor in [\"OL22\"]) & (gougeevent_id==37):\n",
    "#         peaks, _ = signal.find_peaks(pwin_data_detrended, prominence=1e-7) \n",
    "    \n",
    "#     if peaks.size<1:\n",
    "#         # no P peaks found due to low S/N. Use the original P pick\n",
    "#         peak_P = 0\n",
    "#         onset_p = onset_p_origin\n",
    "    \n",
    "#     else:\n",
    "#         # if dist>100:\n",
    "#         # Deprecated: find the peaks closest from the original tpick\n",
    "#         #     peak_P = peaks[np.argmin(np.abs(peaks - onset_p_origin))]\n",
    "#         # else:\n",
    "        \n",
    "#         # UPDATE: pick the largest value\n",
    "#         peak_P = peaks[np.argmax(pwin_data_detrended[peaks])]\n",
    "\n",
    "#         # Modify the peak location for AS07 event 110:\n",
    "#         if (repeated_sensor in [\"OL07\"]) & (gougeevent_id==110):\n",
    "#             peak_P = peaks[0]\n",
    "        \n",
    "#         # Modify the peak location for AS22 event 30:\n",
    "#         elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id in [30, 37, 110]):\n",
    "#             peak_P = peaks[0]         \n",
    "         \n",
    "#         # compute inflection\n",
    "#         pwin_data_d = np.gradient(pwin_data_detrended[peak_P::-1])\n",
    "#         pwin_data_dd = np.gradient(np.gradient(pwin_data_detrended[peak_P::-1]))\n",
    "#         peaks_onset, _ = signal.find_peaks(pwin_data_dd) #, width=3)\n",
    "\n",
    "#         # if not peaks_onset.size:\n",
    "#         #     print(i)\n",
    "#         #     # further find the onset\n",
    "#         #     peaks_onset, _ = signal.find_peaks(pwin_data_dd)\n",
    "        \n",
    "#         # threshold out the peaks by distance from the peak_P\n",
    "#         # print(peaks_onset, peak_P)\n",
    "#         # peaks_onset = peaks_onset[(mininflection_Nthresh<peaks_onset) & (peaks_onset<maxinflection_Nthresh)]\n",
    "        \n",
    "#         if peaks_onset.size<1:\n",
    "#             # no found of new P pick. Use original tpick\n",
    "#             peak_P = 0\n",
    "#             onset_p = onset_p_origin\n",
    "#         else:\n",
    "#             # set the new P pick\n",
    "#             # onset_p = peak_P - peaks_onset[np.argmin(np.abs(peaks_onset - onset_p_origin))]-1\n",
    "#             # onset_p = peak_P - peaks_onset[0] - 1 # the onset is one step ahead of the inflection\n",
    "#             onset_p  = peak_P-peaks_onset[np.argmax(pwin_data_dd[peaks_onset])] - 1\n",
    "            \n",
    "#         # Select the new or original tpick\n",
    "#         # we confirmed that id AS07 110 is correct with new pick\n",
    "#         if (repeated_sensor in [\"OL07\"]) & (gougeevent_id==110):\n",
    "#             print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "\n",
    "#         # AS08 128 is better with the original pick\n",
    "#         elif (repeated_sensor in [\"OL08\"]) & (gougeevent_id==128):\n",
    "#             onset_p = onset_p_origin\n",
    "\n",
    "#         # AS22 30 is better with the new pick\n",
    "#         elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==30):\n",
    "#             print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "#             onset_p  = peak_P-peaks_onset[0] - 1 # use second peak\n",
    "\n",
    "#         # AS22 37 is better with the new pick\n",
    "#         elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==37):\n",
    "#             print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "#             onset_p  = peak_P-peaks_onset[0] - 1 # use second peak\n",
    "\n",
    "#         # AS22 55 is better with the new pick\n",
    "#         elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==55):\n",
    "#             print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "#             onset_p  = peak_P-peaks_onset[1] - 1 # use second peak\n",
    "#             # print(onset_p)\n",
    "       \n",
    "#         # AS22 110 is better with the new pick\n",
    "#         elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==110):\n",
    "#             print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "#             onset_p  = peak_P-peaks_onset[0] - 1 # use second peak\n",
    "#             # print(onset_p)\n",
    "        \n",
    "#         elif np.abs(onset_p - onset_p_origin) > tpick_diff_thresh:\n",
    "#             # the new t pick is too far from the origin. Use the original tpick\n",
    "#             onset_p = onset_p_origin\n",
    "    \n",
    "#     plotampnorm = np.abs(pwin_data_detrended[peak_P])\n",
    "#     ax.plot(pwin_data_detrended/plotampnorm, \"-\", c=\"k\")\n",
    "#     ax.plot(tr_poly/plotampnorm, \"--\", c=\"k\")\n",
    "    \n",
    "#     if peak_P>0:\n",
    "#         ax.plot(peak_P, pwin_data_detrended[peak_P]/plotampnorm, \"o\", c=\"r\")\n",
    "    \n",
    "#     ax.plot(peaks, np.zeros(len(peaks)), \"o\", c=\"y\")\n",
    "#     ax.plot(onset_p, 0, \"+\", c=\"b\", label=\"new t pick\")\n",
    "#     ax.plot(onset_p_origin, 0, \"v\", c=\"g\", label=\"original t pick\")\n",
    "#     gougeevent_id = int(tr.stats.dataindex.split(\"__\")[-1])\n",
    "#     titlestr = f\"event ID: {gougeevent_id}\"\n",
    "#     ax.set_title(titlestr)\n",
    "#     # plt.clf()\n",
    "#     # plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks_onset[(mininflection_Nthresh<peaks_onset) & (peaks_onset<maxinflection_Nthresh)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(pwin_data_d, \".-\")\n",
    "# plt.plot(pwin_data_dd)\n",
    "# plt.plot(pwin_data_detrended[peak_P::-1])\n",
    "# plt.plot(peaks_onset, np.zeros(len(peaks_onset)), \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 10))\n",
    "\n",
    "yshift = 0\n",
    "\n",
    "lc = plt.get_cmap(\"viridis\")\n",
    "norm = plt.Normalize(0, len(st_filt_repick))\n",
    "\n",
    "new_onset_p = dict()\n",
    "peak_P_amp = dict() #save the peak P wave amplitude to normalize the waveform plot\n",
    "peak_P_ind = dict() # save the timing of the P wave peak to align the P wave window\n",
    "\n",
    "for i, tr in enumerate(st_filt_repick):\n",
    "# tr = st_filt[14]\n",
    "    \n",
    "    gougeevent_id = int(tr.stats.dataindex.split(\"__\")[-1])\n",
    "    # print(gougeevent_id)\n",
    "    datacase = tr.stats.dataindex[-14:]\n",
    "    tvec = tr.times()*1e3\n",
    "    \n",
    "    fs = st_filt_repick[0].stats.sampling_rate\n",
    "    pwin_pre = 4e-6 #3e-6\n",
    "    pwin_len = 4e-6\n",
    "    tpick_diff_thresh = 20 #15 # if the newly picked P onset is N points different from the original, use the original tpick.\n",
    "    pwin_init_noise_thresh = 1e-6\n",
    "    # mininflection_Nthresh = 5 # deprecated # find max inflection larger than this points from peak\n",
    "    # maxinflection_Nthresh = 15 # deprecated #12 # find max inflection within this points from peak\n",
    "    \n",
    "    # onset_amp_thresh = 0.1 # threshold fraction to find the onset\n",
    "    \n",
    "    pp = tr.stats.pretrigger\n",
    "    pt = tr.stats.tpick\n",
    "    \n",
    "    st_ind = np.where(tvec>(pp+pt-pwin_pre*1e3))[0][0]\n",
    "    et_ind = np.where(tvec>(pp+pt+pwin_len*1e3))[0][0]\n",
    "    pt_ind = np.where(tvec>(pp+pt))[0][0]\n",
    "    onset_p_origin = (pt_ind - st_ind) # relative location of the original tpick time\n",
    "    \n",
    "    polarity = -1 * np.sign(tr.stats.xi1) * np.sign(channel_loc[repeated_sensor][1])\n",
    "    \n",
    "    pwin_data = polarity*tr.data[st_ind:et_ind]\n",
    "    pwin_data_origin = copy.deepcopy(pwin_data) # copy the P win waveform to evaluate the peak value\n",
    "    Npwin_data = len(pwin_data)\n",
    "    \n",
    "    # find the location of the peak in P \n",
    "    # We detrend by polynomial fitting\n",
    "    # switch the order by the level of noise\n",
    "    pwin_init_noiselevel = np.std(pwin_data[:10])\n",
    "    # print(pwin_init_noiselevel)\n",
    "    if pwin_init_noiselevel>pwin_init_noise_thresh:\n",
    "        poly_order = 3\n",
    "    else:\n",
    "        poly_order = 1\n",
    "    \n",
    "    tvec_data = np.array(range(Npwin_data)) * (1/fs)\n",
    "    k_poly = np.polynomial.polynomial.polyfit(tvec_data, pwin_data, poly_order)\n",
    "    tr_poly = np.polynomial.polynomial.polyval(tvec_data, k_poly)\n",
    "    pwin_data_detrended = pwin_data-tr_poly\n",
    "    \n",
    "    # apply tapering\n",
    "    pwin_data_detrended *= signal.windows.hann(Npwin_data)\n",
    "    \n",
    "    # pwin_data_detrended = signal.detrend(pwin_data)\n",
    "    peaks, _ = signal.find_peaks(pwin_data_detrended, prominence=1e-6) #threshold=5e-7 ) # prominence in [m/s]\n",
    "\n",
    "    # AS22 37 decrease the prominence\n",
    "    if (repeated_sensor in [\"OL22\"]) & (gougeevent_id==37):\n",
    "        peaks, _ = signal.find_peaks(pwin_data_detrended, prominence=1e-7) \n",
    "    \n",
    "    if peaks.size<1:\n",
    "        # no P peaks found due to low S/N. Use the original P pick\n",
    "        peak_P = 0\n",
    "        onset_p = onset_p_origin\n",
    "        P_amp = np.max(np.abs(pwin_data_origin)) # use the maximum value of the P window as the normalizing factor\n",
    "    \n",
    "    else:\n",
    "        # if dist>100:\n",
    "        # Deprecated: find the peaks closest from the original tpick\n",
    "        #     peak_P = peaks[np.argmin(np.abs(peaks - onset_p_origin))]\n",
    "        # else:\n",
    "        \n",
    "        # UPDATE: pick the largest value\n",
    "        peak_P = peaks[np.argmax(pwin_data_detrended[peaks])]\n",
    "                \n",
    "        # Modify the peak location for AS07 event 110:\n",
    "        if (repeated_sensor in [\"OL07\"]) & (gougeevent_id in [110]):\n",
    "            peak_P = peaks[0]\n",
    "       \n",
    "        # Modify the peak location for AS22 event 30, 37:\n",
    "        elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id in [30, 37, 110]):\n",
    "            peak_P = peaks[0]\n",
    "\n",
    "        # Modify the peak location for AS22 event 49:\n",
    "        elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id in [49]):\n",
    "            peak_P = peaks[1]\n",
    "\n",
    "        # compute inflection\n",
    "        pwin_data_d = np.gradient(pwin_data_detrended[peak_P::-1])\n",
    "        pwin_data_dd = np.gradient(np.gradient(pwin_data_detrended[peak_P::-1]))\n",
    "        peaks_onset, _ = signal.find_peaks(pwin_data_dd) #, width=3)\n",
    "        \n",
    "        # if not peaks_onset.size:\n",
    "        #     print(i)\n",
    "        #     # further find the onset\n",
    "        #     peaks_onset, _ = signal.find_peaks(pwin_data_dd)\n",
    "\n",
    "        # threshold out the peaks by distance from the peak_P\n",
    "        # print(peaks_onset, peak_P)\n",
    "        # peaks_onset = peaks_onset[peaks_onset<maxinflection_Nthresh]\n",
    "        # peaks_onset = peaks_onset[(mininflection_Nthresh<peaks_onset) & (peaks_onset<maxinflection_Nthresh)]\n",
    "\n",
    "        if peaks_onset.size<1:\n",
    "            # no found of new P pick. Use original tpick\n",
    "            peak_P = 0\n",
    "            onset_p = onset_p_origin\n",
    "        else:\n",
    "            # set the new P pick\n",
    "            # onset_p = peak_P - peaks_onset[np.argmin(np.abs(peaks_onset - onset_p_origin))]-1\n",
    "            # onset_p = peak_P - peaks_onset[0] - 1 # the onset is one step ahead of the inflection\n",
    "            onset_p  = peak_P-peaks_onset[np.argmax(pwin_data_dd[peaks_onset])] - 1\n",
    "\n",
    "        # Using the value of the detrended P, especially for the tiny events.\n",
    "        # P_amp = pwin_data_detrended[peak_P] - pwin_data_detrended[onset_p] # update: use the relative amplitude from the onset\n",
    "        # Update: use the absolute P peak as P_amp or the relative amplitude depending on the sensors\n",
    "        if repeated_sensor == \"OL22\":\n",
    "            P_amp = pwin_data_detrended[peak_P]\n",
    "        else:\n",
    "            P_amp = pwin_data_detrended[peak_P] - pwin_data_detrended[onset_p]\n",
    "\n",
    "        # P_amp = pwin_data_origin[peak_P]\n",
    "        \n",
    "    # Select the new or original tpick\n",
    "    # we confirmed that id AS07 110 is correct with new pick\n",
    "    if (repeated_sensor in [\"OL07\"]) & (gougeevent_id in [110]):\n",
    "        print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "\n",
    "    # AS08 128 is better with the original pick\n",
    "    elif (repeated_sensor in [\"OL08\"]) & (gougeevent_id==128):\n",
    "        print(f\"AS{repeated_sensor} event {gougeevent_id} uses an original pick.\")\n",
    "        onset_p = onset_p_origin\n",
    "        \n",
    "    # AS22 30 is better with the new pick\n",
    "    elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==30):\n",
    "        print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "        onset_p  = peak_P-peaks_onset[0] - 1 # use second peak\n",
    "\n",
    "    # AS22 37 is better with the new pick\n",
    "    elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==37):\n",
    "        print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "        onset_p  = peak_P-peaks_onset[0] - 1 # use second peak\n",
    "        \n",
    "    # AS22 55 is better with the new pick\n",
    "    # elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==55):\n",
    "    #         print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "    #         onset_p  = peak_P-peaks_onset[1] - 1 # use second peak\n",
    "        \n",
    "    # AS22 110 is better with the new pick\n",
    "    elif (repeated_sensor in [\"OL22\"]) & (gougeevent_id==110):\n",
    "        print(f\"AS{repeated_sensor} event {gougeevent_id} uses a new pick.\")\n",
    "        onset_p  = peak_P-peaks_onset[0] - 1 # use second peak\n",
    "        # print(onset_p)     \n",
    "    \n",
    "    elif np.abs(onset_p - onset_p_origin) > tpick_diff_thresh:\n",
    "        # the new t pick is too far from the origin. Use the original tpick\n",
    "        onset_p = onset_p_origin\n",
    "\n",
    "\n",
    "    new_onset_p[datacase] = st_ind + onset_p\n",
    "    peak_P_amp[datacase] = P_amp\n",
    "    peak_P_ind[datacase] = st_ind + peak_P # update: for the P win zoom window align\n",
    "    \n",
    "    ax.plot(pwin_data_detrended/pwin_data_detrended[peak_P]-yshift, \"-\", c=lc(norm(i)))\n",
    "    ax.text(-1, pwin_data_detrended[0]/pwin_data_detrended[peak_P]-yshift, f\"{gougeevent_id}\", c=lc(norm(i)))\n",
    "    # ax.plot(pwin_data_grad/np.max(pwin_data_grad)-yshift, \"--\", c=lc(norm(i)))\n",
    "    ax.plot(peak_P, pwin_data_detrended[peak_P]/pwin_data_detrended[peak_P]-yshift, \"o\", c=lc(norm(i)))\n",
    "    ax.plot(onset_p, pwin_data_detrended[onset_p]/pwin_data_detrended[peak_P]-yshift, \"+\", c=lc(norm(i)))\n",
    "\n",
    "    yshift -= 1\n",
    "\n",
    "ax.set_xlabel(\"Data point\")\n",
    "titlestr = f\"FB03-087 P wave pulse onset AE sensor: {repeated_sensor}\"\n",
    "ax.set_title(titlestr)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + f\"/onset_P_{gougepatch_id}_{repeated_sensor}.png\", dpi=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_P_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the data frame for the onset of P wave used for the trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onset = pd.DataFrame(new_onset_p, index=[\"onset_npt\"]).T\n",
    "tvec = st_filt_repick[0].times()*1e3 # [ms]\n",
    "pretrigger = st_filt_repick[0].stats.pretrigger # [ms]\n",
    "df_onset.loc[:, \"sensor\"] = repeated_sensor \n",
    "df_onset.loc[:, \"onset_t[ms]\"]=df_onset.apply(lambda x: tvec[x.onset_npt]-pretrigger, axis=1)\n",
    "df_onset.loc[:, \"onset_d_ref[mm]\"]=df_onset.apply(lambda x: x[\"onset_t[ms]\"]*param[\"cp\"], axis=1)\n",
    "df_onset.to_csv(dataoutdir+f\"/P_repicked_onset_time_{gougepatch_id}_{repeated_sensor}.csv\", float_format='%12.5g')\n",
    "df_onset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all the events with the alignment at the onset of P\n",
    "\n",
    "We plot all the events with the alignment at the onset of P. We use `st_filt_repick`, which the high-pass filter is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average pp_side\n",
    "pp_side_all = []\n",
    "pS_side_all = []\n",
    "sP_side_all = []\n",
    "for tr in st_repeat:\n",
    "    (p_direct, pp_side, pp_bottom, pp_top, ppp_side) = compute_p_reflection(tr, param)\n",
    "\n",
    "    # tps, tsp, (ideg_ps, jdeg_ps, ideg_sp, jdeg_sp) = compute_ps_and_sp_side_reflection(tr, param)\n",
    "    tps, tsp, deg_Ps, deg_sP = compute_ps_and_sp_side_reflection2(tr, param)\n",
    "\n",
    "    pp_side_all.append(pp_side)\n",
    "    pS_side_all.append(tps)\n",
    "    sP_side_all.append(tsp)\n",
    "\n",
    "pp_side_mean = np.mean(pp_side_all)\n",
    "sP_side_mean = np.mean(sP_side_all)\n",
    "pS_side_mean = np.mean(pS_side_all)\n",
    "\n",
    "(p_direct, pp_side, pp_bottom, pp_top, ppp_side), pp_side_mean, pS_side_mean, sP_side_mean,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color for the all the events\n",
    "skipcolor = 10\n",
    "c_norm = mpl.colors.Normalize(vmin=0, vmax=len(datacases_sorted)+skipcolor)\n",
    "lc_all = dict()\n",
    "cmap = sns.color_palette(\"viridis_r\", as_cmap=True)\n",
    "\n",
    "for i, datacase in enumerate(datacases_sorted[::-1]):\n",
    "    lc_all[datacase] = cmap(c_norm(i+skipcolor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: We measure the signal-to-noise ratio to avoid the large flactuation in the plotting with normalization.\n",
    "> The SNR is measured by the peak P value to the noise window before the onset of P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 12))\n",
    "\n",
    "selected_sensor = st_filt_repick[0].stats.station\n",
    "tvec = st_filt_repick[0].times()*1e3\n",
    "\n",
    "# compute P and S arrival\n",
    "tp = dist/param['cp']\n",
    "ts = dist/param['cs']\n",
    "\n",
    "yshift = 0\n",
    "del_yshift = 7e-3 \n",
    "ampnorm = 0.04 #0.06 \n",
    "ampnorm_normalized = 5e2 # ampnorm normalized with the peak P wave amplitude\n",
    "\n",
    "# parameters to evaluate signal to noise ratio\n",
    "noise_winlen = int(5e-6*st_filt_repick[0].stats.sampling_rate) # noise window\n",
    "SNR_thresh = 2.0 # threshold to correct the noramlizing factor\n",
    "M0_lowSNR_thresh = 0.3\n",
    "min_normalize_thresh = 3e-5 # we threshold the normalizing factor for tiny events with low S/N.\n",
    "\n",
    "yspan = 0# 1.2e-3\n",
    "expr_id = datacases[0].split('__')[0]\n",
    "\n",
    "pretrigger = st_filt_repick[0].stats.pretrigger # [ms]\n",
    "ytickloc = []\n",
    "yticklabel = []\n",
    "\n",
    "IfParrivalshift = True #False #True \n",
    "\n",
    "Nvalidsensors_thresh = 0 # use the source param if the number of STF fitting sensors is more than thresh\n",
    "\n",
    "# plot absolute amplitude and normalized waveform\n",
    "for j, ax in enumerate(axs):\n",
    "    yshift = 0\n",
    "\n",
    "    # Plot repeated events\n",
    "    for i, datacase in enumerate(datacases_sorted):\n",
    "        # i = 4\n",
    "        gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "        tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "        tr_obs_filtered = st_filt_repick[tr_ind]\n",
    "        assert(tr_obs_filtered.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "    \n",
    "        # debug: foreshock or aftershock\n",
    "        event_timing=df_sourceparam_sorted[df_sourceparam_sorted.index==datacase][\"eventtiming\"].values[0]\n",
    "        if event_timing==0:\n",
    "            evtype = \"F\"\n",
    "        else:\n",
    "            evtype = \"A\"\n",
    "        \n",
    "        ytickloc.append(-yshift)\n",
    "        yticklabel.append(f\"{gougeevent_id:d}{evtype}\")\n",
    "    \n",
    "        # load the onset of P wave\n",
    "        onset_p_t = tvec[new_onset_p[f\"{datacase}\"]]\n",
    "            \n",
    "        # time shift to align at P wave arrival\n",
    "        if IfParrivalshift:\n",
    "            dtshift = (tp+pretrigger)-onset_p_t\n",
    "        else:\n",
    "            dtshift = 0 \n",
    "\n",
    "        # set amplitude normalization value\n",
    "        if j==0:\n",
    "            plotamp = ampnorm\n",
    "            lc_plot=lc_all[datacase]\n",
    "        else:\n",
    "            # normalize the value by P wave amplitude\n",
    "            ampnorm_peak_P = peak_P_amp[datacase]\n",
    "            # print(ampnorm_peak_P)\n",
    "            # set minimum normalizing factor for low S/N with smaller events\n",
    "            # SNR_event = np.abs(ampnorm_peak_P)/np.std(tr_obs_filtered.data[:noise_winlen])\n",
    "            onset_p_ind = new_onset_p[f\"{datacase}\"]\n",
    "            SNR_event = np.abs(ampnorm_peak_P)/np.std(tr_obs_filtered.data[onset_p_ind-noise_winlen:onset_p_ind])\n",
    "            \n",
    "            # print(SNR_event)\n",
    "            # if np.abs(ampnorm_peak_P)<min_normalize_thresh:\n",
    "            if (df_sourceparam_sorted.loc[datacase][\"M0\"] < M0_lowSNR_thresh) & (SNR_event < SNR_thresh):\n",
    "                print(gougeevent_id)\n",
    "                # floor the ampnorm\n",
    "                # print(\"test\")\n",
    "                ampnorm_peak_P = min_normalize_thresh\n",
    "                lc_plot=\"gray\"\n",
    "            else:\n",
    "                lc_plot=lc_all[datacase]\n",
    "            \n",
    "            plotamp = np.abs(ampnorm_peak_P)*ampnorm_normalized\n",
    "        \n",
    "        ax.plot(tvec-pretrigger+dtshift, (tr_obs_filtered.data/plotamp) - yshift, \"-\", lw=1, c=lc_plot)\n",
    "        \n",
    "        yshift = yshift + del_yshift\n",
    "    \n",
    "    # # Annotate estimated source parameters\n",
    "    annot_x = 0.0027\n",
    "    annot_x_text = 0.002\n",
    "    annot_y = 0.002 #-0.003\n",
    "    \n",
    "    for i, datacase in enumerate(datacases_sorted):\n",
    "        # print(datacase)\n",
    "        # M0_best = df_bestparam.loc[datacase][\"M0_best\"]\n",
    "        # TR_best = df_bestparam.loc[datacase][\"TR_best\"]\n",
    "        if df_sourceparam_sorted.loc[datacase, \"Nvalidsensors\"] >= Nvalidsensors_thresh:\n",
    "            M0_best = df_sourceparam_sorted.loc[datacase, \"M0\"]\n",
    "            Tw_best = df_sourceparam_sorted.loc[datacase, \"Tw\"]\n",
    "        else:\n",
    "            print(\"use waveform fit source param\")\n",
    "            M0_best = df_sourceparam_sorted.loc[datacase, \"M0_fromwavfit\"]\n",
    "            Tw_best = df_sourceparam_sorted.loc[datacase, \"Tw_fromwavfit\"]\n",
    "\n",
    "\n",
    "        # ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f},  {:.1f}\".format(M0_best, TR_best), ha=\"left\")\n",
    "        ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f}\".format(M0_best), ha=\"left\")\n",
    "    \n",
    "    # annotate only seismic moment\n",
    "    annot_txt = [r\"M$_{\\mathrm{0}}$\"]\n",
    "    annot_txt_unit = [\"[Nm]\"]\n",
    "    ax.text(annot_x+0.0025, ytickloc[0]+0.0135, \"{}\".format(*annot_txt), ha=\"center\")\n",
    "    ax.text(annot_x-0.001, ytickloc[0]+0.008, \"{}\".format(*annot_txt_unit), ha=\"left\")\n",
    "    \n",
    "    # annotate the scale of velocity\n",
    "    if j==0:\n",
    "        scale_x = 0.01\n",
    "        scale_y = -(ytickloc[-1]-0.01)\n",
    "        scale_amplitude = 0.2e-3 #[mm/s]\n",
    "        ax.plot([scale_x, scale_x], np.array([-scale_amplitude/2, +scale_amplitude/2])/ampnorm-scale_y, \"k-\");\n",
    "        ax.text(scale_x+0.001, -scale_amplitude/2/ampnorm-scale_y, f\"{scale_amplitude*1e3:.1f} mm/s\" )\n",
    "        \n",
    "    # annotate p and s arrival\n",
    "    arrow_y = ytickloc[0]+0.015\n",
    "    ax.arrow(tp, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "    ax.arrow(ts, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "    ax.text(tp, arrow_y+1e-3, \"P\", ha=\"center\")\n",
    "    ax.text(ts, arrow_y+1e-3, \"S\", ha=\"center\")\n",
    "\n",
    "    # annotate p and sp reflections from side\n",
    "    # ax.arrow(pp_side_mean*1e3, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "    ax.arrow(sP_side_mean*1e3, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "    # ax.text(pp_side_mean*1e3, arrow_y+3e-3, \"pP\", ha=\"center\", fontsize=11)\n",
    "    ax.text(sP_side_mean*1e3, arrow_y+1e-3, \"sP\", ha=\"center\", fontsize=11)\n",
    "    if repeated_sensor == \"OL22\":\n",
    "        # plot pS\n",
    "        ax.arrow(pS_side_mean*1e3, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "        ax.text(pS_side_mean*1e3, arrow_y+1e-3, \"pS\", ha=\"center\", fontsize=11)\n",
    "    \n",
    "    # decoration of figure\n",
    "    ax.text(-0.042, 0.93, \"ID\", transform=ax.transAxes)\n",
    "    \n",
    "    ax.set_xlim([0.0, 0.1])\n",
    "    ax.set_ylim([ytickloc[-1]-0.02, ytickloc[0]+0.03])\n",
    "    \n",
    "    ax.set_xlabel(\"Time [ms]\")\n",
    "    \n",
    "    ax.set_yticks(np.round(ytickloc, 3))\n",
    "    ax.set_yticklabels(yticklabel)\n",
    "    \n",
    "    # title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "    # ax.set_title(title_str)\n",
    "\n",
    "# add suptitle\n",
    "title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g} MHz\"\n",
    "plt.suptitle(title_str)\n",
    "\n",
    "# annotation\n",
    "axs[0].text(-0.08, 0.98, \"a\", fontweight='bold', fontsize=17, transform=axs[0].transAxes)\n",
    "# axs[0].text(0.6, 0.98, \"Velocity\", fontsize=12, transform=axs[0].transAxes)\n",
    "axs[1].text(-0.08, 0.98, \"b\", fontweight='bold', fontsize=17, transform=axs[1].transAxes)\n",
    "axs[1].text(0.33, 0.98, \"Amplitude normalized by the peak of P wave\", fontsize=12, transform=axs[1].transAxes)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + f\"/gougeevent_all_{gougepatch_id}_{repeated_sensor}_afterinstrumentalcorrection_all_sorted_timeshift{IfParrivalshift}.png\", dpi=80)\n",
    "plt.savefig(figdir + f\"/gougeevent_all_{gougepatch_id}_{repeated_sensor}_afterinstrumentalcorrection_all_sorted_timeshift{IfParrivalshift}.eps\")\n",
    "# plt.savefig(figdir + \"/waveform_repeated_event_{}_{}_afterinstrumentalcorrection_all_sorted.eps\".format(gougepatch_id, repeated_sensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_P_amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot master figure on the Figure 1\n",
    "\n",
    "We select the events with number of STF fit sensors for the sake of visuallization. Note that we evaluate the source properties for all the events, not using the cc threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvalidsensors_masterplot = 4\n",
    "df_sourceparam_selected = df_sourceparam_sorted[df_sourceparam_sorted[\"Nvalidsensors\"]==Nvalidsensors_masterplot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the first run, we manually set the 44 events\n",
    "if df_sourceparam_selected.empty: # when the first run\n",
    "    print(\"We insert the select events for first run.\")\n",
    "    GPevent_selectedlist = [4,   9,  18,  19,  20,  21,  24,  27,  31,  38,  40,  43,  44,\n",
    "            50,  52,  61,  62,  69,  72,  77,  85,  88,  89,  95,  99, 100,\n",
    "           109, 118, 120, 126, 128, 129, 131]\n",
    "    df_sourceparam_selected = df_sourceparam_sorted.loc[df_sourceparam_sorted[\"gougeevent_id\"].isin(GPevent_selectedlist), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacases_selected = df_sourceparam_selected.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of gouge events\n",
    "print(f\"all: {len(df_sourceparam_sorted)}, Nvalid=4: {len(datacases_selected)}\") # Nvalidsensors=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color for the selected the events\n",
    "skipcolor = 10\n",
    "c_norm = mpl.colors.Normalize(vmin=0, vmax=len(datacases_selected)+skipcolor)\n",
    "lc_selected = dict()\n",
    "cmap = sns.color_palette(\"viridis_r\", as_cmap=True)\n",
    "\n",
    "for i, datacase in enumerate(datacases_selected[::-1]):\n",
    "    lc_selected[datacase] = cmap(c_norm(i+skipcolor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump line color dictionary\n",
    "with open(dataoutdir+f'/lc_dict_{gougepatch_id}_{repeated_sensor}.pkl', 'wb') as fo:\n",
    "    pickle.dump(lc_selected, fo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6.2, 6.25)) #7))\n",
    "\n",
    "selected_sensor = st_filt_repick[0].stats.station\n",
    "tvec = st_filt_repick[0].times()*1e3\n",
    "\n",
    "# compute P and S arrival\n",
    "tp = dist/param['cp']\n",
    "ts = dist/param['cs']\n",
    "\n",
    "yshift = 0\n",
    "del_yshift = 7e-3 \n",
    "ampnorm = 0.04 #0.06 \n",
    "ampnorm_normalized = 4.5e2 #6e2 # ampnorm normalized with the peak P wave amplitude\n",
    "\n",
    "# parameters to evaluate signal to noise ratio\n",
    "noise_winlen = int(5e-6*st_filt_repick[0].stats.sampling_rate) # noise window\n",
    "SNR_thresh = 2.0 # threshold to correct the noramlizing factor\n",
    "M0_lowSNR_thresh = 0.3\n",
    "min_normalize_thresh = 3e-5 # we threshold the normalizing factor for tiny events with low S/N.\n",
    "\n",
    "yspan = 0# 1.2e-3\n",
    "expr_id = datacases[0].split('__')[0]\n",
    "\n",
    "pretrigger = st_filt_repick[0].stats.pretrigger # [ms]\n",
    "ytickloc = []\n",
    "yticklabel = []\n",
    "\n",
    "IfParrivalshift = True #False #True \n",
    "\n",
    "yshift = 0\n",
    "normalize_j= 1\n",
    "\n",
    "ifPolarityPos = False\n",
    "\n",
    "# Plot repeated events\n",
    "for i, datacase in enumerate(datacases_selected):\n",
    "    # i = 4\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs_filtered = st_filt_repick[tr_ind]\n",
    "    # tr_obs_filtered_plot = st_filt_plot[tr_ind]\n",
    "    assert(tr_obs_filtered.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "\n",
    "    # debug: foreshock or aftershock\n",
    "    event_timing=df_sourceparam_selected[df_sourceparam_selected.index==datacase][\"eventtiming\"].values[0]\n",
    "    if event_timing==0:\n",
    "        evtype = \"F\"\n",
    "    else:\n",
    "        evtype = \"A\"\n",
    "    \n",
    "    ytickloc.append(-yshift)\n",
    "    # yticklabel.append(f\"{gougeevent_id:d}{evtype}\")\n",
    "    yticklabel.append(f\"{gougeevent_id:d}\")\n",
    "\n",
    "    # load the onset of P wave\n",
    "    onset_p_t = tvec[new_onset_p[f\"{datacase}\"]]\n",
    "        \n",
    "    # time shift to align at P wave arrival\n",
    "    if IfParrivalshift:\n",
    "        dtshift = (tp+pretrigger)-onset_p_t\n",
    "    else:\n",
    "        dtshift = 0 \n",
    "\n",
    "    # set amplitude normalization value\n",
    "    if normalize_j==0:\n",
    "        plotamp = ampnorm\n",
    "        lc_plot=lc_all[datacase]\n",
    "    else:\n",
    "        # normalize the value by P wave amplitude\n",
    "        ampnorm_peak_P = peak_P_amp[datacase]\n",
    "        # print(ampnorm_peak_P)\n",
    "        # set minimum normalizing factor for low S/N with smaller events\n",
    "        # SNR_event = np.abs(ampnorm_peak_P)/np.std(tr_obs_filtered.data[:noise_winlen])\n",
    "        onset_p_ind = new_onset_p[f\"{datacase}\"]\n",
    "        SNR_event = np.abs(ampnorm_peak_P)/np.std(tr_obs_filtered.data[onset_p_ind-noise_winlen:onset_p_ind])\n",
    "            \n",
    "        # print(SNR_event)\n",
    "        # if np.abs(ampnorm_peak_P)<min_normalize_thresh:\n",
    "        # if (df_bestparam.loc[datacase][\"M0_best\"] < M0_lowSNR_thresh) & (SNR_event < SNR_thresh):\n",
    "        if (df_sourceparam_selected.loc[datacase, \"M0\"] < M0_lowSNR_thresh) & (SNR_event < SNR_thresh):\n",
    "            # floor the ampnorm\n",
    "            # print(\"test\")\n",
    "            ampnorm_peak_P = min_normalize_thresh\n",
    "            lc_plot=\"gray\"\n",
    "            # We skip plotting the low S/N for Figure 1\n",
    "            print(f\"skip {datacase} due to low SNR.\")\n",
    "            continue\n",
    "        else:\n",
    "            lc_plot=lc_all[datacase]\n",
    "\n",
    "        plotamp = np.abs(ampnorm_peak_P)*ampnorm_normalized\n",
    "    \n",
    "    # print(gougeevent_id, plotamp)\n",
    "\n",
    "    if ifPolarityPos:\n",
    "        polarity = -1 * np.sign(tr_obs_filtered.stats.xi1) * np.sign(channel_loc[repeated_sensor][1])\n",
    "    else:\n",
    "        polarity = 1\n",
    "        \n",
    "    ax.plot(tvec-pretrigger+dtshift, (tr_obs_filtered.data/plotamp) - yshift, \"-\", lw=1, c=lc_plot)\n",
    "    # ax.plot(tvec-pretrigger+dtshift, (tr_obs_filtered_plot.data/plotamp) - yshift, \"-\", lw=1, c=lc_plot)\n",
    "    \n",
    "    yshift = yshift + del_yshift\n",
    "\n",
    "    # # Annotate estimated source parameters\n",
    "    annot_x = 0.0027\n",
    "    annot_x_text = 0.002\n",
    "    annot_y = 0.001 #-0.003\n",
    "    \n",
    "    # for i, datacase in enumerate(datacases_selected):\n",
    "    # print(datacase)\n",
    "    # M0_best = df_bestparam.loc[datacase][\"M0_best\"]\n",
    "    # TR_best = df_bestparam.loc[datacase][\"TR_best\"]\n",
    "    if df_sourceparam_sorted.loc[datacase, \"Nvalidsensors\"] >= Nvalidsensors_thresh:\n",
    "        M0_best = df_sourceparam_selected.loc[datacase, \"M0\"]\n",
    "        Tw_best = df_sourceparam_selected.loc[datacase, \"Tw\"]\n",
    "    else:\n",
    "        print(\"use waveform fit source param\")\n",
    "        M0_best = df_sourceparam_selected.loc[datacase, \"M0_fromwavfit\"]\n",
    "        Tw_best = df_sourceparam_selected.loc[datacase, \"Tw_fromwavfit\"]\n",
    "\n",
    "    assert(len(df_sourceparam_selected.loc[datacase, :] == 1))\n",
    "    # M0_best_fromSTFfit = df_stacked_sorted[df_stacked_sorted[\"datacase\"] == datacase][\"M0_mean\"].values[0]\n",
    "    # Tw_best_fromSTFfit = df_stacked_sorted[df_stacked_sorted[\"datacase\"] == datacase][\"Tw_mean\"].values[0] * 1e6\n",
    "    # ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f},  {:.1f}\".format(M0_best, TR_best), ha=\"left\")\n",
    "    # ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f}\".format(M0_best), ha=\"left\")\n",
    "    ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f}\".format(M0_best), ha=\"left\", fontsize=11)\n",
    "    # ax.text(annot_x_text+0.01, ytickloc[i]+annot_y, r\"{:.2f}\".format(M0_best), ha=\"left\", c=\"b\") # debug from best fit param\n",
    "\n",
    "# annotate only seismic moment\n",
    "annot_txt = [r\"M$_{\\mathrm{0}}$\"]\n",
    "annot_txt_unit = [\"[Nm]\"]\n",
    "ax.text(annot_x+0.0028, ytickloc[0]+0.0165, \"{}\".format(*annot_txt), ha=\"center\", fontsize=11)\n",
    "ax.text(annot_x-0.001, ytickloc[0]+0.0094, \"{}\".format(*annot_txt_unit), ha=\"left\", fontsize=11)\n",
    "\n",
    "# annotate the scale of velocity\n",
    "if normalize_j==0:\n",
    "    scale_x = 0.01\n",
    "    scale_y = -(ytickloc[-1]-0.01)\n",
    "    scale_amplitude = 0.2e-3 #[mm/s]\n",
    "    ax.plot([scale_x, scale_x], np.array([-scale_amplitude/2, +scale_amplitude/2])/ampnorm-scale_y, \"k-\");\n",
    "    ax.text(scale_x+0.001, -scale_amplitude/2/ampnorm-scale_y, f\"{scale_amplitude*1e3:.1f} mm/s\" )\n",
    "    \n",
    "# annotate p and s arrival\n",
    "arrow_y = 1.1e-2 #ytickloc[0]+0.015\n",
    "# s_arrival_shift = 2e-3\n",
    "# ax.arrow(tp, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "ax.arrow(ts, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "# ax.text(tp, arrow_y-0.6e-3, \" P\", ha=\"left\")\n",
    "ax.text(ts, arrow_y+3e-3, \"S\", ha=\"center\", fontsize=11)\n",
    "\n",
    "# annotate p and sp reflections from side\n",
    "# ax.arrow(pp_side_mean*1e3, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "# ax.arrow(pS_side_mean*1e3, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "ax.arrow(sP_side_mean*1e3, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "# ax.text(pp_side_mean*1e3, arrow_y+3e-3, \"pP\", ha=\"center\", fontsize=11)\n",
    "# ax.text(pS_side_mean*1e3, arrow_y+3e-3, \"    pS\", ha=\"center\", fontsize=11)\n",
    "ax.text(sP_side_mean*1e3, arrow_y+3e-3, \"sP\", ha=\"center\", fontsize=11)\n",
    "\n",
    "# annotate p pulse window used to compute far-field displacement pulse\n",
    "arrow_y = 1.1e-2 # 6e-3\n",
    "pwin_pre = 4e-6 # taken from the values in the following cell\n",
    "pwin_len = 6e-6\n",
    "pp = tp #np.mean(pp_all) # aligned timing at average distance divided by the velocity\n",
    "\n",
    "ax.plot([pp-pwin_pre*1e3, pp+pwin_len*1e3], [arrow_y, arrow_y], \"k-\", marker=\"|\", ms=7, markeredgewidth=1)\n",
    "ax.text(pp, arrow_y+3e-3, \"   P\", ha=\"center\", fontsize=11)\n",
    "\n",
    "# decoration of figure\n",
    "# ax.text(-0.036, 0.922, \"ID\", transform=ax.transAxes)\n",
    "ax.text(-0.036, 0.925, \"ID\", transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "ax.set_xlim([0.0, 0.12])\n",
    "# ax.set_ylim([ytickloc[-1]-0.01, ytickloc[0]+0.025]) # use this to remove the bottom space\n",
    "ax.set_ylim([ytickloc[-1]-0.02, ytickloc[0]+0.025])\n",
    "\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "\n",
    "ax.set_yticks(np.round(ytickloc, 3))\n",
    "ax.set_yticklabels(yticklabel, fontsize=11)\n",
    "\n",
    "# title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "# ax.set_title(title_str)\n",
    "\n",
    "# add suptitle\n",
    "# title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "gouge_x = 1.75 # gouge patch at G3 \n",
    "# title_str = f\"Asperity patch location: G3, AS{selected_sensor[2:]} source distance: {dist:.1f} mm\"\n",
    "title_str = f\"Gouge patch location: P3, AS{selected_sensor[2:]} source distance: {dist:.1f} mm\"\n",
    "ax.set_title(title_str, fontsize=12)\n",
    "\n",
    "ax.text(0.61, 0.965, f\"Band-pass filtered: {freqmin/1e6:g}-{freqmax/1e6:.1g} MHz\", transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + f\"/Fig1_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_normalize_{normalize_j}_all_sorted_timeshift{IfParrivalshift}_Polaritypos{ifPolarityPos}.png\", dpi=80)\n",
    "plt.savefig(figdir + f\"/Fig1_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_normalize_{normalize_j}_all_sorted_timeshift{IfParrivalshift}_Polaritypos{ifPolarityPos}.eps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot superimposed normalized waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 3)) #7))\n",
    "\n",
    "selected_sensor = st_filt_repick[0].stats.station\n",
    "tvec = st_filt_repick[0].times()*1e3\n",
    "\n",
    "yspan = 0# 1.2e-3\n",
    "expr_id = datacases[0].split('__')[0]\n",
    "\n",
    "ytickloc = []\n",
    "yticklabel = []\n",
    "\n",
    "IfParrivalshift = True #False #True \n",
    "\n",
    "yshift = 0\n",
    "normalize_j= 1\n",
    "\n",
    "ampnorm_normalized = 5\n",
    "\n",
    "# Plot repeated events\n",
    "for i, datacase in enumerate(datacases_selected):\n",
    "    # i = 4\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs_filtered = st_filt_repick[tr_ind]\n",
    "    assert(tr_obs_filtered.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "\n",
    "    # debug: foreshock or aftershock\n",
    "    event_timing=df_sourceparam_selected[df_sourceparam_selected.index==datacase][\"eventtiming\"].values[0]\n",
    "    if event_timing==0:\n",
    "        evtype = \"F\"\n",
    "    else:\n",
    "        evtype = \"A\"\n",
    "    \n",
    "    ytickloc.append(-yshift)\n",
    "    # yticklabel.append(f\"{gougeevent_id:d}{evtype}\")\n",
    "    yticklabel.append(f\"{gougeevent_id:d}\")\n",
    "\n",
    "    # load the onset of P wave\n",
    "    onset_p_t = tvec[new_onset_p[f\"{datacase}\"]]\n",
    "        \n",
    "    # time shift to align at P wave arrival\n",
    "    if IfParrivalshift:\n",
    "        dtshift = (tp+pretrigger)-onset_p_t\n",
    "    else:\n",
    "        dtshift = 0 \n",
    "\n",
    "    # set amplitude normalization value\n",
    "    if normalize_j==0:\n",
    "        plotamp = ampnorm\n",
    "        lc_plot=lc_all[datacase]\n",
    "    else:\n",
    "        # normalize the value by P wave amplitude\n",
    "        ampnorm_peak_P = peak_P_amp[datacase]\n",
    "        # print(ampnorm_peak_P)\n",
    "        # set minimum normalizing factor for low S/N with smaller events\n",
    "        SNR_event = np.abs(ampnorm_peak_P)/np.std(tr_obs_filtered.data[:noise_winlen])\n",
    "        # print(SNR_event)\n",
    "        # if np.abs(ampnorm_peak_P)<min_normalize_thresh:\n",
    "        if (df_sourceparam_selected.loc[datacase, \"M0\"] < M0_lowSNR_thresh) & (SNR_event < SNR_thresh):\n",
    "            # floor the ampnorm\n",
    "            # print(\"test\")\n",
    "            ampnorm_peak_P = min_normalize_thresh\n",
    "            lc_plot=\"gray\"\n",
    "            # We skip plotting the low S/N for Figure 1\n",
    "            print(f\"skip {datacase} due to low SNR.\")\n",
    "            continue\n",
    "        else:\n",
    "            lc_plot=lc_all[datacase]\n",
    "        \n",
    "        plotamp = np.abs(ampnorm_peak_P)*ampnorm_normalized\n",
    "    \n",
    "    ax.plot(tvec-pretrigger+dtshift, (tr_obs_filtered.data/plotamp) - yshift, \"-\", lw=1, c=lc_plot)\n",
    "    \n",
    "    # yshift = yshift + del_yshift\n",
    "\n",
    "# # decoration of figure\n",
    "# ax.text(-0.036, 0.925, \"ID\", transform=ax.transAxes)\n",
    "\n",
    "ax.set_xlim([0.0, 0.08])\n",
    "ax.set_ylim([-1, 1])\n",
    "# ax.set_ylim([ytickloc[-1]-0.01, ytickloc[0]+0.02])\n",
    "\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "ax.set_ylabel(\"Normalized amplitude\")\n",
    "# ax.set_yticks(np.round(ytickloc, 3))\n",
    "# ax.set_yticklabels(yticklabel)\n",
    "\n",
    "title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "ax.set_title(title_str)\n",
    "\n",
    "# ax.text(0.605, 0.96, f\"Band-pass filtered: {freqmin/1e6:g}-{freqmax/1e6:.1g} MHz\", transform=ax.transAxes)\n",
    "ax.tick_params(axis='x', which='major', pad=5)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + f\"/Fig1aux_supimp_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_normalize_{normalize_j}_all_sorted_timeshift{IfParrivalshift}.png\", dpi=80)\n",
    "# plt.savefig(figdir + f\"/Fig1aux_supimp_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_all_sorted_timeshift{IfParrivalshift}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot velocity without amplitude normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_Ps, deg_sP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.stats.eta1, tr.stats.xi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6.2, 6.25)) #figsize=(7, 7.3)) #7))\n",
    "\n",
    "selected_sensor = st_filt_repick[0].stats.station\n",
    "tvec = st_filt_repick[0].times()*1e3\n",
    "\n",
    "yshift = 0\n",
    "del_yshift = 7e-3 \n",
    "\n",
    "if repeated_sensor in [\"OL23\", \"OL07\"]:\n",
    "    ampnorm = 0.08 #0.04 #0.06 \n",
    "else:\n",
    "    ampnorm = 0.035 #0.04 #0.06 \n",
    "\n",
    "yspan = 0# 1.2e-3\n",
    "expr_id = datacases[0].split('__')[0]\n",
    "\n",
    "pretrigger = st_filt_repick[0].stats.pretrigger # [ms]\n",
    "ytickloc = []\n",
    "yticklabel = []\n",
    "\n",
    "IfParrivalshift = True #False #True \n",
    "\n",
    "yshift = 0\n",
    "normalize_j= 0\n",
    "\n",
    "ifPolarityPos = False # plot the polarity as positive\n",
    "\n",
    "# Plot repeated events\n",
    "for i, datacase in enumerate(datacases_selected):\n",
    "    # i = 4\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs_filtered = st_filt_repick[tr_ind]\n",
    "    assert(tr_obs_filtered.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "\n",
    "    # debug: foreshock or aftershock\n",
    "    event_timing=df_sourceparam_selected[df_sourceparam_selected.index==datacase][\"eventtiming\"].values[0]\n",
    "    if event_timing==0:\n",
    "        evtype = \"F\"\n",
    "    else:\n",
    "        evtype = \"A\"\n",
    "    \n",
    "    ytickloc.append(-yshift)\n",
    "    # yticklabel.append(f\"{gougeevent_id:d}{evtype}\")\n",
    "    yticklabel.append(f\"{gougeevent_id:d}\")\n",
    "\n",
    "    # load the onset of P wave\n",
    "    onset_p_t = tvec[new_onset_p[f\"{datacase}\"]]\n",
    "        \n",
    "    # time shift to align at P wave arrival\n",
    "    if IfParrivalshift:\n",
    "        dtshift = (tp+pretrigger)-onset_p_t\n",
    "    else:\n",
    "        dtshift = 0 \n",
    "\n",
    "    # set amplitude normalization value\n",
    "    if normalize_j==0:\n",
    "        plotamp = ampnorm\n",
    "        lc_plot=lc_all[datacase]\n",
    "    else:\n",
    "        # normalize the value by P wave amplitude\n",
    "        ampnorm_peak_P = peak_P_amp[datacase]\n",
    "        # print(ampnorm_peak_P)\n",
    "        # set minimum normalizing factor for low S/N with smaller events\n",
    "        SNR_event = np.abs(ampnorm_peak_P)/np.std(tr_obs_filtered.data[:noise_winlen])\n",
    "        # print(SNR_event)\n",
    "        # if np.abs(ampnorm_peak_P)<min_normalize_thresh:\n",
    "        if (df_sourceparam_selected.loc[datacase, \"M0\"] < M0_lowSNR_thresh) & (SNR_event < SNR_thresh):\n",
    "            # floor the ampnorm\n",
    "            # print(\"test\")\n",
    "            ampnorm_peak_P = min_normalize_thresh\n",
    "            lc_plot=\"gray\"\n",
    "            # We skip plotting the low S/N for Figure 1\n",
    "            print(f\"skip {datacase} due to low SNR.\")\n",
    "            continue\n",
    "        else:\n",
    "            lc_plot=lc_all[datacase]\n",
    "        \n",
    "        plotamp = np.abs(ampnorm_peak_P)*ampnorm_normalized\n",
    "\n",
    "    if ifPolarityPos:\n",
    "        polarity = -1 * np.sign(tr_obs_filtered.stats.xi1) * np.sign(channel_loc[repeated_sensor][1])\n",
    "    else:\n",
    "        polarity = 1\n",
    "        \n",
    "    ax.plot(tvec-pretrigger+dtshift, polarity * (tr_obs_filtered.data/plotamp) - yshift, \"-\", lw=1, c=lc_plot)\n",
    "    \n",
    "    yshift = yshift + del_yshift\n",
    "\n",
    "    # # Annotate estimated source parameters\n",
    "    annot_x = 0.0027\n",
    "    annot_x_text = 0.002\n",
    "    annot_y = 0.001 #-0.003\n",
    "    \n",
    "    # for i, datacase in enumerate(datacases_selected):\n",
    "    # print(datacase)\n",
    "    # M0_best = df_bestparam.loc[datacase][\"M0_best\"]\n",
    "    # TR_best = df_bestparam.loc[datacase][\"TR_best\"]\n",
    "    if df_sourceparam_sorted.loc[datacase, \"Nvalidsensors\"] >= Nvalidsensors_thresh:\n",
    "        M0_best = df_sourceparam_selected.loc[datacase, \"M0\"]\n",
    "        Tw_best = df_sourceparam_selected.loc[datacase, \"Tw\"]\n",
    "    else:\n",
    "        print(\"use waveform fit source param\")\n",
    "        M0_best = df_sourceparam_selected.loc[datacase, \"M0_fromwavfit\"]\n",
    "        Tw_best = df_sourceparam_selected.loc[datacase, \"Tw_fromwavfit\"]\n",
    "\n",
    "    assert(len(df_sourceparam_selected.loc[datacase, :] == 1))\n",
    "    # ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f},  {:.1f}\".format(M0_best, TR_best), ha=\"left\")\n",
    "    ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f}\".format(M0_best), ha=\"left\", fontsize=11)\n",
    "\n",
    "# annotate only seismic moment\n",
    "annot_txt = [r\"M$_{\\mathrm{0}}$\"]\n",
    "annot_txt_unit = [\"[Nm]\"]\n",
    "ax.text(annot_x+0.0028, ytickloc[0]+0.0165, \"{}\".format(*annot_txt), ha=\"center\", fontsize=11)\n",
    "ax.text(annot_x-0.001, ytickloc[0]+0.0094, \"{}\".format(*annot_txt_unit), ha=\"left\", fontsize=11)\n",
    "\n",
    "# annotate the scale of velocity\n",
    "if normalize_j==0:\n",
    "    scale_x = 0.01\n",
    "    scale_y = -(ytickloc[-1]-0.01)\n",
    "    scale_amplitude = 0.2e-3 #[mm/s]\n",
    "    ax.plot([scale_x, scale_x], np.array([-scale_amplitude/2, +scale_amplitude/2])/ampnorm-scale_y, \"k-\");\n",
    "    ax.text(scale_x+0.001, -scale_amplitude/2/ampnorm-scale_y, f\"{scale_amplitude*1e3:.1f} mm/s\", fontsize=11)\n",
    "    \n",
    "# annotate p and s arrival\n",
    "arrow_y = 1.1e-2 #ytickloc[0]+0.015\n",
    "# s_arrival_shift = 2e-3\n",
    "# ax.arrow(tp, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "ax.arrow(ts, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "# ax.text(tp, arrow_y-0.6e-3, \" P\", ha=\"left\")\n",
    "ax.text(ts, arrow_y+3e-3, \"S\", ha=\"center\", fontsize=11)\n",
    "\n",
    "# annotate p and sp reflections from side\n",
    "# ax.arrow(pp_side_mean*1e3, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "# ax.arrow(pS_side_mean*1e3, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "ax.arrow(sP_side_mean*1e3, arrow_y+1e-3, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.0e-3, color='k')\n",
    "# ax.text(pp_side_mean*1e3, arrow_y+3e-3, \"pP\", ha=\"center\", fontsize=11)\n",
    "# ax.text(pS_side_mean*1e3, arrow_y+3e-3, \"    pS\", ha=\"center\", fontsize=11)\n",
    "ax.text(sP_side_mean*1e3, arrow_y+3e-3, \"sP\", ha=\"center\", fontsize=11)\n",
    "\n",
    "# annotate p pulse window used to compute far-field displacement pulse\n",
    "arrow_y = 1.1e-2 # 6e-3\n",
    "pwin_pre = 4e-6 # taken from the values in the following cell\n",
    "pwin_len = 6e-6\n",
    "pp = tp #np.mean(pp_all) # aligned timing at average distance divided by the velocity\n",
    "\n",
    "ax.plot([pp-pwin_pre*1e3, pp+pwin_len*1e3], [arrow_y, arrow_y], \"k-\", marker=\"|\", ms=7, markeredgewidth=1)\n",
    "ax.text(pp, arrow_y+3e-3, \"   P\", ha=\"center\", fontsize=11)\n",
    "\n",
    "\n",
    "# annotate s pulse window\n",
    "# arrow_y = 1.1e-2 # 6e-3\n",
    "# swin_pre = 2e-6 # taken from the values in the following cell\n",
    "# swin_len = 8e-6\n",
    "# ps = ts\n",
    "\n",
    "# ax.plot([ps-swin_pre*1e3, ps+swin_len*1e3], [arrow_y, arrow_y], \"k-\", marker=\"|\", ms=7, markeredgewidth=1)\n",
    "# ax.text(ps, arrow_y+3e-3, \"       S\", ha=\"center\", fontsize=11)\n",
    "\n",
    "\n",
    "# decoration of figure\n",
    "ax.text(-0.036, 0.925, \"ID\", transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "ax.set_xlim([0.0, 0.12])\n",
    "ax.set_ylim([ytickloc[-1]-0.02, ytickloc[0]+0.025])\n",
    "\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "\n",
    "ax.set_yticks(np.round(ytickloc, 3))\n",
    "ax.set_yticklabels(yticklabel, fontsize=11)\n",
    "\n",
    "# title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "# ax.set_title(title_str)\n",
    "\n",
    "# add suptitle\n",
    "# title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "gouge_x = 1.75 # gouge patch at G3 \n",
    "title_str = f\"Gouge patch location: P3, AS{selected_sensor[2:]} source distance: {dist:.1f} mm\"\n",
    "ax.set_title(title_str, fontsize=12)\n",
    "\n",
    "ax.text(0.61, 0.965, f\"Band-pass filtered: {freqmin/1e6:g}-{freqmax/1e6:.1g} MHz\", transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(figdir + f\"/Fig1_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_{normalize_j}_all_sorted_timeshift{IfParrivalshift}_Polaritypos{ifPolarityPos}.png\", dpi=80)\n",
    "plt.savefig(figdir + f\"/Fig1_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_{normalize_j}_all_sorted_timeshift{IfParrivalshift}_Polaritypos{ifPolarityPos}.eps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot P wave window\n",
    "\n",
    "Plot P wave window for the introduction figure. We align at the peak P amplitude of the velocity waveforms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_P_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_align_event = 129 # align the P wave at this event\n",
    "pt_align = tvec[peak_P_ind[f'fb03-087__{pt_align_event:04d}']]-pretrigger\n",
    "pt_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax2) = plt.subplots(2, 1, figsize=(2.6, 6.25), gridspec_kw={'height_ratios': [5, 1]}, sharex=True) #7))\n",
    "\n",
    "selected_sensor = st_filt_repick[0].stats.station\n",
    "tvec = st_filt_repick[0].times()*1e3\n",
    "\n",
    "yshift = 0\n",
    "del_yshift = 7e-3 \n",
    "\n",
    "if repeated_sensor in [\"OL23\", \"OL07\"]:\n",
    "    ampnorm = 0.08 #0.04 #0.06 \n",
    "else:\n",
    "    ampnorm = 0.03#0.04 #0.06 \n",
    "\n",
    "yspan = 0# 1.2e-3\n",
    "expr_id = datacases[0].split('__')[0]\n",
    "\n",
    "pretrigger = st_filt_repick[0].stats.pretrigger # [ms]\n",
    "ytickloc = []\n",
    "yticklabel = []\n",
    "\n",
    "# IfParrivalshift = True #False #True \n",
    "IfPpeakshift = True # align at the P peak\n",
    "\n",
    "yshift = 0\n",
    "normalize_j= 1\n",
    "ampnorm_normalized = 1.6e2\n",
    "\n",
    "ifPolarityPos = False # plot the polarity as positive\n",
    "\n",
    "\n",
    "# Plot repeated events\n",
    "for i, datacase in enumerate(datacases_selected):\n",
    "    # i = 4\n",
    "    gougeevent_id = int(datacase.split(\"__\")[1])\n",
    "    tr_ind = [x.stats.dataindex[6:] for x in st_repeat].index(datacase)\n",
    "    tr_obs_filtered = st_filt_repick[tr_ind]\n",
    "    assert(tr_obs_filtered.stats.dataindex[6:]==datacase) # check if the correct datacase is selected\n",
    "\n",
    "    # debug: foreshock or aftershock\n",
    "    event_timing=df_sourceparam_selected[df_sourceparam_selected.index==datacase][\"eventtiming\"].values[0]\n",
    "    if event_timing==0:\n",
    "        evtype = \"F\"\n",
    "    else:\n",
    "        evtype = \"A\"\n",
    "    \n",
    "    ytickloc.append(-yshift)\n",
    "    # yticklabel.append(f\"{gougeevent_id:d}{evtype}\")\n",
    "    yticklabel.append(f\"{gougeevent_id:d}\")\n",
    "\n",
    "    # load the onset of P wave\n",
    "    onset_p_t = tvec[new_onset_p[f\"{datacase}\"]]\n",
    "        \n",
    "    # time shift to align at P wave arrival\n",
    "    # if IfParrivalshift:\n",
    "    #     dtshift = (tp+pretrigger)-onset_p_t\n",
    "    # else:\n",
    "    #     dtshift = 0 \n",
    "    if IfPpeakshift:\n",
    "        Ppeak_event = tvec[peak_P_ind[datacase]]-pretrigger\n",
    "        dtshift = pt_align - Ppeak_event\n",
    "    else:\n",
    "        dtshift = 0\n",
    "\n",
    "    # set amplitude normalization value\n",
    "    if normalize_j==0:\n",
    "        plotamp = ampnorm\n",
    "        lc_plot=lc_all[datacase]\n",
    "    else:\n",
    "        # normalize the value by P wave amplitude\n",
    "        ampnorm_peak_P = peak_P_amp[datacase]\n",
    "        # print(ampnorm_peak_P)\n",
    "        # set minimum normalizing factor for low S/N with smaller events\n",
    "        SNR_event = np.abs(ampnorm_peak_P)/np.std(tr_obs_filtered.data[:noise_winlen])\n",
    "        # print(SNR_event)\n",
    "        # if np.abs(ampnorm_peak_P)<min_normalize_thresh:\n",
    "        if (df_sourceparam_selected.loc[datacase, \"M0\"] < M0_lowSNR_thresh) & (SNR_event < SNR_thresh):\n",
    "            # floor the ampnorm\n",
    "            # print(\"test\")\n",
    "            ampnorm_peak_P = min_normalize_thresh\n",
    "            lc_plot=\"gray\"\n",
    "            # We skip plotting the low S/N for Figure 1\n",
    "            print(f\"skip {datacase} due to low SNR.\")\n",
    "            continue\n",
    "        else:\n",
    "            lc_plot=lc_all[datacase]\n",
    "        \n",
    "        plotamp = np.abs(ampnorm_peak_P)*ampnorm_normalized\n",
    "\n",
    "    if ifPolarityPos:\n",
    "        polarity = -1 * np.sign(tr_obs_filtered.stats.xi1) * np.sign(channel_loc[repeated_sensor][1])\n",
    "    else:\n",
    "        polarity = 1\n",
    "        \n",
    "    ax.plot(tvec-pretrigger+dtshift, polarity * (tr_obs_filtered.data/plotamp) - yshift, \"-\", lw=1, c=lc_plot)\n",
    "    \n",
    "    yshift = yshift + del_yshift\n",
    "\n",
    "    # # Annotate estimated source parameters\n",
    "    annot_x = 0.0027\n",
    "    annot_x_text = 0.002\n",
    "    annot_y = 0.001 #-0.003\n",
    "    \n",
    "    # for i, datacase in enumerate(datacases_selected):\n",
    "    # print(datacase)\n",
    "    # M0_best = df_bestparam.loc[datacase][\"M0_best\"]\n",
    "    # TR_best = df_bestparam.loc[datacase][\"TR_best\"]\n",
    "    if df_sourceparam_sorted.loc[datacase, \"Nvalidsensors\"] >= Nvalidsensors_thresh:\n",
    "        M0_best = df_sourceparam_selected.loc[datacase, \"M0\"]\n",
    "        Tw_best = df_sourceparam_selected.loc[datacase, \"Tw\"]\n",
    "    else:\n",
    "        print(\"use waveform fit source param\")\n",
    "        M0_best = df_sourceparam_selected.loc[datacase, \"M0_fromwavfit\"]\n",
    "        Tw_best = df_sourceparam_selected.loc[datacase, \"Tw_fromwavfit\"]\n",
    "\n",
    "    assert(len(df_sourceparam_selected.loc[datacase, :] == 1))\n",
    "    # ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f},  {:.1f}\".format(M0_best, TR_best), ha=\"left\")\n",
    "    # ax.text(annot_x_text, ytickloc[i]+annot_y, r\"{:.2f}\".format(M0_best), ha=\"left\")\n",
    "\n",
    "    #---Plot superimposed waveform---#\n",
    "    # normalize the peak as unity\n",
    "    Pamp_abs = np.abs(tr_obs_filtered.data[peak_P_ind[datacase]])\n",
    "    # ax2.plot(tvec-pretrigger+dtshift, polarity * (tr_obs_filtered.data/plotamp*ampnorm_normalized), \"-\", lw=1, c=lc_plot)\n",
    "    ax2.plot(tvec-pretrigger+dtshift, polarity * (tr_obs_filtered.data/Pamp_abs), \"-\", lw=1, c=lc_plot)\n",
    "\n",
    "# annotate only seismic moment\n",
    "annot_txt = [r\"M$_{\\mathrm{0}}$\"]\n",
    "annot_txt_unit = [\"[Nm]\"]\n",
    "# ax.text(annot_x+0.0025, ytickloc[0]+0.0145, \"{}\".format(*annot_txt), ha=\"center\")\n",
    "# ax.text(annot_x-0.001, ytickloc[0]+0.009, \"{}\".format(*annot_txt_unit), ha=\"left\")\n",
    "\n",
    "# annotate the scale of velocity\n",
    "if normalize_j==0:\n",
    "    scale_x = 0.028 #0.01\n",
    "    scale_y = -(ytickloc[-1]-0.01)\n",
    "    scale_amplitude = 0.2e-3 #[mm/s]\n",
    "    ax.plot([scale_x, scale_x], np.array([-scale_amplitude/2, +scale_amplitude/2])/ampnorm-scale_y, \"k-\");\n",
    "    ax.text(scale_x+0.001, -scale_amplitude/2/ampnorm-scale_y, f\"{scale_amplitude*1e3:.1f} mm/s\" )\n",
    "    \n",
    "# annotate p and s arrival\n",
    "# arrow_y = ytickloc[0]+0.015\n",
    "# ax.arrow(tp, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "# ax.arrow(ts, arrow_y, 0, -6e-3, width=5e-5, length_includes_head=True, head_length=2e-3,head_width=1.5e-3, color='k')\n",
    "# ax.text(tp, arrow_y-0.6e-3, \" P\", ha=\"left\")\n",
    "# ax.text(ts, arrow_y-0.6e-3, \" S\", ha=\"left\")\n",
    "\n",
    "# annotate p pulse window used to compute far-field displacement pulse\n",
    "arrow_y = 1.5e-2 # 6e-3\n",
    "pwin_pre = 4e-6 # taken from the values in the following cell\n",
    "pwin_len = 6e-6\n",
    "pp = tp #np.mean(pp_all) # aligned timing at average distance divided by the velocity\n",
    "\n",
    "# ax.plot([pp-pwin_pre*1e3, pp+pwin_len*1e3], [arrow_y, arrow_y], \"r-\", marker=\"|\", ms=7, markeredgewidth=1)\n",
    "# ax.text(pp, arrow_y+3e-3, \"   P\", ha=\"center\")\n",
    "\n",
    "# decoration of figure\n",
    "ax.text(-0.11, 0.96, \"ID\", transform=ax.transAxes, fontsize=11)\n",
    "\n",
    "# ax.set_xlim([0.0, 0.12])\n",
    "ax.set_xlim([pp-pwin_pre*1e3, pp+pwin_len*1e3])\n",
    "# ax.set_ylim([ytickloc[-1]-0.02, ytickloc[0]+0.025])\n",
    "ax.set_ylim([ytickloc[-1]-0.015, ytickloc[0]+0.015])\n",
    "\n",
    "# ax.set_xlabel(\"Time [ms]\")\n",
    "\n",
    "ax.set_yticks(np.round(ytickloc, 3))\n",
    "ax.set_yticklabels(yticklabel, fontsize=11)\n",
    "\n",
    "# title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "# ax.set_title(title_str)\n",
    "\n",
    "# add suptitle\n",
    "# title_str = f\"FB03-087 AS{selected_sensor[2:]}: Source distance:{dist:.1f}mm Bandpass filtered: {freqmin/1e6:g}-{freqmax/1e6:g}MHz\"\n",
    "gouge_x = 1.75 # gouge patch at G3 \n",
    "# title_str = f\"Asperity patch location: G3, AS{selected_sensor[2:]} source distance: {dist:.1f} mm\"\n",
    "title_str = f\"Patch: P3, AS{selected_sensor[2:]} \"\n",
    "ax.set_title(title_str, fontsize=12)\n",
    "\n",
    "# ax.text(0.605, 0.96, f\"Band-pass filtered: {freqmin/1e6:g}-{freqmax/1e6:.1g} MHz\", transform=ax.transAxes)\n",
    "\n",
    "ax2.set_ylim([-1.5, 1.5])\n",
    "ax2.set_xlabel(\"Time [ms]\")\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplots_adjust(hspace=0.05)\n",
    "\n",
    "\n",
    "plt.savefig(figdir + f\"/Fig1Pwin_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_{normalize_j}_all_sorted_timeshift{IfParrivalshift}_Polaritypos{ifPolarityPos}.png\", dpi=80)\n",
    "plt.savefig(figdir + f\"/Fig1Pwin_gougeevent_selected_{gougepatch_id}_{repeated_sensor}_{normalize_j}_all_sorted_timeshift{IfParrivalshift}_Polaritypos{ifPolarityPos}.eps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The normalization P amplitude is measured by the relative value between the onset and the peak P in the early part of this notebook. Here we recompute the noramlizing factor by the absolute P peak amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_obs_filtered.data[peak_P_ind[datacase]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook computes the onset of the P wave pulse and plots the gouge events for the master figures. The onset time is dumped to the csv file, which is used to trim the P wave window in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
